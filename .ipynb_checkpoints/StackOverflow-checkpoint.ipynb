{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53796caf",
   "metadata": {},
   "source": [
    "# Showing the reason for not using 33L dataset and going for Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54d96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbf96473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3370528 entries, 0 to 3370527\n",
      "Data columns (total 15 columns):\n",
      " #   Column                               Dtype \n",
      "---  ------                               ----- \n",
      " 0   PostId                               int64 \n",
      " 1   PostCreationDate                     object\n",
      " 2   OwnerUserId                          int64 \n",
      " 3   OwnerCreationDate                    object\n",
      " 4   ReputationAtPostCreation             int64 \n",
      " 5   OwnerUndeletedAnswerCountAtPostTime  int64 \n",
      " 6   Title                                object\n",
      " 7   BodyMarkdown                         object\n",
      " 8   Tag1                                 object\n",
      " 9   Tag2                                 object\n",
      " 10  Tag3                                 object\n",
      " 11  Tag4                                 object\n",
      " 12  Tag5                                 object\n",
      " 13  PostClosedDate                       object\n",
      " 14  OpenStatus                           object\n",
      "dtypes: int64(4), object(11)\n",
      "memory usage: 385.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4552ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>PostCreationDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>OwnerCreationDate</th>\n",
       "      <th>ReputationAtPostCreation</th>\n",
       "      <th>OwnerUndeletedAnswerCountAtPostTime</th>\n",
       "      <th>Title</th>\n",
       "      <th>BodyMarkdown</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>PostClosedDate</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>07/31/2008 21:42:52</td>\n",
       "      <td>8</td>\n",
       "      <td>07/31/2008 21:33:24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Decimal vs Double?</td>\n",
       "      <td>I'm new to C#, and I want to use a trackbar fo...</td>\n",
       "      <td>c#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>07/31/2008 22:08:08</td>\n",
       "      <td>9</td>\n",
       "      <td>07/31/2008 21:35:26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Percentage width child in absolutely positione...</td>\n",
       "      <td>I've got an absolutely positioned div containi...</td>\n",
       "      <td>html</td>\n",
       "      <td>css</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>07/31/2008 23:33:19</td>\n",
       "      <td>9</td>\n",
       "      <td>07/31/2008 21:35:26</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Tools for porting J# code to C#</td>\n",
       "      <td>Are there any conversion tools for porting Vis...</td>\n",
       "      <td>j#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>07/31/2008 23:40:59</td>\n",
       "      <td>1</td>\n",
       "      <td>07/31/2008 14:22:31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I calculate someone's age in c#?</td>\n",
       "      <td>Given a DateTime representing their birthday, ...</td>\n",
       "      <td>c#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9610539</td>\n",
       "      <td>03/07/2012 23:07:09</td>\n",
       "      <td>1021610</td>\n",
       "      <td>10/31/2011 08:26:49</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>retrieve data from NSUserDefaults to TableView</td>\n",
       "      <td>I save values of two labels through NSUserDefa...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>objective-c</td>\n",
       "      <td>ios5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PostId     PostCreationDate  OwnerUserId    OwnerCreationDate  \\\n",
       "0        4  07/31/2008 21:42:52            8  07/31/2008 21:33:24   \n",
       "1        6  07/31/2008 22:08:08            9  07/31/2008 21:35:26   \n",
       "2        8  07/31/2008 23:33:19            9  07/31/2008 21:35:26   \n",
       "3        9  07/31/2008 23:40:59            1  07/31/2008 14:22:31   \n",
       "4  9610539  03/07/2012 23:07:09      1021610  10/31/2011 08:26:49   \n",
       "\n",
       "   ReputationAtPostCreation  OwnerUndeletedAnswerCountAtPostTime  \\\n",
       "0                         1                                    0   \n",
       "1                         1                                    0   \n",
       "2                        16                                    1   \n",
       "3                         1                                    1   \n",
       "4                        29                                    0   \n",
       "\n",
       "                                               Title  \\\n",
       "0                                 Decimal vs Double?   \n",
       "1  Percentage width child in absolutely positione...   \n",
       "2                    Tools for porting J# code to C#   \n",
       "3            How do I calculate someone's age in c#?   \n",
       "4     retrieve data from NSUserDefaults to TableView   \n",
       "\n",
       "                                        BodyMarkdown    Tag1         Tag2  \\\n",
       "0  I'm new to C#, and I want to use a trackbar fo...      c#          NaN   \n",
       "1  I've got an absolutely positioned div containi...    html          css   \n",
       "2  Are there any conversion tools for porting Vis...      j#          NaN   \n",
       "3  Given a DateTime representing their birthday, ...      c#          NaN   \n",
       "4  I save values of two labels through NSUserDefa...  iphone  objective-c   \n",
       "\n",
       "   Tag3 Tag4 Tag5 PostClosedDate OpenStatus  \n",
       "0   NaN  NaN  NaN            NaN       open  \n",
       "1   NaN  NaN  NaN            NaN       open  \n",
       "2   NaN  NaN  NaN            NaN       open  \n",
       "3   NaN  NaN  NaN            NaN       open  \n",
       "4  ios5  NaN  NaN            NaN       open  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a223678e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostId                                       0\n",
       "PostCreationDate                             0\n",
       "OwnerUserId                                  0\n",
       "OwnerCreationDate                            0\n",
       "ReputationAtPostCreation                     0\n",
       "OwnerUndeletedAnswerCountAtPostTime          0\n",
       "Title                                        0\n",
       "BodyMarkdown                                 1\n",
       "Tag1                                       160\n",
       "Tag2                                    525174\n",
       "Tag3                                   1389204\n",
       "Tag4                                   2328489\n",
       "Tag5                                   2965559\n",
       "PostClosedDate                         3300392\n",
       "OpenStatus                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2cb8622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Open status: 3300392\n",
      "No. of Close Status: 70136\n",
      "Percentage of open status of whole dataset: 97.91913907850639 %\n",
      "Percentage of close status of whole dataset: 2.080860921493606 %\n"
     ]
    }
   ],
   "source": [
    "len_open=len(df.OpenStatus[df.OpenStatus=='open'])\n",
    "len_close=len(df)-len_open\n",
    "print(\"No. of Open status:\",len_open)\n",
    "print(\"No. of Close Status:\",len_close)\n",
    "print(\"Percentage of open status of whole dataset:\",(len_open/len(df))*100,\"%\")\n",
    "print(\"Percentage of close status of whole dataset:\",(len_close/len(df))*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b366519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=[\"BodyMarkdown\"],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a704904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostId                                       0\n",
       "PostCreationDate                             0\n",
       "OwnerUserId                                  0\n",
       "OwnerCreationDate                            0\n",
       "ReputationAtPostCreation                     0\n",
       "OwnerUndeletedAnswerCountAtPostTime          0\n",
       "Title                                        0\n",
       "BodyMarkdown                                 0\n",
       "Tag1                                       160\n",
       "Tag2                                    525174\n",
       "Tag3                                   1389203\n",
       "Tag4                                   2328488\n",
       "Tag5                                   2965558\n",
       "PostClosedDate                         3300391\n",
       "OpenStatus                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e311db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Open status: 3300391\n",
      "No. of Close Status: 70136\n",
      "Percentage of open status of whole dataset: 97.9191384611368 %\n",
      "Percentage of close status of whole dataset: 2.0808615388632106 %\n"
     ]
    }
   ],
   "source": [
    "len_open=len(df.OpenStatus[df.OpenStatus=='open'])\n",
    "len_close=len(df)-len_open\n",
    "print(\"No. of Open status:\",len_open)\n",
    "print(\"No. of Close Status:\",len_close)\n",
    "print(\"Percentage of open status of whole dataset:\",(len_open/len(df))*100,\"%\")\n",
    "print(\"Percentage of close status of whole dataset:\",(len_close/len(df))*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "299000ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\train-sample.csv\\train-sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52f847c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostId                                      0\n",
       "PostCreationDate                            0\n",
       "OwnerUserId                                 0\n",
       "OwnerCreationDate                           0\n",
       "ReputationAtPostCreation                    0\n",
       "OwnerUndeletedAnswerCountAtPostTime         0\n",
       "Title                                       0\n",
       "BodyMarkdown                                0\n",
       "Tag1                                       10\n",
       "Tag2                                    27251\n",
       "Tag3                                    64358\n",
       "Tag4                                   100622\n",
       "Tag5                                   124558\n",
       "PostClosedDate                          70136\n",
       "OpenStatus                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64f9a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Open status: 70136\n",
      "No. of Close Status: 70136\n",
      "Percentage of open status of whole dataset: 50.0 %\n",
      "Percentage of close status of whole dataset: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "len_open=len(df.OpenStatus[df.OpenStatus=='open'])\n",
    "len_close=len(df)-len_open\n",
    "print(\"No. of Open status:\",len_open)\n",
    "print(\"No. of Close Status:\",len_close)\n",
    "print(\"Percentage of open status of whole dataset:\",(len_open/len(df))*100,\"%\")\n",
    "print(\"Percentage of close status of whole dataset:\",(len_close/len(df))*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf96bc",
   "metadata": {},
   "source": [
    "# Creating tokens without stop words and getting top words based on Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "317b8eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 411272\n",
      "Most Common Words: [('1', 116406), ('0', 100576), ('2', 64041), ('using', 59058), ('code', 57381), ('new', 55681), ('like', 53264), ('c', 51703), ('java', 48905), ('get', 47378), ('class', 46101), ('com', 45630), ('file', 45532), ('http', 44910), ('use', 43750), ('want', 43719), ('data', 41971), ('id', 41814), ('name', 41737), ('would', 41692)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stopwords and tokenizer (only needed once)\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# File path\n",
    "file_path = r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\train-sample.csv\\train-sample.csv\"\n",
    "\n",
    "# selecting only relevant columns\n",
    "df = pd.read_csv(file_path, usecols=[\"Title\", \"BodyMarkdown\"])\n",
    "\n",
    "# Combine Title and BodyMarkdown into one text field\n",
    "df[\"text\"] = df[\"Title\"].astype(str) + \" \" + df[\"BodyMarkdown\"].astype(str)\n",
    "\n",
    "# Text Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"\\W+\", \" \", text)  # Remove special characters & punctuation\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]  # Remove stopwords\n",
    "    return words\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"tokens\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Build Vocabulary\n",
    "vocab = Counter()\n",
    "for tokens in df[\"tokens\"]:\n",
    "    tokens=ast.literal_eval(tokens)\n",
    "    vocab.update(tokens)\n",
    "\n",
    "# Print Vocabulary Size\n",
    "print(f\"Vocabulary Size: {len(vocab)}\")\n",
    "\n",
    "# Print Most Common Words\n",
    "print(\"Most Common Words:\", vocab.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "093ed1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tokens_sample_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54bfd640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 116406,\n",
       "         '0': 100576,\n",
       "         '2': 64041,\n",
       "         'using': 59058,\n",
       "         'code': 57381,\n",
       "         'new': 55681,\n",
       "         'like': 53264,\n",
       "         'c': 51703,\n",
       "         'java': 48905,\n",
       "         'get': 47378,\n",
       "         'class': 46101,\n",
       "         'com': 45630,\n",
       "         'file': 45532,\n",
       "         'http': 44910,\n",
       "         'use': 43750,\n",
       "         'want': 43719,\n",
       "         'data': 41971,\n",
       "         'id': 41814,\n",
       "         'name': 41737,\n",
       "         'would': 41692,\n",
       "         'string': 41043,\n",
       "         '3': 39047,\n",
       "         'php': 36607,\n",
       "         'one': 36531,\n",
       "         'int': 35266,\n",
       "         'error': 35119,\n",
       "         'function': 35066,\n",
       "         'android': 34032,\n",
       "         'value': 32979,\n",
       "         'public': 32781,\n",
       "         'thanks': 32264,\n",
       "         'need': 32188,\n",
       "         'text': 32060,\n",
       "         'user': 31480,\n",
       "         'know': 30651,\n",
       "         'server': 30335,\n",
       "         'application': 29394,\n",
       "         'way': 29029,\n",
       "         'type': 28509,\n",
       "         'return': 28346,\n",
       "         'system': 27786,\n",
       "         'help': 27780,\n",
       "         'page': 25382,\n",
       "         '4': 24609,\n",
       "         'e': 24501,\n",
       "         'app': 24198,\n",
       "         'web': 23866,\n",
       "         'html': 23355,\n",
       "         'x': 23290,\n",
       "         'problem': 23179,\n",
       "         'div': 23132,\n",
       "         'set': 23108,\n",
       "         'time': 23057,\n",
       "         '5': 22465,\n",
       "         'org': 22163,\n",
       "         'create': 21711,\n",
       "         'add': 21466,\n",
       "         'work': 21309,\n",
       "         'net': 20990,\n",
       "         'list': 20918,\n",
       "         'void': 20737,\n",
       "         'table': 20116,\n",
       "         'make': 19686,\n",
       "         'method': 19629,\n",
       "         'please': 19398,\n",
       "         'object': 19109,\n",
       "         'null': 18824,\n",
       "         'find': 18702,\n",
       "         'var': 18612,\n",
       "         'image': 18606,\n",
       "         'trying': 18302,\n",
       "         'database': 18235,\n",
       "         'b': 17965,\n",
       "         'example': 17962,\n",
       "         'view': 17832,\n",
       "         'also': 17628,\n",
       "         'true': 17583,\n",
       "         'n': 17367,\n",
       "         'could': 17172,\n",
       "         'something': 17102,\n",
       "         'array': 17056,\n",
       "         'script': 16934,\n",
       "         '10': 16613,\n",
       "         'first': 16573,\n",
       "         'form': 16294,\n",
       "         'question': 16286,\n",
       "         'end': 16264,\n",
       "         'following': 16187,\n",
       "         'line': 15933,\n",
       "         'project': 15910,\n",
       "         'files': 15878,\n",
       "         'else': 15745,\n",
       "         'td': 15659,\n",
       "         'select': 15634,\n",
       "         'run': 15539,\n",
       "         'input': 15371,\n",
       "         'working': 15201,\n",
       "         'www': 14852,\n",
       "         'button': 14698,\n",
       "         'javascript': 14434,\n",
       "         'jquery': 14425,\n",
       "         'br': 14421,\n",
       "         'anyone': 14266,\n",
       "         'url': 14123,\n",
       "         'test': 14054,\n",
       "         'p': 13958,\n",
       "         'windows': 13720,\n",
       "         'xml': 13650,\n",
       "         '6': 13493,\n",
       "         'two': 13419,\n",
       "         'see': 13380,\n",
       "         'number': 13250,\n",
       "         'content': 13108,\n",
       "         '8': 13028,\n",
       "         'r': 12882,\n",
       "         '7': 12844,\n",
       "         'possible': 12839,\n",
       "         'good': 12795,\n",
       "         'tried': 12699,\n",
       "         'used': 12646,\n",
       "         'best': 12587,\n",
       "         'program': 12545,\n",
       "         'private': 12509,\n",
       "         'sql': 12464,\n",
       "         'main': 12454,\n",
       "         'false': 12368,\n",
       "         'right': 12247,\n",
       "         'start': 12244,\n",
       "         'try': 12130,\n",
       "         'import': 11968,\n",
       "         'google': 11853,\n",
       "         'site': 11835,\n",
       "         'works': 11834,\n",
       "         'query': 11727,\n",
       "         'write': 11704,\n",
       "         'asp': 11685,\n",
       "         'result': 11661,\n",
       "         'source': 11619,\n",
       "         'self': 11605,\n",
       "         'different': 11555,\n",
       "         'read': 11487,\n",
       "         'call': 11103,\n",
       "         'found': 11075,\n",
       "         'open': 11069,\n",
       "         'width': 10990,\n",
       "         'version': 10947,\n",
       "         'users': 10942,\n",
       "         'key': 10923,\n",
       "         'show': 10919,\n",
       "         'another': 10881,\n",
       "         'etc': 10875,\n",
       "         'change': 10800,\n",
       "         'display': 10777,\n",
       "         'however': 10708,\n",
       "         'message': 10704,\n",
       "         'size': 10667,\n",
       "         'li': 10656,\n",
       "         'client': 10507,\n",
       "         'able': 10427,\n",
       "         'values': 10279,\n",
       "         'simple': 10197,\n",
       "         'access': 10195,\n",
       "         'service': 10191,\n",
       "         'row': 10098,\n",
       "         'post': 10029,\n",
       "         'without': 10021,\n",
       "         'date': 9970,\n",
       "         '00': 9959,\n",
       "         'library': 9841,\n",
       "         'case': 9777,\n",
       "         'website': 9749,\n",
       "         'link': 9731,\n",
       "         'title': 9730,\n",
       "         'python': 9715,\n",
       "         'option': 9711,\n",
       "         'static': 9619,\n",
       "         'looking': 9615,\n",
       "         'h': 9612,\n",
       "         'event': 9611,\n",
       "         'index': 9550,\n",
       "         'advance': 9498,\n",
       "         'click': 9473,\n",
       "         'include': 9444,\n",
       "         'really': 9443,\n",
       "         '9': 9434,\n",
       "         'item': 9432,\n",
       "         'many': 9395,\n",
       "         'style': 9329,\n",
       "         'getting': 9205,\n",
       "         'document': 9160,\n",
       "         'mysql': 9078,\n",
       "         'echo': 8884,\n",
       "         'think': 8877,\n",
       "         'request': 8833,\n",
       "         'css': 8715,\n",
       "         'field': 8572,\n",
       "         'images': 8490,\n",
       "         'search': 8486,\n",
       "         'model': 8468,\n",
       "         'go': 8459,\n",
       "         'output': 8409,\n",
       "         'seems': 8386,\n",
       "         'even': 8336,\n",
       "         'much': 8322,\n",
       "         'left': 8310,\n",
       "         'j': 8282,\n",
       "         'apache': 8237,\n",
       "         'framework': 8235,\n",
       "         'running': 8227,\n",
       "         '12': 8176,\n",
       "         'programming': 8151,\n",
       "         'language': 8138,\n",
       "         'height': 8132,\n",
       "         'api': 8130,\n",
       "         'build': 8109,\n",
       "         'f': 8105,\n",
       "         'load': 8089,\n",
       "         'solution': 8030,\n",
       "         'g': 7974,\n",
       "         'js': 7936,\n",
       "         'exception': 7872,\n",
       "         'created': 7860,\n",
       "         'sure': 7823,\n",
       "         'update': 7802,\n",
       "         'fine': 7799,\n",
       "         'path': 7737,\n",
       "         'questions': 7718,\n",
       "         'still': 7652,\n",
       "         'color': 7632,\n",
       "         'log': 7623,\n",
       "         'property': 7587,\n",
       "         'href': 7571,\n",
       "         'lib': 7568,\n",
       "         'point': 7548,\n",
       "         'based': 7544,\n",
       "         'check': 7489,\n",
       "         'information': 7464,\n",
       "         '11': 7426,\n",
       "         '100': 7404,\n",
       "         'tr': 7388,\n",
       "         'default': 7382,\n",
       "         'length': 7381,\n",
       "         'background': 7368,\n",
       "         'command': 7363,\n",
       "         'idea': 7323,\n",
       "         'better': 7294,\n",
       "         'src': 7283,\n",
       "         'print': 7251,\n",
       "         'well': 7248,\n",
       "         'process': 7241,\n",
       "         'wrong': 7185,\n",
       "         'email': 7177,\n",
       "         'window': 7174,\n",
       "         'done': 7132,\n",
       "         '20': 7121,\n",
       "         'someone': 7102,\n",
       "         'control': 7036,\n",
       "         'put': 7028,\n",
       "         'db': 6971,\n",
       "         'current': 6930,\n",
       "         'order': 6921,\n",
       "         'element': 6918,\n",
       "         'every': 6906,\n",
       "         'back': 6885,\n",
       "         'thread': 6885,\n",
       "         'next': 6883,\n",
       "         'action': 6877,\n",
       "         'send': 6861,\n",
       "         'count': 6854,\n",
       "         'top': 6853,\n",
       "         'facebook': 6846,\n",
       "         'password': 6843,\n",
       "         'issue': 6810,\n",
       "         'column': 6768,\n",
       "         'char': 6746,\n",
       "         'got': 6729,\n",
       "         'thank': 6714,\n",
       "         'long': 6667,\n",
       "         'development': 6657,\n",
       "         'variable': 6576,\n",
       "         'ruby': 6563,\n",
       "         'give': 6550,\n",
       "         'already': 6477,\n",
       "         'since': 6422,\n",
       "         'context': 6405,\n",
       "         'multiple': 6382,\n",
       "         'connection': 6346,\n",
       "         'called': 6338,\n",
       "         'format': 6311,\n",
       "         'response': 6309,\n",
       "         'info': 6295,\n",
       "         'png': 6178,\n",
       "         'label': 6125,\n",
       "         'custom': 6116,\n",
       "         'second': 6113,\n",
       "         'lot': 6069,\n",
       "         'stack': 6026,\n",
       "         'software': 6014,\n",
       "         'say': 6011,\n",
       "         'iphone': 5991,\n",
       "         'store': 5968,\n",
       "         'position': 5960,\n",
       "         'instead': 5947,\n",
       "         'ajax': 5903,\n",
       "         'enter': 5889,\n",
       "         'address': 5826,\n",
       "         'inside': 5822,\n",
       "         'part': 5815,\n",
       "         'node': 5812,\n",
       "         'directory': 5804,\n",
       "         'understand': 5800,\n",
       "         'currently': 5795,\n",
       "         'ui': 5773,\n",
       "         'appreciated': 5770,\n",
       "         'microsoft': 5758,\n",
       "         'insert': 5742,\n",
       "         'body': 5735,\n",
       "         'local': 5718,\n",
       "         'bit': 5701,\n",
       "         'login': 5662,\n",
       "         'screen': 5644,\n",
       "         'anything': 5640,\n",
       "         'save': 5638,\n",
       "         'things': 5635,\n",
       "         'double': 5627,\n",
       "         'may': 5620,\n",
       "         'eclipse': 5616,\n",
       "         '15': 5607,\n",
       "         'results': 5604,\n",
       "         'map': 5594,\n",
       "         'nbsp': 5593,\n",
       "         'support': 5568,\n",
       "         'location': 5557,\n",
       "         'linux': 5516,\n",
       "         'items': 5502,\n",
       "         'last': 5449,\n",
       "         'browser': 5438,\n",
       "         'creating': 5402,\n",
       "         'instance': 5401,\n",
       "         'json': 5389,\n",
       "         'objects': 5365,\n",
       "         'specific': 5362,\n",
       "         'take': 5353,\n",
       "         'box': 5351,\n",
       "         'going': 5331,\n",
       "         'let': 5321,\n",
       "         'look': 5320,\n",
       "         'tell': 5311,\n",
       "         'rails': 5252,\n",
       "         'close': 5243,\n",
       "         'v': 5231,\n",
       "         'core': 5225,\n",
       "         'username': 5224,\n",
       "         'thing': 5214,\n",
       "         'memory': 5208,\n",
       "         'via': 5176,\n",
       "         'install': 5157,\n",
       "         'must': 5155,\n",
       "         'description': 5134,\n",
       "         'ideas': 5133,\n",
       "         'seem': 5126,\n",
       "         'rows': 5126,\n",
       "         'game': 5121,\n",
       "         'convert': 5115,\n",
       "         'menu': 5109,\n",
       "         'folder': 5108,\n",
       "         'home': 5093,\n",
       "         'correct': 5089,\n",
       "         'within': 5037,\n",
       "         '2011': 5021,\n",
       "         'header': 5006,\n",
       "         'catch': 4991,\n",
       "         'reference': 4983,\n",
       "         'people': 4978,\n",
       "         'font': 4959,\n",
       "         'debug': 4953,\n",
       "         'design': 4950,\n",
       "         'loop': 4949,\n",
       "         'given': 4941,\n",
       "         'stackoverflow': 4930,\n",
       "         'controller': 4908,\n",
       "         'implement': 4896,\n",
       "         'mvc': 4886,\n",
       "         'answer': 4874,\n",
       "         'learn': 4872,\n",
       "         'around': 4849,\n",
       "         '30': 4845,\n",
       "         'os': 4817,\n",
       "         'span': 4811,\n",
       "         'domain': 4795,\n",
       "         'connect': 4791,\n",
       "         'developer': 4775,\n",
       "         '01': 4763,\n",
       "         'similar': 4759,\n",
       "         'always': 4754,\n",
       "         'delete': 4748,\n",
       "         'classes': 4741,\n",
       "         'session': 4736,\n",
       "         'book': 4733,\n",
       "         'root': 4726,\n",
       "         'contains': 4721,\n",
       "         'remove': 4711,\n",
       "         'single': 4706,\n",
       "         'visual': 4699,\n",
       "         'video': 4673,\n",
       "         'template': 4662,\n",
       "         'tag': 4644,\n",
       "         'everything': 4636,\n",
       "         'img': 4625,\n",
       "         'free': 4613,\n",
       "         'device': 4607,\n",
       "         'side': 4591,\n",
       "         'options': 4584,\n",
       "         'layout': 4563,\n",
       "         'l': 4551,\n",
       "         'methods': 4526,\n",
       "         'available': 4510,\n",
       "         'console': 4505,\n",
       "         'far': 4504,\n",
       "         'usr': 4491,\n",
       "         'float': 4473,\n",
       "         'break': 4472,\n",
       "         'activity': 4470,\n",
       "         'pages': 4465,\n",
       "         'plugin': 4453,\n",
       "         'returns': 4444,\n",
       "         'interface': 4434,\n",
       "         '16': 4430,\n",
       "         'added': 4427,\n",
       "         'k': 4425,\n",
       "         'wondering': 4412,\n",
       "         'looks': 4395,\n",
       "         'block': 4382,\n",
       "         'config': 4376,\n",
       "         'std': 4376,\n",
       "         '2010': 4355,\n",
       "         'pass': 4351,\n",
       "         'println': 4351,\n",
       "         'fields': 4344,\n",
       "         'lang': 4339,\n",
       "         'w': 4334,\n",
       "         'parent': 4293,\n",
       "         'level': 4282,\n",
       "         'product': 4265,\n",
       "         'security': 4258,\n",
       "         'uses': 4247,\n",
       "         'functions': 4232,\n",
       "         'group': 4229,\n",
       "         'status': 4225,\n",
       "         'made': 4221,\n",
       "         'tables': 4208,\n",
       "         '2012': 4204,\n",
       "         'yes': 4200,\n",
       "         'bar': 4195,\n",
       "         'writing': 4178,\n",
       "         'base': 4173,\n",
       "         'errors': 4159,\n",
       "         'projects': 4154,\n",
       "         'none': 4151,\n",
       "         'download': 4142,\n",
       "         'integer': 4133,\n",
       "         'submit': 4121,\n",
       "         '14': 4111,\n",
       "         'const': 4105,\n",
       "         'state': 4102,\n",
       "         'tostring': 4094,\n",
       "         'missing': 4086,\n",
       "         'account': 4084,\n",
       "         'might': 4051,\n",
       "         'edit': 4047,\n",
       "         'actually': 4037,\n",
       "         'kind': 4034,\n",
       "         'selected': 4029,\n",
       "         'foo': 4012,\n",
       "         'internal': 3998,\n",
       "         'studio': 3992,\n",
       "         'nothing': 3981,\n",
       "         'word': 3971,\n",
       "         'jpg': 3969,\n",
       "         'final': 3954,\n",
       "         'copy': 3932,\n",
       "         'handle': 3928,\n",
       "         '50': 3918,\n",
       "         'sun': 3899,\n",
       "         'phone': 3879,\n",
       "         'reason': 3875,\n",
       "         'installed': 3872,\n",
       "         'empty': 3863,\n",
       "         'head': 3858,\n",
       "         'sort': 3858,\n",
       "         'required': 3855,\n",
       "         'def': 3855,\n",
       "         'keep': 3854,\n",
       "         'ul': 3847,\n",
       "         'place': 3841,\n",
       "         'applications': 3838,\n",
       "         'us': 3835,\n",
       "         'changes': 3826,\n",
       "         'figure': 3813,\n",
       "         'problems': 3812,\n",
       "         'elements': 3809,\n",
       "         'basic': 3787,\n",
       "         'machine': 3774,\n",
       "         'https': 3754,\n",
       "         'grid': 3751,\n",
       "         'vs': 3742,\n",
       "         'execute': 3731,\n",
       "         'u': 3721,\n",
       "         'ok': 3718,\n",
       "         'package': 3717,\n",
       "         'either': 3708,\n",
       "         'override': 3707,\n",
       "         'im': 3700,\n",
       "         'gems': 3691,\n",
       "         '07': 3691,\n",
       "         'ie': 3689,\n",
       "         'small': 3684,\n",
       "         'module': 3680,\n",
       "         'computer': 3678,\n",
       "         'cell': 3675,\n",
       "         'maybe': 3675,\n",
       "         'suggestions': 3671,\n",
       "         'tools': 3666,\n",
       "         'mobile': 3664,\n",
       "         'border': 3656,\n",
       "         'sample': 3653,\n",
       "         'allow': 3636,\n",
       "         'upload': 3634,\n",
       "         'intent': 3634,\n",
       "         'ip': 3633,\n",
       "         'configuration': 3625,\n",
       "         'alert': 3622,\n",
       "         'properties': 3621,\n",
       "         'written': 3619,\n",
       "         'making': 3586,\n",
       "         'started': 3585,\n",
       "         'host': 3583,\n",
       "         'apps': 3580,\n",
       "         '13': 3558,\n",
       "         'auto': 3557,\n",
       "         'non': 3554,\n",
       "         'generated': 3549,\n",
       "         'parameters': 3549,\n",
       "         'reading': 3547,\n",
       "         'dll': 3539,\n",
       "         'z': 3535,\n",
       "         'columns': 3527,\n",
       "         'company': 3523,\n",
       "         'txt': 3513,\n",
       "         'learning': 3513,\n",
       "         'resources': 3509,\n",
       "         'statement': 3505,\n",
       "         'task': 3504,\n",
       "         'pre': 3501,\n",
       "         'times': 3492,\n",
       "         'shows': 3481,\n",
       "         'provide': 3481,\n",
       "         'center': 3465,\n",
       "         'day': 3455,\n",
       "         '04': 3454,\n",
       "         'books': 3452,\n",
       "         'stuff': 3447,\n",
       "         'services': 3446,\n",
       "         'large': 3444,\n",
       "         'experience': 3440,\n",
       "         'links': 3429,\n",
       "         'ios': 3428,\n",
       "         'filter': 3427,\n",
       "         'needs': 3427,\n",
       "         'mean': 3415,\n",
       "         'move': 3415,\n",
       "         '02': 3411,\n",
       "         'pdf': 3409,\n",
       "         'printf': 3408,\n",
       "         'little': 3402,\n",
       "         'great': 3400,\n",
       "         'performance': 3400,\n",
       "         'target': 3400,\n",
       "         'rb': 3390,\n",
       "         'settings': 3383,\n",
       "         'tool': 3375,\n",
       "         'never': 3372,\n",
       "         'parameter': 3369,\n",
       "         'adding': 3367,\n",
       "         'gets': 3364,\n",
       "         'boolean': 3355,\n",
       "         'failed': 3353,\n",
       "         'setting': 3352,\n",
       "         'network': 3352,\n",
       "         'numbers': 3335,\n",
       "         'lines': 3329,\n",
       "         'stored': 3327,\n",
       "         'setup': 3324,\n",
       "         'easy': 3319,\n",
       "         'mail': 3307,\n",
       "         'en': 3305,\n",
       "         'replace': 3303,\n",
       "         '25': 3303,\n",
       "         'entity': 3294,\n",
       "         'note': 3290,\n",
       "         'basically': 3288,\n",
       "         'release': 3284,\n",
       "         'join': 3277,\n",
       "         'mode': 3274,\n",
       "         'variables': 3271,\n",
       "         'dialog': 3271,\n",
       "         'init': 3263,\n",
       "         'sub': 3259,\n",
       "         'jar': 3243,\n",
       "         'several': 3237,\n",
       "         'django': 3230,\n",
       "         'aspx': 3229,\n",
       "         'developing': 3221,\n",
       "         '06': 3220,\n",
       "         'record': 3211,\n",
       "         'real': 3208,\n",
       "         'port': 3208,\n",
       "         'fix': 3205,\n",
       "         'syntax': 3196,\n",
       "         'tab': 3192,\n",
       "         'generate': 3188,\n",
       "         'bin': 3184,\n",
       "         'engine': 3183,\n",
       "         'springframework': 3181,\n",
       "         'cout': 3173,\n",
       "         'admin': 3164,\n",
       "         'servlet': 3147,\n",
       "         'structure': 3138,\n",
       "         'though': 3131,\n",
       "         'suggest': 3128,\n",
       "         'dev': 3127,\n",
       "         'hello': 3108,\n",
       "         'year': 3098,\n",
       "         'full': 3094,\n",
       "         'stop': 3084,\n",
       "         '09': 3073,\n",
       "         'testing': 3072,\n",
       "         'byte': 3071,\n",
       "         'frame': 3062,\n",
       "         'implementation': 3043,\n",
       "         '17': 3042,\n",
       "         'internet': 3041,\n",
       "         'examples': 3034,\n",
       "         'solve': 3033,\n",
       "         'q': 3032,\n",
       "         'random': 3025,\n",
       "         'imgur': 3023,\n",
       "         'total': 3023,\n",
       "         'append': 3021,\n",
       "         'match': 3019,\n",
       "         'defined': 3019,\n",
       "         'androidruntime': 3016,\n",
       "         'clear': 3006,\n",
       "         'javax': 2998,\n",
       "         'nsstring': 2995,\n",
       "         'come': 2984,\n",
       "         'xmlns': 2983,\n",
       "         '_post': 2983,\n",
       "         'certain': 2978,\n",
       "         'quite': 2971,\n",
       "         '22': 2965,\n",
       "         'temp': 2959,\n",
       "         '05': 2958,\n",
       "         'job': 2951,\n",
       "         '21': 2951,\n",
       "         'loading': 2950,\n",
       "         'bool': 2945,\n",
       "         'person': 2944,\n",
       "         '19': 2942,\n",
       "         'parse': 2935,\n",
       "         'related': 2933,\n",
       "         'approach': 2932,\n",
       "         'define': 2924,\n",
       "         'pattern': 2919,\n",
       "         'ask': 2918,\n",
       "         'flash': 2914,\n",
       "         'thought': 2907,\n",
       "         'invoke': 2907,\n",
       "         'rather': 2899,\n",
       "         'environment': 2898,\n",
       "         'hibernate': 2887,\n",
       "         'val': 2881,\n",
       "         'mac': 2881,\n",
       "         'whether': 2880,\n",
       "         'names': 2878,\n",
       "         'develop': 2867,\n",
       "         'documentation': 2866,\n",
       "         '18': 2863,\n",
       "         'localhost': 2860,\n",
       "         'details': 2859,\n",
       "         'child': 2855,\n",
       "         '2008': 2854,\n",
       "         'standard': 2851,\n",
       "         'filename': 2849,\n",
       "         '_': 2847,\n",
       "         'explain': 2846,\n",
       "         'io': 2846,\n",
       "         'margin': 2844,\n",
       "         'ubuntu': 2842,\n",
       "         'git': 2841,\n",
       "         'namespace': 2839,\n",
       "         'correctly': 2831,\n",
       "         'difference': 2825,\n",
       "         'attribute': 2823,\n",
       "         'common': 2822,\n",
       "         'algorithm': 2819,\n",
       "         'super': 2817,\n",
       "         'anybody': 2812,\n",
       "         'exe': 2809,\n",
       "         'particular': 2807,\n",
       "         'features': 2802,\n",
       "         'changed': 2801,\n",
       "         'pretty': 2799,\n",
       "         'online': 2793,\n",
       "         'models': 2788,\n",
       "         'play': 2788,\n",
       "         'cache': 2787,\n",
       "         'protected': 2785,\n",
       "         'param': 2780,\n",
       "         'types': 2778,\n",
       "         'step': 2773,\n",
       "         'dont': 2770,\n",
       "         'forms': 2770,\n",
       "         'compile': 2766,\n",
       "         'old': 2759,\n",
       "         'yet': 2758,\n",
       "         'warning': 2744,\n",
       "         'space': 2744,\n",
       "         'building': 2739,\n",
       "         'category': 2738,\n",
       "         'player': 2731,\n",
       "         'foreach': 2728,\n",
       "         'util': 2724,\n",
       "         'seen': 2723,\n",
       "         'bundle': 2718,\n",
       "         'spring': 2711,\n",
       "         'unable': 2710,\n",
       "         'tags': 2709,\n",
       "         'big': 2706,\n",
       "         'languages': 2702,\n",
       "         'buttons': 2701,\n",
       "         'virtual': 2693,\n",
       "         'section': 2684,\n",
       "         'vector': 2675,\n",
       "         'three': 2671,\n",
       "         'hidden': 2669,\n",
       "         '03': 2664,\n",
       "         'nil': 2661,\n",
       "         'makes': 2658,\n",
       "         'platform': 2657,\n",
       "         'native': 2655,\n",
       "         'per': 2654,\n",
       "         'textview': 2652,\n",
       "         'characters': 2650,\n",
       "         'thinking': 2649,\n",
       "         'checked': 2646,\n",
       "         'dynamic': 2646,\n",
       "         '32': 2645,\n",
       "         'binding': 2642,\n",
       "         'gives': 2641,\n",
       "         'stream': 2632,\n",
       "         'socket': 2628,\n",
       "         'handler': 2625,\n",
       "         'th': 2623,\n",
       "         'switch': 2619,\n",
       "         'events': 2618,\n",
       "         'expression': 2617,\n",
       "         'component': 2616,\n",
       "         'records': 2614,\n",
       "         'course': 2612,\n",
       "         'automatically': 2606,\n",
       "         'py': 2602,\n",
       "         'existing': 2598,\n",
       "         'buffer': 2598,\n",
       "         'widget': 2597,\n",
       "         'share': 2596,\n",
       "         'takes': 2593,\n",
       "         'bottom': 2591,\n",
       "         'struct': 2585,\n",
       "         'tutorial': 2583,\n",
       "         'expected': 2578,\n",
       "         'resource': 2573,\n",
       "         'hard': 2572,\n",
       "         'container': 2565,\n",
       "         'firefox': 2564,\n",
       "         '31': 2561,\n",
       "         'obj': 2557,\n",
       "         'chrome': 2550,\n",
       "         'comment': 2550,\n",
       "         'extends': 2549,\n",
       "         'remote': 2549,\n",
       "         'world': 2548,\n",
       "         'args': 2547,\n",
       "         'whole': 2546,\n",
       "         'messages': 2543,\n",
       "         'desktop': 2534,\n",
       "         'wordpress': 2531,\n",
       "         'controls': 2531,\n",
       "         'issues': 2530,\n",
       "         'range': 2525,\n",
       "         'textbox': 2524,\n",
       "         'normal': 2519,\n",
       "         'begin': 2517,\n",
       "         'lt': 2516,\n",
       "         'str': 2514,\n",
       "         'sender': 2512,\n",
       "         'starting': 2510,\n",
       "         'editor': 2508,\n",
       "         'amount': 2508,\n",
       "         'report': 2503,\n",
       "         'complete': 2502,\n",
       "         'simply': 2499,\n",
       "         'excel': 2496,\n",
       "         'onclick': 2495,\n",
       "         'enough': 2494,\n",
       "         'loaded': 2492,\n",
       "         'collection': 2489,\n",
       "         'feature': 2489,\n",
       "         'alloc': 2487,\n",
       "         'days': 2484,\n",
       "         'max': 2483,\n",
       "         'bad': 2483,\n",
       "         'says': 2482,\n",
       "         'calls': 2480,\n",
       "         'bytes': 2475,\n",
       "         'sdk': 2471,\n",
       "         'views': 2457,\n",
       "         '08': 2457,\n",
       "         'utf': 2454,\n",
       "         'require': 2440,\n",
       "         'character': 2439,\n",
       "         'jboss': 2424,\n",
       "         'pointer': 2420,\n",
       "         'libraries': 2419,\n",
       "         '23': 2406,\n",
       "         'oracle': 2404,\n",
       "         'means': 2403,\n",
       "         'apple': 2401,\n",
       "         'points': 2399,\n",
       "         'needed': 2396,\n",
       "         'entry': 2392,\n",
       "         'ms': 2389,\n",
       "         'modules': 2381,\n",
       "         'datetime': 2378,\n",
       "         'exists': 2372,\n",
       "         '24': 2371,\n",
       "         'align': 2368,\n",
       "         'encoding': 2364,\n",
       "         'runtime': 2364,\n",
       "         'success': 2363,\n",
       "         'achieve': 2362,\n",
       "         'words': 2358,\n",
       "         'functionality': 2358,\n",
       "         'wanted': 2350,\n",
       "         'properly': 2349,\n",
       "         'external': 2346,\n",
       "         'built': 2334,\n",
       "         'less': 2333,\n",
       "         'price': 2331,\n",
       "         'math': 2324,\n",
       "         'developers': 2316,\n",
       "         'sites': 2316,\n",
       "         'drop': 2310,\n",
       "         'calling': 2310,\n",
       "         'month': 2308,\n",
       "         'showing': 2294,\n",
       "         'unknown': 2290,\n",
       "         'exist': 2282,\n",
       "         'hide': 2279,\n",
       "         'tree': 2279,\n",
       "         'advice': 2273,\n",
       "         'frameworks': 2263,\n",
       "         'cpp': 2261,\n",
       "         'hi': 2260,\n",
       "         'compiler': 2260,\n",
       "         'padding': 2257,\n",
       "         'exit': 2252,\n",
       "         'regards': 2245,\n",
       "         'area': 2238,\n",
       "         'valid': 2233,\n",
       "         'probably': 2230,\n",
       "         'xsl': 2224,\n",
       "         'comments': 2221,\n",
       "         'displayed': 2216,\n",
       "         'constructor': 2206,\n",
       "         'blog': 2196,\n",
       "         'coding': 2195,\n",
       "         '200': 2184,\n",
       "         'canvas': 2184,\n",
       "         'runat': 2181,\n",
       "         'draw': 2181,\n",
       "         'wpf': 2179,\n",
       "         'appear': 2175,\n",
       "         '40': 2171,\n",
       "         'exactly': 2171,\n",
       "         'previous': 2170,\n",
       "         'directly': 2167,\n",
       "         'choose': 2166,\n",
       "         'guess': 2162,\n",
       "         'rest': 2160,\n",
       "         'actual': 2156,\n",
       "         'runs': 2154,\n",
       "         'member': 2153,\n",
       "         'sum': 2153,\n",
       "         'years': 2147,\n",
       "         'linq': 2146,\n",
       "         'extension': 2143,\n",
       "         'sent': 2143,\n",
       "         'general': 2142,\n",
       "         'redirect': 2142,\n",
       "         'endl': 2142,\n",
       "         'ready': 2134,\n",
       "         'active': 2133,\n",
       "         'catalina': 2133,\n",
       "         'maps': 2132,\n",
       "         'goes': 2130,\n",
       "         'push': 2125,\n",
       "         'separate': 2120,\n",
       "         'strings': 2116,\n",
       "         'worked': 2115,\n",
       "         'least': 2115,\n",
       "         'products': 2113,\n",
       "         'comes': 2112,\n",
       "         'customer': 2111,\n",
       "         'cursor': 2109,\n",
       "         'happens': 2105,\n",
       "         'contents': 2100,\n",
       "         'gui': 2089,\n",
       "         'seconds': 2088,\n",
       "         'management': 2080,\n",
       "         'authentication': 2078,\n",
       "         'limit': 2076,\n",
       "         'bind': 2076,\n",
       "         'perl': 2074,\n",
       "         'graph': 2069,\n",
       "         'xcode': 2065,\n",
       "         'arraylist': 2064,\n",
       "         'processing': 2063,\n",
       "         'logic': 2061,\n",
       "         'tests': 2060,\n",
       "         'min': 2057,\n",
       "         'checkbox': 2056,\n",
       "         'recently': 2053,\n",
       "         'panel': 2053,\n",
       "         'undefined': 2050,\n",
       "         'validation': 2045,\n",
       "         '29': 2044,\n",
       "         'appears': 2043,\n",
       "         'article': 2041,\n",
       "         'icon': 2041,\n",
       "         'contain': 2030,\n",
       "         'split': 2029,\n",
       "         'dim': 2029,\n",
       "         'guys': 2027,\n",
       "         'jsp': 2026,\n",
       "         'original': 2022,\n",
       "         'hope': 2021,\n",
       "         'hours': 2021,\n",
       "         'global': 2019,\n",
       "         'live': 2015,\n",
       "         'unit': 2005,\n",
       "         'ex': 2004,\n",
       "         'except': 1993,\n",
       "         '80': 1990,\n",
       "         'feel': 1987,\n",
       "         'shared': 1983,\n",
       "         'visible': 1971,\n",
       "         'appreciate': 1962,\n",
       "         'getelementbyid': 1960,\n",
       "         'across': 1957,\n",
       "         'dynamically': 1955,\n",
       "         'primary': 1955,\n",
       "         'nice': 1954,\n",
       "         'tutorials': 1951,\n",
       "         'media': 1947,\n",
       "         'profile': 1945,\n",
       "         'regex': 1943,\n",
       "         'posts': 1937,\n",
       "         'useful': 1935,\n",
       "         'docs': 1933,\n",
       "         'assembly': 1932,\n",
       "         '1000': 1932,\n",
       "         'others': 1924,\n",
       "         'repository': 1922,\n",
       "         'documents': 1922,\n",
       "         'pc': 1920,\n",
       "         '26': 1920,\n",
       "         'render': 1918,\n",
       "         'bean': 1912,\n",
       "         'retrieve': 1909,\n",
       "         'high': 1909,\n",
       "         'avoid': 1908,\n",
       "         'invalid': 1900,\n",
       "         'team': 1898,\n",
       "         'operator': 1897,\n",
       "         'picture': 1896,\n",
       "         'contact': 1894,\n",
       "         'vb': 1888,\n",
       "         'keys': 1887,\n",
       "         'boost': 1887,\n",
       "         ...})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa035858",
   "metadata": {},
   "source": [
    "# Bag of Words, Its Matrix and showing Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0bfb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Matrix Shape: (140272, 10000)\n",
      "Sample BoW representation:\n",
      "   00  000  0000  000000  00000000  0000000000000000  00000001  0000ff  0001  \\\n",
      "0   0    0     0       0         0                 0         0       0     0   \n",
      "1   0    0     0       0         0                 0         0       0     0   \n",
      "2   0    0     0       0         0                 0         0       0     0   \n",
      "3   0    0     0       0         0                 0         0       0     0   \n",
      "4   0    0     0       0         0                 0         0       0     0   \n",
      "\n",
      "   001  ...  zlib  zombie  zone  zones  zoom  zooming  zsoa  zurich  \\\n",
      "0    0  ...     0       0     0      0     0        0     0       0   \n",
      "1    0  ...     0       0     0      0     0        0     0       0   \n",
      "2    0  ...     0       0     0      0     0        0     0       0   \n",
      "3    0  ...     0       0     0      0     0        0     0       0   \n",
      "4    0  ...     0       0     0      0     0        0     0       0   \n",
      "\n",
      "   zygoteinit  âldapobjectâ  \n",
      "0           0             0  \n",
      "1           0             0  \n",
      "2           0             0  \n",
      "3           0             0  \n",
      "4           0             0  \n",
      "\n",
      "[5 rows x 10000 columns]\n",
      "Sparsity: 99.61%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import ast\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\tokens_sample_train.csv\")\n",
    "def string_text(tokens):\n",
    "    tokens=ast.literal_eval(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text']=df[\"tokens\"].apply(string_text)\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_bow = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "bow_df = pd.DataFrame(X_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print shape of BoW matrix\n",
    "print(f\"BoW Matrix Shape: {bow_df.shape}\")\n",
    "\n",
    "# Print sample BoW features\n",
    "print(\"Sample BoW representation:\")\n",
    "print(bow_df.head())\n",
    "\n",
    "# Check sparsity (percentage of zeros)\n",
    "sparsity = (bow_df.to_numpy() == 0).sum() / bow_df.size * 100\n",
    "print(f\"Sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366700f3",
   "metadata": {},
   "source": [
    "# TF IDF, Its Matrix and showing Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547f2aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (140272, 10000)\n",
      "Sample TF-IDF representation:\n",
      "    00  000  0000  000000  00000000  0000000000000000  00000001  0000ff  0001  \\\n",
      "0  0.0  0.0   0.0     0.0       0.0               0.0       0.0     0.0   0.0   \n",
      "1  0.0  0.0   0.0     0.0       0.0               0.0       0.0     0.0   0.0   \n",
      "2  0.0  0.0   0.0     0.0       0.0               0.0       0.0     0.0   0.0   \n",
      "3  0.0  0.0   0.0     0.0       0.0               0.0       0.0     0.0   0.0   \n",
      "4  0.0  0.0   0.0     0.0       0.0               0.0       0.0     0.0   0.0   \n",
      "\n",
      "   001  ...  zlib  zombie  zone  zones  zoom  zooming  zsoa  zurich  \\\n",
      "0  0.0  ...   0.0     0.0   0.0    0.0   0.0      0.0   0.0     0.0   \n",
      "1  0.0  ...   0.0     0.0   0.0    0.0   0.0      0.0   0.0     0.0   \n",
      "2  0.0  ...   0.0     0.0   0.0    0.0   0.0      0.0   0.0     0.0   \n",
      "3  0.0  ...   0.0     0.0   0.0    0.0   0.0      0.0   0.0     0.0   \n",
      "4  0.0  ...   0.0     0.0   0.0    0.0   0.0      0.0   0.0     0.0   \n",
      "\n",
      "   zygoteinit  âldapobjectâ  \n",
      "0         0.0           0.0  \n",
      "1         0.0           0.0  \n",
      "2         0.0           0.0  \n",
      "3         0.0           0.0  \n",
      "4         0.0           0.0  \n",
      "\n",
      "[5 rows x 10000 columns]\n",
      "Sparsity: 99.61%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import ast\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\tokens_sample_train.csv\")\n",
    "def string_text(tokens):\n",
    "    tokens=ast.literal_eval(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text']=df[\"tokens\"].apply(string_text)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Print shape of TF-IDF matrix\n",
    "print(f\"TF-IDF Matrix Shape: {tfidf_df.shape}\")\n",
    "\n",
    "# Print sample TF-IDF representation\n",
    "print(\"Sample TF-IDF representation:\")\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Check sparsity (percentage of zeros)\n",
    "sparsity = (tfidf_df.to_numpy() == 0).sum() / tfidf_df.size * 100\n",
    "print(f\"Sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344d976",
   "metadata": {},
   "source": [
    "# TFIDF AND BAG OF WORDS MULTICLASS CLASSIFICATION Using 10000 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "423ca58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Logistic Regression Accuracy: 0.6334\n",
      "Saved 10286 TF-IDF misclassified cases to 'misclassified_tfidf_logistic.csv'\n",
      "\n",
      "BoW Logistic Regression Accuracy: 0.5915\n",
      "Saved 11461 BoW misclassified cases to 'misclassified_bow_logistic.csv'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\tokens_sample_train.csv\")\n",
    "\n",
    "# Convert token lists to strings\n",
    "def string_text(tokens):\n",
    "    tokens = ast.literal_eval(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df[\"tokens\"].apply(string_text)\n",
    "\n",
    "# Vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_features=10000)\n",
    "X_bow = bow_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "y = df[\"OpenStatus\"]  \n",
    "\n",
    "# Split once for both models\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test, df_train, df_test = train_test_split(\n",
    "    X_tfidf, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_bow, X_test_bow, _, _, _, _ = train_test_split(\n",
    "    X_bow, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------- TF-IDF Logistic Regression --------------------\n",
    "log_reg_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = log_reg_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"\\nTF-IDF Logistic Regression Accuracy: {accuracy_tfidf:.4f}\")\n",
    "\n",
    "# Save misclassifications (TF-IDF)\n",
    "misclassified_tfidf = []\n",
    "\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_tfidf, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_tfidf.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\")\n",
    "        })\n",
    "\n",
    "misclassified_df_tfidf = pd.DataFrame(misclassified_tfidf)\n",
    "misclassified_df_tfidf.to_csv(\"misclassified_tfidf_logistic.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_df_tfidf)} TF-IDF misclassified cases to 'misclassified_tfidf_logistic.csv'\")\n",
    "\n",
    "\n",
    "# -------------------- BoW Logistic Regression --------------------\n",
    "log_reg_bow = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow = log_reg_bow.predict(X_test_bow)\n",
    "\n",
    "accuracy_bow = accuracy_score(y_test, y_pred_bow)\n",
    "print(f\"\\nBoW Logistic Regression Accuracy: {accuracy_bow:.4f}\")\n",
    "\n",
    "# Save misclassifications (BoW)\n",
    "misclassified_bow = []\n",
    "\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_bow, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_bow.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\")\n",
    "        })\n",
    "\n",
    "misclassified_df_bow = pd.DataFrame(misclassified_bow)\n",
    "misclassified_df_bow.to_csv(\"misclassified_bow_logistic.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_df_bow)} BoW misclassified cases to 'misclassified_bow_logistic.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db181e3",
   "metadata": {},
   "source": [
    "# TFIDF AND BAG OF WORDS MULTICLASS CLASSIFICATION Using All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23e50fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Logistic Regression Accuracy: 0.6327\n",
      "Saved 10306 TF-IDF misclassified cases to 'misclassified_tfidf_logistic.csv'\n",
      "\n",
      "BoW Logistic Regression Accuracy: 0.5889\n",
      "Saved 11533 BoW misclassified cases to 'misclassified_bow_logistic.csv'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\tokens_sample_train.csv\")\n",
    "\n",
    "# Convert token lists to strings\n",
    "def string_text(tokens):\n",
    "    tokens = ast.literal_eval(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df[\"tokens\"].apply(string_text)\n",
    "\n",
    "# Vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_bow = bow_vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "y = df[\"OpenStatus\"]  \n",
    "\n",
    "# Split once for both models\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test, df_train, df_test = train_test_split(\n",
    "    X_tfidf, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_bow, X_test_bow, _, _, _, _ = train_test_split(\n",
    "    X_bow, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------- TF-IDF Logistic Regression --------------------\n",
    "log_reg_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = log_reg_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"\\nTF-IDF Logistic Regression Accuracy: {accuracy_tfidf:.4f}\")\n",
    "\n",
    "# Save misclassifications (TF-IDF)\n",
    "misclassified_tfidf = []\n",
    "\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_tfidf, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_tfidf.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\")\n",
    "        })\n",
    "\n",
    "misclassified_df_tfidf = pd.DataFrame(misclassified_tfidf)\n",
    "misclassified_df_tfidf.to_csv(\"misclassified_tfidf_logistic_multi_all.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_df_tfidf)} TF-IDF misclassified cases to 'misclassified_tfidf_logistic.csv'\")\n",
    "\n",
    "\n",
    "# -------------------- BoW Logistic Regression --------------------\n",
    "log_reg_bow = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow = log_reg_bow.predict(X_test_bow)\n",
    "\n",
    "accuracy_bow = accuracy_score(y_test, y_pred_bow)\n",
    "print(f\"\\nBoW Logistic Regression Accuracy: {accuracy_bow:.4f}\")\n",
    "\n",
    "# Save misclassifications (BoW)\n",
    "misclassified_bow = []\n",
    "\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_bow, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_bow.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\")\n",
    "        })\n",
    "\n",
    "misclassified_df_bow = pd.DataFrame(misclassified_bow)\n",
    "misclassified_df_bow.to_csv(\"misclassified_bow_logistic_multi_all.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_df_bow)} BoW misclassified cases to 'misclassified_bow_logistic.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa03f4",
   "metadata": {},
   "source": [
    "# TFIDF AND BAG OF WORDS BINARY CLASSIFICATION Using 10000 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "093f2b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression Accuracy: 0.7400\n",
      "Saved 7294 misclassified TF-IDF samples.\n",
      "BoW Logistic Regression Accuracy: 0.7203\n",
      "Saved 7848 misclassified BoW samples.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\tokens_sample_train.csv\")\n",
    "\n",
    "# Convert tokens from string to space-separated string\n",
    "def string_text(tokens):\n",
    "    tokens = ast.literal_eval(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['tokens'].apply(string_text)\n",
    "\n",
    "# Binary target: OpenStatus (open vs closed)\n",
    "df['OpenStatus_binary'] = df['OpenStatus'].apply(lambda x: 1 if x == 'open' else 0)\n",
    "y = df['OpenStatus_binary']\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# BoW vectorization\n",
    "bow_vectorizer = CountVectorizer(max_features=10000)\n",
    "X_bow = bow_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Train-test split\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test, df_train, df_test = train_test_split(\n",
    "    X_tfidf, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_bow, X_test_bow, _, _, _, _ = train_test_split(\n",
    "    X_bow, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------- TF-IDF Logistic Regression --------------------\n",
    "log_reg_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = log_reg_tfidf.predict(X_test_tfidf)\n",
    "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"TF-IDF Logistic Regression Accuracy: {acc_tfidf:.4f}\")\n",
    "\n",
    "# Misclassifications\n",
    "misclassified_tfidf = []\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_tfidf, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_tfidf.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\")\n",
    "        })\n",
    "\n",
    "pd.DataFrame(misclassified_tfidf).to_csv(\"misclassified_tfidf_binary.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_tfidf)} misclassified TF-IDF samples.\")\n",
    "\n",
    "\n",
    "# -------------------- BoW Logistic Regression --------------------\n",
    "log_reg_bow = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow = log_reg_bow.predict(X_test_bow)\n",
    "acc_bow = accuracy_score(y_test, y_pred_bow)\n",
    "print(f\"BoW Logistic Regression Accuracy: {acc_bow:.4f}\")\n",
    "\n",
    "# Misclassifications\n",
    "misclassified_bow = []\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_bow, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_bow.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\")\n",
    "        })\n",
    "\n",
    "pd.DataFrame(misclassified_bow).to_csv(\"misclassified_bow_binary.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_bow)} misclassified BoW samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd3be9",
   "metadata": {},
   "source": [
    "# TFIDF AND BAG OF WORDS BINARY CLASSIFICATION Using ALL Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5da9f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression Accuracy: 0.7351\n",
      "Saved 7433 misclassified TF-IDF samples.\n",
      "BoW Logistic Regression Accuracy: 0.7148\n",
      "Saved 8001 misclassified BoW samples.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\tokens_sample_train.csv\")\n",
    "\n",
    "# Convert tokens from string to space-separated text\n",
    "def string_text(tokens):\n",
    "    tokens = ast.literal_eval(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['tokens'].apply(string_text)\n",
    "\n",
    "# Binary target: OpenStatus (open = 1, else = 0)\n",
    "df['OpenStatus_binary'] = df['OpenStatus'].apply(lambda x: 1 if x == 'open' else 0)\n",
    "y = df['OpenStatus_binary']\n",
    "\n",
    "# Vectorize without limiting features\n",
    "tfidf_vectorizer = TfidfVectorizer()  # Removed max_features\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "bow_vectorizer = CountVectorizer()  # Removed max_features\n",
    "X_bow = bow_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Train-test split\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test, df_train, df_test = train_test_split(\n",
    "    X_tfidf, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_bow, X_test_bow, _, _, _, _ = train_test_split(\n",
    "    X_bow, y, df, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------- TF-IDF Logistic Regression --------------------\n",
    "log_reg_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = log_reg_tfidf.predict(X_test_tfidf)\n",
    "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"TF-IDF Logistic Regression Accuracy: {acc_tfidf:.4f}\")\n",
    "\n",
    "# Save TF-IDF Misclassifications\n",
    "misclassified_tfidf = []\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_tfidf, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_tfidf.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\")\n",
    "        })\n",
    "\n",
    "pd.DataFrame(misclassified_tfidf).to_csv(\"misclassified_tfidf_binary_all_features.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_tfidf)} misclassified TF-IDF samples.\")\n",
    "\n",
    "# -------------------- BoW Logistic Regression --------------------\n",
    "log_reg_bow = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_bow.fit(X_train_bow, y_train)\n",
    "y_pred_bow = log_reg_bow.predict(X_test_bow)\n",
    "acc_bow = accuracy_score(y_test, y_pred_bow)\n",
    "print(f\"BoW Logistic Regression Accuracy: {acc_bow:.4f}\")\n",
    "\n",
    "# Save BoW Misclassifications\n",
    "misclassified_bow = []\n",
    "for idx, (pred, actual) in enumerate(zip(y_pred_bow, y_test)):\n",
    "    if pred != actual:\n",
    "        row = df_test.iloc[idx]\n",
    "        misclassified_bow.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row.get(\"Title\", \"\"),\n",
    "            \"BodyMarkdown\": row.get(\"BodyMarkdown\", \"\"),\n",
    "            \"Tags_combined\": row.get(\"Tags_combined\", \"\"),\n",
    "            \"CodeSnippets\": row.get(\"CodeSnippets\", \"\")\n",
    "        })\n",
    "\n",
    "pd.DataFrame(misclassified_bow).to_csv(\"misclassified_bow_binary_all_features.csv\", index=False)\n",
    "print(f\"Saved {len(misclassified_bow)} misclassified BoW samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b97106",
   "metadata": {},
   "source": [
    "# WORD2VEC CBOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95326f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Download nltk tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\train-sample.csv\\train-sample.csv\")  # Adjust filename if needed\n",
    "\n",
    "# Combine Title & BodyMarkdown\n",
    "df[\"text\"] = df[\"Title\"].fillna(\"\") + \" \" + df[\"BodyMarkdown\"].fillna(\"\")\n",
    "\n",
    "# Text Cleaning Function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"tokens\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Train Word2Vec (CBOW)\n",
    "cbow_model = Word2Vec(sentences=df[\"tokens\"], vector_size=100, window=5, min_count=5, workers=4, sg=0)\n",
    "\n",
    "# Save Model\n",
    "cbow_model.save(\"cbow_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bf411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar words to 'python':\n",
      "[('perl', 0.7874644994735718), ('haskell', 0.7107198238372803), ('ruby', 0.667743980884552), ('django', 0.6568008065223694), ('ironpython', 0.611203670501709), ('erlang', 0.6092310547828674), ('lisp', 0.5984227657318115), ('sphinx', 0.5979190468788147), ('bash', 0.5974279642105103), ('ror', 0.5974060893058777)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 similar words to 'python':\")\n",
    "print(cbow_model.wv.most_similar(\"python\", topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca228114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_embeddings(model, words):\n",
    "    word_vectors = np.array([model.wv[word] for word in words])  # Convert to NumPy array\n",
    "    tsne = TSNE(n_components=2, perplexity=min(len(words) - 1, 5), random_state=42)  # Reduce perplexity\n",
    "    word_vectors_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, word in enumerate(words):\n",
    "        plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1])\n",
    "        plt.annotate(word, (word_vectors_2d[i, 0], word_vectors_2d[i, 1]))\n",
    "    plt.title(\"Word2Vec CBOW Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "# Try plotting again\n",
    "selected_words = [\"python\", \"java\", \"php\", \"javascript\", \"django\", \"numpy\", \"flask\"]\n",
    "plot_embeddings(cbow_model, selected_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a24aa",
   "metadata": {},
   "source": [
    "# WORD2VEC SKIPGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b127a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_model = Word2Vec(sentences=df[\"tokens\"], vector_size=100, window=5, min_count=5, workers=4, sg=1)\n",
    "skipgram_model.save(\"skipgram_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8644d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_embeddings(model, words):\n",
    "    word_vectors = np.array([model.wv[word] for word in words])  # Convert to NumPy array\n",
    "    tsne = TSNE(n_components=2, perplexity=min(len(words) - 1, 5), random_state=42)  # Reduce perplexity\n",
    "    word_vectors_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, word in enumerate(words):\n",
    "        plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1])\n",
    "        plt.annotate(word, (word_vectors_2d[i, 0], word_vectors_2d[i, 1]))\n",
    "    plt.title(\"Word2Vec SkipGram Visualization\")\n",
    "    plt.show()\n",
    "plot_embeddings(skipgram_model, selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e470d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sample_train_tokens_with_stop_words.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a05ab",
   "metadata": {},
   "source": [
    "# WORD2VEC CBOW AND SKIPGRAM BINARY CLASSIFICATION USING NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0219c6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with CBOW Accuracy: 0.6808412047763323\n",
      "Naive Bayes with Skip-gram Accuracy: 0.6806629834254143\n",
      "\n",
      "Classification Report (CBOW):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.65     14117\n",
      "           1       0.65      0.78      0.71     13938\n",
      "\n",
      "    accuracy                           0.68     28055\n",
      "   macro avg       0.69      0.68      0.68     28055\n",
      "weighted avg       0.69      0.68      0.68     28055\n",
      "\n",
      "\n",
      "Classification Report (Skip-gram):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.64     14117\n",
      "           1       0.65      0.79      0.71     13938\n",
      "\n",
      "    accuracy                           0.68     28055\n",
      "   macro avg       0.69      0.68      0.68     28055\n",
      "weighted avg       0.69      0.68      0.68     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load pre-trained CBOW & Skip-gram models\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "skipgram_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\skipgram_model.model\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\sample_train_tokens_with_stop_words.csv\")  # Adjust filename if needed\n",
    "\n",
    "# Combine Title & BodyMarkdown\n",
    "df[\"text\"] = df[\"Title\"].fillna(\"\") + \" \" + df[\"BodyMarkdown\"].fillna(\"\")\n",
    "\n",
    "# Convert OpenStatus (target variable) to binary labels\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "\n",
    "# Text Preprocessing (Tokenization)\n",
    "def preprocess_text(text):\n",
    "    return text.lower().split()  # Simple whitespace-based tokenization\n",
    "\n",
    "df[\"tokens\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Function to compute document embeddings by averaging word vectors\n",
    "def get_sentence_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if len(vectors) > 0 else np.zeros(model.vector_size)\n",
    "\n",
    "# Create features using CBOW embeddings\n",
    "X_cbow = np.array([get_sentence_vector(tokens, cbow_model) for tokens in df[\"tokens\"]])\n",
    "\n",
    "# Create features using Skip-gram embeddings\n",
    "X_skipgram = np.array([get_sentence_vector(tokens, skipgram_model) for tokens in df[\"tokens\"]])\n",
    "\n",
    "# Target labels\n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into train & test sets\n",
    "X_cbow_train, X_cbow_test, y_train, y_test = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n",
    "X_skipgram_train, X_skipgram_test, _, _ = train_test_split(X_skipgram, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes Classifier on CBOW\n",
    "nb_cbow = GaussianNB()\n",
    "nb_cbow.fit(X_cbow_train, y_train)\n",
    "y_pred_cbow = nb_cbow.predict(X_cbow_test)\n",
    "\n",
    "# Train Naive Bayes Classifier on Skip-gram\n",
    "nb_skipgram = GaussianNB()\n",
    "nb_skipgram.fit(X_skipgram_train, y_train)\n",
    "y_pred_skipgram = nb_skipgram.predict(X_skipgram_test)\n",
    "\n",
    "# Evaluate Performance\n",
    "print(\"Naive Bayes with CBOW Accuracy:\", accuracy_score(y_test, y_pred_cbow))\n",
    "print(\"Naive Bayes with Skip-gram Accuracy:\", accuracy_score(y_test, y_pred_skipgram))\n",
    "\n",
    "print(\"\\nClassification Report (CBOW):\")\n",
    "print(classification_report(y_test, y_pred_cbow))\n",
    "\n",
    "print(\"\\nClassification Report (Skip-gram):\")\n",
    "print(classification_report(y_test, y_pred_skipgram))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06fb8ef",
   "metadata": {},
   "source": [
    "# WORD2VEC CBOW AND SKIPGRAM BINARY CLASSIFICATION USING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with CBOW Accuracy: 0.7159151666369631\n",
      "\n",
      "Classification Report (CBOW - Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71     14117\n",
      "           1       0.70      0.74      0.72     13938\n",
      "\n",
      "    accuracy                           0.72     28055\n",
      "   macro avg       0.72      0.72      0.72     28055\n",
      "weighted avg       0.72      0.72      0.72     28055\n",
      "\n",
      "Logistic Regression with Skip-gram Accuracy: 0.7217251826768847\n",
      "\n",
      "Classification Report (Skip-gram - Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     14117\n",
      "           1       0.71      0.75      0.73     13938\n",
      "\n",
      "    accuracy                           0.72     28055\n",
      "   macro avg       0.72      0.72      0.72     28055\n",
      "weighted avg       0.72      0.72      0.72     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting Data\n",
    "X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n",
    "X_train_skipgram, X_test_skipgram, _, _ = train_test_split(X_skipgram, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_cbow = LogisticRegression(max_iter=1000)\n",
    "logreg_cbow.fit(X_train_cbow, y_train)\n",
    "y_pred_cbow_logreg = logreg_cbow.predict(X_test_cbow)\n",
    "print(\"Logistic Regression with CBOW Accuracy:\", accuracy_score(y_test, y_pred_cbow_logreg))\n",
    "print(\"\\nClassification Report (CBOW - Logistic Regression):\\n\", classification_report(y_test, y_pred_cbow_logreg))\n",
    "\n",
    "logreg_skipgram = LogisticRegression(max_iter=1000)\n",
    "logreg_skipgram.fit(X_train_skipgram, y_train)\n",
    "y_pred_skipgram_logreg = logreg_skipgram.predict(X_test_skipgram)\n",
    "print(\"Logistic Regression with Skip-gram Accuracy:\", accuracy_score(y_test, y_pred_skipgram_logreg))\n",
    "print(\"\\nClassification Report (Skip-gram - Logistic Regression):\\n\", classification_report(y_test, y_pred_skipgram_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6f621",
   "metadata": {},
   "source": [
    "#  WORD2VEC CBOW AND SKIPGRAM MULTICLASS CLASSIFICATION USING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b02c02a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression (CBOW) ---\n",
      "Accuracy: 0.6168240955266441\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "not a real question       0.55      0.34      0.42      6196\n",
      "   not constructive       0.56      0.53      0.55      3110\n",
      "          off topic       0.55      0.39      0.46      3563\n",
      "               open       0.65      0.87      0.74     13938\n",
      "      too localized       0.32      0.02      0.03      1248\n",
      "\n",
      "           accuracy                           0.62     28055\n",
      "          macro avg       0.53      0.43      0.44     28055\n",
      "       weighted avg       0.59      0.62      0.58     28055\n",
      "\n",
      "\n",
      "--- Logistic Regression (Skip-gram) ---\n",
      "Accuracy: 0.6197825699518802\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "not a real question       0.54      0.34      0.42      6196\n",
      "   not constructive       0.57      0.53      0.55      3110\n",
      "          off topic       0.56      0.41      0.47      3563\n",
      "               open       0.65      0.87      0.75     13938\n",
      "      too localized       0.31      0.01      0.03      1248\n",
      "\n",
      "           accuracy                           0.62     28055\n",
      "          macro avg       0.53      0.43      0.44     28055\n",
      "       weighted avg       0.59      0.62      0.59     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load pre-trained CBOW & Skip-gram models\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "skipgram_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\skipgram_model.model\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\sample_train_tokens_with_stop_words.csv\")\n",
    "\n",
    "# Combine Title & BodyMarkdown\n",
    "df[\"text\"] = df[\"Title\"].fillna(\"\") + \" \" + df[\"BodyMarkdown\"].fillna(\"\")\n",
    "\n",
    "# Keep OpenStatus as is for multiclass\n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "df[\"tokens\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Create sentence vectors\n",
    "def get_sentence_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "X_cbow = np.array([get_sentence_vector(tokens, cbow_model) for tokens in df[\"tokens\"]])\n",
    "X_skipgram = np.array([get_sentence_vector(tokens, skipgram_model) for tokens in df[\"tokens\"]])\n",
    "\n",
    "# Train-Test Split\n",
    "X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n",
    "X_train_skipgram, X_test_skipgram, _, _ = train_test_split(X_skipgram, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------- CBOW Logistic Regression ----------------\n",
    "logreg_cbow = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "logreg_cbow.fit(X_train_cbow, y_train)\n",
    "y_pred_cbow = logreg_cbow.predict(X_test_cbow)\n",
    "\n",
    "print(\"\\n--- Logistic Regression (CBOW) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_cbow))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_cbow))\n",
    "\n",
    "# ---------------- Skip-gram Logistic Regression ----------------\n",
    "logreg_skipgram = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "logreg_skipgram.fit(X_train_skipgram, y_train)\n",
    "y_pred_skipgram = logreg_skipgram.predict(X_test_skipgram)\n",
    "\n",
    "print(\"\\n--- Logistic Regression (Skip-gram) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_skipgram))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_skipgram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce901627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edab664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656ce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6073857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62029026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473bb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dc22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418e809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b33e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302feca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6f4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adae231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897a109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8527bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c635a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a62f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ad40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c860b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9244556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\sample_train_tokens_with_stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df9c4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PostId</th>\n",
       "      <th>PostCreationDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>OwnerCreationDate</th>\n",
       "      <th>ReputationAtPostCreation</th>\n",
       "      <th>OwnerUndeletedAnswerCountAtPostTime</th>\n",
       "      <th>Title</th>\n",
       "      <th>BodyMarkdown</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>PostClosedDate</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6046168</td>\n",
       "      <td>05/18/2011 14:14:05</td>\n",
       "      <td>543315</td>\n",
       "      <td>09/17/2010 10:15:06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>I am building a corpus of indexed sentences in...</td>\n",
       "      <td>mongodb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>['for', 'mongodb', 'is', 'it', 'better', 'to',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4873911</td>\n",
       "      <td>02/02/2011 11:30:10</td>\n",
       "      <td>465076</td>\n",
       "      <td>10/03/2010 09:30:58</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>i create a xml document with JAXP and search a...</td>\n",
       "      <td>dom</td>\n",
       "      <td>xsd</td>\n",
       "      <td>jaxp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>['how', 'to', 'insert', 'schemalocation', 'in'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3311559</td>\n",
       "      <td>07/22/2010 17:21:54</td>\n",
       "      <td>406143</td>\n",
       "      <td>07/22/2010 16:58:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Too many lookup tables</td>\n",
       "      <td>What are the adverse effects of having too man...</td>\n",
       "      <td>sql-server</td>\n",
       "      <td>database-design</td>\n",
       "      <td>enums</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "      <td>['too', 'many', 'lookup', 'tables', 'what', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9990413</td>\n",
       "      <td>04/03/2012 09:18:39</td>\n",
       "      <td>851755</td>\n",
       "      <td>07/19/2011 10:22:40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>What is this PHP code in VB.net</td>\n",
       "      <td>I am looking for the vb.net equivalent of this...</td>\n",
       "      <td>php</td>\n",
       "      <td>vb.net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/15/2012 21:12:48</td>\n",
       "      <td>too localized</td>\n",
       "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
       "      <td>['what', 'is', 'this', 'php', 'code', 'in', 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10421966</td>\n",
       "      <td>05/02/2012 21:25:01</td>\n",
       "      <td>603588</td>\n",
       "      <td>02/04/2011 18:05:34</td>\n",
       "      <td>334</td>\n",
       "      <td>14</td>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>With Spring-Data, you can use the @Document an...</td>\n",
       "      <td>mongodb</td>\n",
       "      <td>spring-data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>['spring', 'data', 'mongodb', 'querying', 'mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>140267</td>\n",
       "      <td>2982729</td>\n",
       "      <td>06/06/2010 01:03:41</td>\n",
       "      <td>8303</td>\n",
       "      <td>09/15/2008 15:40:08</td>\n",
       "      <td>520</td>\n",
       "      <td>34</td>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>I am facing a rather peculiar problem. I am wo...</td>\n",
       "      <td>bitwise-operators</td>\n",
       "      <td>discrete-mathematics</td>\n",
       "      <td>compiler-optimization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>['is', 'it', 'possible', 'to', 'implement', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>140268</td>\n",
       "      <td>8809105</td>\n",
       "      <td>01/10/2012 19:13:53</td>\n",
       "      <td>1130251</td>\n",
       "      <td>01/04/2012 15:31:10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>I have the following installed:\\r\\nMac Os 10.7...</td>\n",
       "      <td>mysql</td>\n",
       "      <td>ruby-on-rails</td>\n",
       "      <td>gem</td>\n",
       "      <td>osx-lion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>['ruby', 'on', 'rails', 'mysql', 'gem', 'does'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>140269</td>\n",
       "      <td>10674791</td>\n",
       "      <td>05/20/2012 15:36:31</td>\n",
       "      <td>1388595</td>\n",
       "      <td>05/11/2012 04:43:47</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>deleting image from image folder</td>\n",
       "      <td>I am working with an asp.net application.I wan...</td>\n",
       "      <td>asp.net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/21/2012 21:21:27</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>deleting image from image folder I am working ...</td>\n",
       "      <td>['deleting', 'image', 'from', 'image', 'folder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>140270</td>\n",
       "      <td>3997045</td>\n",
       "      <td>10/22/2010 13:04:30</td>\n",
       "      <td>484232</td>\n",
       "      <td>10/22/2010 13:04:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Need help making HTML's</td>\n",
       "      <td>Hi to all the gurus out there.\\r\\n\\r\\nAnybody ...</td>\n",
       "      <td>html</td>\n",
       "      <td>copy</td>\n",
       "      <td>remove</td>\n",
       "      <td>move</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/22/2010 13:10:28</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>Need help making HTML's Hi to all the gurus ou...</td>\n",
       "      <td>['need', 'help', 'making', 'html', 's', 'hi', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>140271</td>\n",
       "      <td>11570849</td>\n",
       "      <td>07/19/2012 23:36:57</td>\n",
       "      <td>1539253</td>\n",
       "      <td>07/19/2012 22:17:04</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>Following on from a question I asked about esc...</td>\n",
       "      <td>php</td>\n",
       "      <td>content-management-system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>['how', 'dangerous', 'is', 'it', 'to', 'output...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140272 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    PostId     PostCreationDate  OwnerUserId  \\\n",
       "0                0   6046168  05/18/2011 14:14:05       543315   \n",
       "1                1   4873911  02/02/2011 11:30:10       465076   \n",
       "2                2   3311559  07/22/2010 17:21:54       406143   \n",
       "3                3   9990413  04/03/2012 09:18:39       851755   \n",
       "4                4  10421966  05/02/2012 21:25:01       603588   \n",
       "...            ...       ...                  ...          ...   \n",
       "140267      140267   2982729  06/06/2010 01:03:41         8303   \n",
       "140268      140268   8809105  01/10/2012 19:13:53      1130251   \n",
       "140269      140269  10674791  05/20/2012 15:36:31      1388595   \n",
       "140270      140270   3997045  10/22/2010 13:04:30       484232   \n",
       "140271      140271  11570849  07/19/2012 23:36:57      1539253   \n",
       "\n",
       "          OwnerCreationDate  ReputationAtPostCreation  \\\n",
       "0       09/17/2010 10:15:06                         1   \n",
       "1       10/03/2010 09:30:58                       192   \n",
       "2       07/22/2010 16:58:20                         1   \n",
       "3       07/19/2011 10:22:40                         4   \n",
       "4       02/04/2011 18:05:34                       334   \n",
       "...                     ...                       ...   \n",
       "140267  09/15/2008 15:40:08                       520   \n",
       "140268  01/04/2012 15:31:10                         1   \n",
       "140269  05/11/2012 04:43:47                         4   \n",
       "140270  10/22/2010 13:04:30                         1   \n",
       "140271  07/19/2012 22:17:04                         3   \n",
       "\n",
       "        OwnerUndeletedAnswerCountAtPostTime  \\\n",
       "0                                         2   \n",
       "1                                        24   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                        14   \n",
       "...                                     ...   \n",
       "140267                                   34   \n",
       "140268                                    0   \n",
       "140269                                    0   \n",
       "140270                                    0   \n",
       "140271                                    1   \n",
       "\n",
       "                                                    Title  \\\n",
       "0       For Mongodb is it better to reference an objec...   \n",
       "1       How to insert schemalocation in a xml document...   \n",
       "2                                 Too many lookup tables    \n",
       "3                         What is this PHP code in VB.net   \n",
       "4       Spring-Data mongodb querying multiple classes ...   \n",
       "...                                                   ...   \n",
       "140267  Is it possible to implement bitwise operators ...   \n",
       "140268  Ruby on Rails: MySql Gem does not work: uninit...   \n",
       "140269                   deleting image from image folder   \n",
       "140270                            Need help making HTML's   \n",
       "140271  How dangerous is it to output certain content ...   \n",
       "\n",
       "                                             BodyMarkdown               Tag1  \\\n",
       "0       I am building a corpus of indexed sentences in...            mongodb   \n",
       "1       i create a xml document with JAXP and search a...                dom   \n",
       "2       What are the adverse effects of having too man...         sql-server   \n",
       "3       I am looking for the vb.net equivalent of this...                php   \n",
       "4       With Spring-Data, you can use the @Document an...            mongodb   \n",
       "...                                                   ...                ...   \n",
       "140267  I am facing a rather peculiar problem. I am wo...  bitwise-operators   \n",
       "140268  I have the following installed:\\r\\nMac Os 10.7...              mysql   \n",
       "140269  I am working with an asp.net application.I wan...            asp.net   \n",
       "140270  Hi to all the gurus out there.\\r\\n\\r\\nAnybody ...               html   \n",
       "140271  Following on from a question I asked about esc...                php   \n",
       "\n",
       "                             Tag2                   Tag3      Tag4 Tag5  \\\n",
       "0                             NaN                    NaN       NaN  NaN   \n",
       "1                             xsd                   jaxp       NaN  NaN   \n",
       "2                 database-design                  enums       NaN  NaN   \n",
       "3                          vb.net                    NaN       NaN  NaN   \n",
       "4                     spring-data                    NaN       NaN  NaN   \n",
       "...                           ...                    ...       ...  ...   \n",
       "140267       discrete-mathematics  compiler-optimization       NaN  NaN   \n",
       "140268              ruby-on-rails                    gem  osx-lion  NaN   \n",
       "140269                        NaN                    NaN       NaN  NaN   \n",
       "140270                       copy                 remove      move  NaN   \n",
       "140271  content-management-system                    NaN       NaN  NaN   \n",
       "\n",
       "             PostClosedDate           OpenStatus  \\\n",
       "0                       NaN                 open   \n",
       "1                       NaN                 open   \n",
       "2                       NaN                 open   \n",
       "3       04/15/2012 21:12:48        too localized   \n",
       "4                       NaN                 open   \n",
       "...                     ...                  ...   \n",
       "140267                  NaN                 open   \n",
       "140268                  NaN                 open   \n",
       "140269  05/21/2012 21:21:27  not a real question   \n",
       "140270  10/22/2010 13:10:28  not a real question   \n",
       "140271                  NaN                 open   \n",
       "\n",
       "                                                     text  \\\n",
       "0       For Mongodb is it better to reference an objec...   \n",
       "1       How to insert schemalocation in a xml document...   \n",
       "2       Too many lookup tables  What are the adverse e...   \n",
       "3       What is this PHP code in VB.net I am looking f...   \n",
       "4       Spring-Data mongodb querying multiple classes ...   \n",
       "...                                                   ...   \n",
       "140267  Is it possible to implement bitwise operators ...   \n",
       "140268  Ruby on Rails: MySql Gem does not work: uninit...   \n",
       "140269  deleting image from image folder I am working ...   \n",
       "140270  Need help making HTML's Hi to all the gurus ou...   \n",
       "140271  How dangerous is it to output certain content ...   \n",
       "\n",
       "                                                   tokens  \n",
       "0       ['for', 'mongodb', 'is', 'it', 'better', 'to',...  \n",
       "1       ['how', 'to', 'insert', 'schemalocation', 'in'...  \n",
       "2       ['too', 'many', 'lookup', 'tables', 'what', 'a...  \n",
       "3       ['what', 'is', 'this', 'php', 'code', 'in', 'v...  \n",
       "4       ['spring', 'data', 'mongodb', 'querying', 'mul...  \n",
       "...                                                   ...  \n",
       "140267  ['is', 'it', 'possible', 'to', 'implement', 'b...  \n",
       "140268  ['ruby', 'on', 'rails', 'mysql', 'gem', 'does'...  \n",
       "140269  ['deleting', 'image', 'from', 'image', 'folder...  \n",
       "140270  ['need', 'help', 'making', 'html', 's', 'hi', ...  \n",
       "140271  ['how', 'dangerous', 'is', 'it', 'to', 'output...  \n",
       "\n",
       "[140272 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5cf351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['open', 'too localized', 'not a real question', 'off topic',\n",
       "       'not constructive'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.OpenStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1521969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_4216\\1536407353.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.OpenStatus[(df.OpenStatus=='too localized') | (df.OpenStatus=='not a real question') | (df.OpenStatus=='off topic') | (df.OpenStatus=='not constructive')]='closed'\n"
     ]
    }
   ],
   "source": [
    "df.OpenStatus[(df.OpenStatus=='too localized') | (df.OpenStatus=='not a real question') | (df.OpenStatus=='off topic') | (df.OpenStatus=='not constructive')]='closed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b033da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289ea56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"OpenStatus\"]=df[\"OpenStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e995c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"text\"]=df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a3dd67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['for', 'mongodb', 'is', 'it', 'better', 'to',...</td>\n",
       "      <td>open</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['how', 'to', 'insert', 'schemalocation', 'in'...</td>\n",
       "      <td>open</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['too', 'many', 'lookup', 'tables', 'what', 'a...</td>\n",
       "      <td>open</td>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['what', 'is', 'this', 'php', 'code', 'in', 'v...</td>\n",
       "      <td>too localized</td>\n",
       "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['spring', 'data', 'mongodb', 'querying', 'mul...</td>\n",
       "      <td>open</td>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>['is', 'it', 'possible', 'to', 'implement', 'b...</td>\n",
       "      <td>open</td>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>['ruby', 'on', 'rails', 'mysql', 'gem', 'does'...</td>\n",
       "      <td>open</td>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>['deleting', 'image', 'from', 'image', 'folder...</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>deleting image from image folder I am working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>['need', 'help', 'making', 'html', 's', 'hi', ...</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>Need help making HTML's Hi to all the gurus ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>['how', 'dangerous', 'is', 'it', 'to', 'output...</td>\n",
       "      <td>open</td>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  \\\n",
       "0       ['for', 'mongodb', 'is', 'it', 'better', 'to',...   \n",
       "1       ['how', 'to', 'insert', 'schemalocation', 'in'...   \n",
       "2       ['too', 'many', 'lookup', 'tables', 'what', 'a...   \n",
       "3       ['what', 'is', 'this', 'php', 'code', 'in', 'v...   \n",
       "4       ['spring', 'data', 'mongodb', 'querying', 'mul...   \n",
       "...                                                   ...   \n",
       "140267  ['is', 'it', 'possible', 'to', 'implement', 'b...   \n",
       "140268  ['ruby', 'on', 'rails', 'mysql', 'gem', 'does'...   \n",
       "140269  ['deleting', 'image', 'from', 'image', 'folder...   \n",
       "140270  ['need', 'help', 'making', 'html', 's', 'hi', ...   \n",
       "140271  ['how', 'dangerous', 'is', 'it', 'to', 'output...   \n",
       "\n",
       "                 OpenStatus                                               text  \n",
       "0                      open  For Mongodb is it better to reference an objec...  \n",
       "1                      open  How to insert schemalocation in a xml document...  \n",
       "2                      open  Too many lookup tables  What are the adverse e...  \n",
       "3             too localized  What is this PHP code in VB.net I am looking f...  \n",
       "4                      open  Spring-Data mongodb querying multiple classes ...  \n",
       "...                     ...                                                ...  \n",
       "140267                 open  Is it possible to implement bitwise operators ...  \n",
       "140268                 open  Ruby on Rails: MySql Gem does not work: uninit...  \n",
       "140269  not a real question  deleting image from image folder I am working ...  \n",
       "140270  not a real question  Need help making HTML's Hi to all the gurus ou...  \n",
       "140271                 open  How dangerous is it to output certain content ...  \n",
       "\n",
       "[140272 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97723b1",
   "metadata": {},
   "source": [
    "# WORD2VEC and try checking outputs manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ee67d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with CBOW Accuracy: 0.7155230796649439\n",
      "\n",
      "Classification Report (CBOW - Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71     14117\n",
      "           1       0.70      0.74      0.72     13938\n",
      "\n",
      "    accuracy                           0.72     28055\n",
      "   macro avg       0.72      0.72      0.72     28055\n",
      "weighted avg       0.72      0.72      0.72     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "def token(tokens):\n",
    "    tokens=ast.literal_eval(tokens)\n",
    "    return tokens\n",
    "\n",
    "df1[\"tokens\"] = df1[\"tokens\"].apply(token)\n",
    "\n",
    "df1[\"OpenStatus\"] = df1[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "\n",
    "# Function to compute document embeddings by averaging word vectors\n",
    "def get_sentence_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if len(vectors) > 0 else np.zeros(model.vector_size)\n",
    "\n",
    "X_cbow = np.array([get_sentence_vector(tokens, cbow_model) for tokens in df1[\"tokens\"]])\n",
    "y = df1[\"OpenStatus\"].values\n",
    "\n",
    "X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg_cbow = LogisticRegression(max_iter=1000)\n",
    "logreg_cbow.fit(X_train_cbow, y_train)\n",
    "y_pred_cbow_logreg = logreg_cbow.predict(X_test_cbow)\n",
    "print(\"Logistic Regression with CBOW Accuracy:\", accuracy_score(y_test, y_pred_cbow_logreg))\n",
    "print(\"\\nClassification Report (CBOW - Logistic Regression):\\n\", classification_report(y_test, y_pred_cbow_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea0ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19673407, -1.1496948 , -0.47109905, ...,  0.92122823,\n",
       "         0.76633984,  0.27517998],\n",
       "       [ 0.21567418, -0.17525965, -0.34893471, ...,  0.39837804,\n",
       "         0.1116984 , -0.10287862],\n",
       "       [ 1.41653335, -0.78492308, -0.19359712, ...,  1.31419539,\n",
       "         0.95551556,  0.07127993],\n",
       "       ...,\n",
       "       [ 0.34200075, -0.59714407, -0.14165327, ...,  0.39085832,\n",
       "         0.24077801,  0.25004232],\n",
       "       [ 0.60892373, -0.68792725, -0.05876273, ...,  0.88152093,\n",
       "         0.78955704,  0.3427099 ],\n",
       "       [ 0.58660024, -0.58383334, -0.03596966, ...,  0.90438801,\n",
       "         0.78233969,  0.09160873]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a59ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"There is a syntax error in my python code print('he'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a02aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n"
     ]
    }
   ],
   "source": [
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "tokens = sentence.lower().split() \n",
    "sentence_vector = get_sentence_vector(tokens, cbow_model).reshape(1, -1)\n",
    "pred=logreg_cbow.predict(sentence_vector)\n",
    "if pred[0]==1:\n",
    "    print(\"Open\")\n",
    "else:\n",
    "    print(\"Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee69cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[df1.OpenStatus==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06286ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_open= np.array([get_sentence_vector(tokens, cbow_model) for tokens in df2[\"tokens\"]])\n",
    "pred=logreg_cbow.predict(test_open)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e6ff9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12340\\2382551189.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"Pred\"]=pred\n"
     ]
    }
   ],
   "source": [
    "df2[\"Pred\"]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef1d79bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[for, mongodb, is, it, better, to, reference, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, to, insert, schemalocation, in, a, xml, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[too, many, lookup, tables, what, are, the, ad...</td>\n",
       "      <td>1</td>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[spring, data, mongodb, querying, multiple, cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[stop, ajax, function, in, midway, when, other...</td>\n",
       "      <td>1</td>\n",
       "      <td>stop ajax function in midway when other elemen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140264</th>\n",
       "      <td>[automated, typing, of, words, fed, through, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Automated typing of words fed through text/csv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140265</th>\n",
       "      <td>[how, to, check, unicode, string, to, be, lett...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to check unicode string to be letters, spa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>[is, it, possible, to, implement, bitwise, ope...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>[ruby, on, rails, mysql, gem, does, not, work,...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>[how, dangerous, is, it, to, output, certain, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  OpenStatus  \\\n",
       "0       [for, mongodb, is, it, better, to, reference, ...           1   \n",
       "1       [how, to, insert, schemalocation, in, a, xml, ...           1   \n",
       "2       [too, many, lookup, tables, what, are, the, ad...           1   \n",
       "4       [spring, data, mongodb, querying, multiple, cl...           1   \n",
       "5       [stop, ajax, function, in, midway, when, other...           1   \n",
       "...                                                   ...         ...   \n",
       "140264  [automated, typing, of, words, fed, through, t...           1   \n",
       "140265  [how, to, check, unicode, string, to, be, lett...           1   \n",
       "140267  [is, it, possible, to, implement, bitwise, ope...           1   \n",
       "140268  [ruby, on, rails, mysql, gem, does, not, work,...           1   \n",
       "140271  [how, dangerous, is, it, to, output, certain, ...           1   \n",
       "\n",
       "                                                     text  Pred  \n",
       "0       For Mongodb is it better to reference an objec...     0  \n",
       "1       How to insert schemalocation in a xml document...     1  \n",
       "2       Too many lookup tables  What are the adverse e...     0  \n",
       "4       Spring-Data mongodb querying multiple classes ...     1  \n",
       "5       stop ajax function in midway when other elemen...     1  \n",
       "...                                                   ...   ...  \n",
       "140264  Automated typing of words fed through text/csv...     0  \n",
       "140265  How to check unicode string to be letters, spa...     0  \n",
       "140267  Is it possible to implement bitwise operators ...     1  \n",
       "140268  Ruby on Rails: MySql Gem does not work: uninit...     1  \n",
       "140271  How dangerous is it to output certain content ...     1  \n",
       "\n",
       "[70136 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ecefefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df2[df2[\"Pred\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b5fe989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[for, mongodb, is, it, better, to, reference, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[too, many, lookup, tables, what, are, the, ad...</td>\n",
       "      <td>1</td>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[in, gef, bendpoints, how, can, i, retrieve, p...</td>\n",
       "      <td>1</td>\n",
       "      <td>In GEF bendpoints, how can i retrieve point fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[how, can, a, windows, phone, 7, application, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>How can a Windows Phone 7 application register...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[micro, cloud, foundry, sinatra, hello, world,...</td>\n",
       "      <td>1</td>\n",
       "      <td>Micro Cloud Foundry Sinatra Hello world applic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140250</th>\n",
       "      <td>[summing, integers, recursive, with, java, i, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summing integers recursive with Java. I have t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140259</th>\n",
       "      <td>[javascript, can, t, find, element, by, id, ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>Javascript can't find element by id?     &lt;html...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140260</th>\n",
       "      <td>[how, to, create, internet, explorer, sidebar,...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to create Internet Explorer sidebar extens...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140264</th>\n",
       "      <td>[automated, typing, of, words, fed, through, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Automated typing of words fed through text/csv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140265</th>\n",
       "      <td>[how, to, check, unicode, string, to, be, lett...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to check unicode string to be letters, spa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17996 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  OpenStatus  \\\n",
       "0       [for, mongodb, is, it, better, to, reference, ...           1   \n",
       "2       [too, many, lookup, tables, what, are, the, ad...           1   \n",
       "10      [in, gef, bendpoints, how, can, i, retrieve, p...           1   \n",
       "20      [how, can, a, windows, phone, 7, application, ...           1   \n",
       "25      [micro, cloud, foundry, sinatra, hello, world,...           1   \n",
       "...                                                   ...         ...   \n",
       "140250  [summing, integers, recursive, with, java, i, ...           1   \n",
       "140259  [javascript, can, t, find, element, by, id, ht...           1   \n",
       "140260  [how, to, create, internet, explorer, sidebar,...           1   \n",
       "140264  [automated, typing, of, words, fed, through, t...           1   \n",
       "140265  [how, to, check, unicode, string, to, be, lett...           1   \n",
       "\n",
       "                                                     text  Pred  \n",
       "0       For Mongodb is it better to reference an objec...     0  \n",
       "2       Too many lookup tables  What are the adverse e...     0  \n",
       "10      In GEF bendpoints, how can i retrieve point fr...     0  \n",
       "20      How can a Windows Phone 7 application register...     0  \n",
       "25      Micro Cloud Foundry Sinatra Hello world applic...     0  \n",
       "...                                                   ...   ...  \n",
       "140250  Summing integers recursive with Java. I have t...     0  \n",
       "140259  Javascript can't find element by id?     <html...     0  \n",
       "140260  How to create Internet Explorer sidebar extens...     0  \n",
       "140264  Automated typing of words fed through text/csv...     0  \n",
       "140265  How to check unicode string to be letters, spa...     0  \n",
       "\n",
       "[17996 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c7a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"False Prediction of Open.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df86b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df2[df2[\"Pred\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90f612b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"True Prediction of Open.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3d2b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, to, insert, schemalocation, in, a, xml, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[spring, data, mongodb, querying, multiple, cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[stop, ajax, function, in, midway, when, other...</td>\n",
       "      <td>1</td>\n",
       "      <td>stop ajax function in midway when other elemen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[regex, to, detect, javascript, in, a, string,...</td>\n",
       "      <td>1</td>\n",
       "      <td>Regex to detect Javascript In a string I am tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[how, to, write, shellextension, contextmenuit...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to write shellextension contextmenuitem in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140253</th>\n",
       "      <td>[hiding, inherited, members, in, c, i, m, look...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hiding inherited members in C# I'm looking for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140254</th>\n",
       "      <td>[dropdown, dont, show, correct, parent, div, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>dropdown dont show correct(parent div has over...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>[is, it, possible, to, implement, bitwise, ope...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>[ruby, on, rails, mysql, gem, does, not, work,...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>[how, dangerous, is, it, to, output, certain, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  OpenStatus  \\\n",
       "1       [how, to, insert, schemalocation, in, a, xml, ...           1   \n",
       "4       [spring, data, mongodb, querying, multiple, cl...           1   \n",
       "5       [stop, ajax, function, in, midway, when, other...           1   \n",
       "6       [regex, to, detect, javascript, in, a, string,...           1   \n",
       "12      [how, to, write, shellextension, contextmenuit...           1   \n",
       "...                                                   ...         ...   \n",
       "140253  [hiding, inherited, members, in, c, i, m, look...           1   \n",
       "140254  [dropdown, dont, show, correct, parent, div, h...           1   \n",
       "140267  [is, it, possible, to, implement, bitwise, ope...           1   \n",
       "140268  [ruby, on, rails, mysql, gem, does, not, work,...           1   \n",
       "140271  [how, dangerous, is, it, to, output, certain, ...           1   \n",
       "\n",
       "                                                     text  Pred  \n",
       "1       How to insert schemalocation in a xml document...     1  \n",
       "4       Spring-Data mongodb querying multiple classes ...     1  \n",
       "5       stop ajax function in midway when other elemen...     1  \n",
       "6       Regex to detect Javascript In a string I am tr...     1  \n",
       "12      How to write shellextension contextmenuitem in...     1  \n",
       "...                                                   ...   ...  \n",
       "140253  Hiding inherited members in C# I'm looking for...     1  \n",
       "140254  dropdown dont show correct(parent div has over...     1  \n",
       "140267  Is it possible to implement bitwise operators ...     1  \n",
       "140268  Ruby on Rails: MySql Gem does not work: uninit...     1  \n",
       "140271  How dangerous is it to output certain content ...     1  \n",
       "\n",
       "[52140 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "597bf493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1[df1.OpenStatus==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53a2a6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close= np.array([get_sentence_vector(tokens, cbow_model) for tokens in df3[\"tokens\"]])\n",
    "pred=logreg_cbow.predict(test_close)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbbc5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12340\\3458487816.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3[\"Pred\"]=pred\n"
     ]
    }
   ],
   "source": [
    "df3[\"Pred\"]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19629ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[what, is, this, php, code, in, vb, net, i, am...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[list, of, all, txt, file, i, want, to, write,...</td>\n",
       "      <td>0</td>\n",
       "      <td>List of all .txt file I want to write a progra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[i, want, to, design, an, invitation, card, fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>I want to design an invitation card for my wed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[vb, script, to, delete, header, and, footer, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>VB Script To Delete Header and Footer plus App...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[is, it, possible, to, create, csv, file, with...</td>\n",
       "      <td>0</td>\n",
       "      <td>Is It Possible to Create CSV File with Multipl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140262</th>\n",
       "      <td>[programming, a, microprocessor, im, not, sure...</td>\n",
       "      <td>0</td>\n",
       "      <td>Programming a microprocessor? Im not sure if t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140263</th>\n",
       "      <td>[disable, duplicate, tab, option, or, disable,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Disable Duplicate Tab Option or disable the ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140266</th>\n",
       "      <td>[force, compile, a, java, file, how, would, i,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Force compile a .java file How would I get a ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>[deleting, image, from, image, folder, i, am, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>deleting image from image folder I am working ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>[need, help, making, html, s, hi, to, all, the...</td>\n",
       "      <td>0</td>\n",
       "      <td>Need help making HTML's Hi to all the gurus ou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  OpenStatus  \\\n",
       "3       [what, is, this, php, code, in, vb, net, i, am...           0   \n",
       "7       [list, of, all, txt, file, i, want, to, write,...           0   \n",
       "8       [i, want, to, design, an, invitation, card, fo...           0   \n",
       "9       [vb, script, to, delete, header, and, footer, ...           0   \n",
       "11      [is, it, possible, to, create, csv, file, with...           0   \n",
       "...                                                   ...         ...   \n",
       "140262  [programming, a, microprocessor, im, not, sure...           0   \n",
       "140263  [disable, duplicate, tab, option, or, disable,...           0   \n",
       "140266  [force, compile, a, java, file, how, would, i,...           0   \n",
       "140269  [deleting, image, from, image, folder, i, am, ...           0   \n",
       "140270  [need, help, making, html, s, hi, to, all, the...           0   \n",
       "\n",
       "                                                     text  Pred  \n",
       "3       What is this PHP code in VB.net I am looking f...     0  \n",
       "7       List of all .txt file I want to write a progra...     0  \n",
       "8       I want to design an invitation card for my wed...     0  \n",
       "9       VB Script To Delete Header and Footer plus App...     0  \n",
       "11      Is It Possible to Create CSV File with Multipl...     1  \n",
       "...                                                   ...   ...  \n",
       "140262  Programming a microprocessor? Im not sure if t...     0  \n",
       "140263  Disable Duplicate Tab Option or disable the ta...     0  \n",
       "140266  Force compile a .java file How would I get a ....     0  \n",
       "140269  deleting image from image folder I am working ...     1  \n",
       "140270  Need help making HTML's Hi to all the gurus ou...     1  \n",
       "\n",
       "[70136 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d117c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df3[df3[\"Pred\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df2c7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(\"False Prediction of Close.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65898384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df3[df3[\"Pred\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "873b42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(\"True Prediction of Close.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b76f8e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed\n"
     ]
    }
   ],
   "source": [
    "sentence=\"Who is president of India? get me the python syntax error print('who is president of in\"\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "tokens = sentence.lower().split() \n",
    "sentence_vector = get_sentence_vector(tokens, cbow_model).reshape(1, -1)\n",
    "pred=logreg_cbow.predict(sentence_vector)\n",
    "if pred[0]==1:\n",
    "    print(\"Open\")\n",
    "else:\n",
    "    print(\"Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "159afdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed\n"
     ]
    }
   ],
   "source": [
    "sentence=\"Get me the error in python  here is the c code printf('hel'\"\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "tokens = sentence.lower().split() \n",
    "sentence_vector = get_sentence_vector(tokens, cbow_model).reshape(1, -1)\n",
    "pred=logreg_cbow.predict(sentence_vector)\n",
    "if pred[0]==1:\n",
    "    print(\"Open\")\n",
    "else:\n",
    "    print(\"Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e71172a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed\n"
     ]
    }
   ],
   "source": [
    "sentence=\"There is a syntax error in my java code system.out.println('he' \"\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "tokens = sentence.lower().split() \n",
    "sentence_vector = get_sentence_vector(tokens, cbow_model).reshape(1, -1)\n",
    "pred=logreg_cbow.predict(sentence_vector)\n",
    "if pred[0]==1:\n",
    "    print(\"Open\")\n",
    "else:\n",
    "    print(\"Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e336d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n"
     ]
    }
   ],
   "source": [
    "sentence=\"There is a syntax error in my python code print('he' \"\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "tokens = sentence.lower().split() \n",
    "sentence_vector = get_sentence_vector(tokens, cbow_model).reshape(1, -1)\n",
    "pred=logreg_cbow.predict(sentence_vector)\n",
    "if pred[0]==1:\n",
    "    print(\"Open\")\n",
    "else:\n",
    "    print(\"Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cac17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"There is a syntax error in python code print('he' \"\n",
    "cbow_model = gensim.models.Word2Vec.load(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\cbow_model.model\")\n",
    "tokens = sentence.lower().split() \n",
    "sentence_vector = get_sentence_vector(tokens, cbow_model).reshape(1, -1)\n",
    "pred=logreg_cbow.predict(sentence_vector)\n",
    "if pred[0]==1:\n",
    "    print(\"Open\")\n",
    "else:\n",
    "    print(\"Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b64fd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(logreg_cbow, \"logreg_cbow_model.pkl\")\n",
    "\n",
    "# Load the model\n",
    "logreg_cbow_loaded = joblib.load(\"logreg_cbow_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70aa683",
   "metadata": {},
   "source": [
    "# SBERT TITLE+BODYMARKDOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ab295d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BERT Accuracy: 0.7552307966494386\n",
      "\n",
      "Classification Report (BERT - Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75     14117\n",
      "           1       0.75      0.77      0.76     13938\n",
      "\n",
      "    accuracy                           0.76     28055\n",
      "   macro avg       0.76      0.76      0.76     28055\n",
      "weighted avg       0.76      0.76      0.76     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a pre-trained BERT model for sentence embeddings\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient & good performance\n",
    "\n",
    "# Assume df1 contains our dataset with \"text\" (combined title + body) and \"OpenStatus\"\n",
    "df1[\"OpenStatus\"] = df1[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "\n",
    "# Generate embeddings\n",
    "X_bert = np.array(bert_model.encode(df1[\"text\"].tolist(), convert_to_numpy=True))\n",
    "y = df1[\"OpenStatus\"].values\n",
    "\n",
    "# Split into train & test sets\n",
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(X_bert, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression on BERT embeddings\n",
    "logreg_bert = LogisticRegression(max_iter=1000)\n",
    "logreg_bert.fit(X_train_bert, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_bert = logreg_bert.predict(X_test_bert)\n",
    "\n",
    "print(\"Logistic Regression with BERT Accuracy:\", accuracy_score(y_test, y_pred_bert))\n",
    "print(\"\\nClassification Report (BERT - Logistic Regression):\\n\", classification_report(y_test, y_pred_bert))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9095aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00409021,  0.03848155, -0.08007107, ..., -0.02321486,\n",
       "        -0.037428  ,  0.02332036],\n",
       "       [ 0.06856707, -0.02134919, -0.00139485, ...,  0.05545509,\n",
       "         0.01753581,  0.01420245],\n",
       "       [ 0.01169384, -0.02159495, -0.05384359, ..., -0.04422171,\n",
       "        -0.07098272,  0.07243653],\n",
       "       ...,\n",
       "       [ 0.03182372,  0.00249363, -0.09880762, ...,  0.03707518,\n",
       "        -0.02233639, -0.05024064],\n",
       "       [-0.03258473, -0.01201572, -0.14578347, ...,  0.02647092,\n",
       "         0.00956726,  0.08082717],\n",
       "       [-0.02405371,  0.08321401, -0.01471415, ..., -0.01313205,\n",
       "         0.08241286, -0.01497937]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d00033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "640d737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"OpenStatus\"]=df[\"OpenStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7efbd468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>deleting image from image folder I am working ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>Need help making HTML's Hi to all the gurus ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  OpenStatus\n",
       "0       For Mongodb is it better to reference an objec...           1\n",
       "1       How to insert schemalocation in a xml document...           1\n",
       "2       Too many lookup tables  What are the adverse e...           1\n",
       "3       What is this PHP code in VB.net I am looking f...           0\n",
       "4       Spring-Data mongodb querying multiple classes ...           1\n",
       "...                                                   ...         ...\n",
       "140267  Is it possible to implement bitwise operators ...           1\n",
       "140268  Ruby on Rails: MySql Gem does not work: uninit...           1\n",
       "140269  deleting image from image folder I am working ...           0\n",
       "140270  Need help making HTML's Hi to all the gurus ou...           0\n",
       "140271  How dangerous is it to output certain content ...           1\n",
       "\n",
       "[140272 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45203694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[df1.OpenStatus==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "553406e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stop ajax function in midway when other elemen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140264</th>\n",
       "      <td>Automated typing of words fed through text/csv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140265</th>\n",
       "      <td>How to check unicode string to be letters, spa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  OpenStatus\n",
       "0       For Mongodb is it better to reference an objec...           1\n",
       "1       How to insert schemalocation in a xml document...           1\n",
       "2       Too many lookup tables  What are the adverse e...           1\n",
       "4       Spring-Data mongodb querying multiple classes ...           1\n",
       "5       stop ajax function in midway when other elemen...           1\n",
       "...                                                   ...         ...\n",
       "140264  Automated typing of words fed through text/csv...           1\n",
       "140265  How to check unicode string to be letters, spa...           1\n",
       "140267  Is it possible to implement bitwise operators ...           1\n",
       "140268  Ruby on Rails: MySql Gem does not work: uninit...           1\n",
       "140271  How dangerous is it to output certain content ...           1\n",
       "\n",
       "[70136 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "477586ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bert_open = np.array(bert_model.encode(df2[\"text\"].tolist(), convert_to_numpy=True))\n",
    "pred=logreg_bert.predict(X_bert_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da786bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12340\\2382551189.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"Pred\"]=pred\n"
     ]
    }
   ],
   "source": [
    "df2[\"Pred\"]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a61a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df2[df2.Pred==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6c4717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Micro Cloud Foundry Sinatra Hello world applic...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What views can i use in an appWidget? Can anyo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Make input in program input value at website I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>can you create one div to flow over others lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140241</th>\n",
       "      <td>which one to use windows services or threading...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140246</th>\n",
       "      <td>How to find the closest value of 2^N to a give...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140250</th>\n",
       "      <td>Summing integers recursive with Java. I have t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140259</th>\n",
       "      <td>Javascript can't find element by id?     &lt;html...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140264</th>\n",
       "      <td>Automated typing of words fed through text/csv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15936 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  OpenStatus  Pred\n",
       "2       Too many lookup tables  What are the adverse e...           1     0\n",
       "25      Micro Cloud Foundry Sinatra Hello world applic...           1     0\n",
       "26      What views can i use in an appWidget? Can anyo...           1     0\n",
       "32      Make input in program input value at website I...           1     0\n",
       "34      can you create one div to flow over others lik...           1     0\n",
       "...                                                   ...         ...   ...\n",
       "140241  which one to use windows services or threading...           1     0\n",
       "140246  How to find the closest value of 2^N to a give...           1     0\n",
       "140250  Summing integers recursive with Java. I have t...           1     0\n",
       "140259  Javascript can't find element by id?     <html...           1     0\n",
       "140264  Automated typing of words fed through text/csv...           1     0\n",
       "\n",
       "[15936 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98fa1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"False Prediction of Open_Bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b564be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2=df2[df2.Pred==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5460e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"True Prediction of Open_Bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de8f95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1[df1.OpenStatus==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f9ca22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>List of all .txt file I want to write a progra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I want to design an invitation card for my wed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VB Script To Delete Header and Footer plus App...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Is It Possible to Create CSV File with Multipl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140262</th>\n",
       "      <td>Programming a microprocessor? Im not sure if t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140263</th>\n",
       "      <td>Disable Duplicate Tab Option or disable the ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140266</th>\n",
       "      <td>Force compile a .java file How would I get a ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>deleting image from image folder I am working ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>Need help making HTML's Hi to all the gurus ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  OpenStatus\n",
       "3       What is this PHP code in VB.net I am looking f...           0\n",
       "7       List of all .txt file I want to write a progra...           0\n",
       "8       I want to design an invitation card for my wed...           0\n",
       "9       VB Script To Delete Header and Footer plus App...           0\n",
       "11      Is It Possible to Create CSV File with Multipl...           0\n",
       "...                                                   ...         ...\n",
       "140262  Programming a microprocessor? Im not sure if t...           0\n",
       "140263  Disable Duplicate Tab Option or disable the ta...           0\n",
       "140266  Force compile a .java file How would I get a ....           0\n",
       "140269  deleting image from image folder I am working ...           0\n",
       "140270  Need help making HTML's Hi to all the gurus ou...           0\n",
       "\n",
       "[70136 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69a07349",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bert_close = np.array(bert_model.encode(df3[\"text\"].tolist(), convert_to_numpy=True))\n",
    "pred=logreg_bert.predict(X_bert_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41b0a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12340\\3458487816.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3[\"Pred\"]=pred\n"
     ]
    }
   ],
   "source": [
    "df3[\"Pred\"]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "908876f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df3[df3.Pred==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec30ce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>List of all .txt file I want to write a progra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I want to design an invitation card for my wed...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VB Script To Delete Header and Footer plus App...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Is It Possible to Create CSV File with Multipl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140262</th>\n",
       "      <td>Programming a microprocessor? Im not sure if t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140263</th>\n",
       "      <td>Disable Duplicate Tab Option or disable the ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140266</th>\n",
       "      <td>Force compile a .java file How would I get a ....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>deleting image from image folder I am working ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>Need help making HTML's Hi to all the gurus ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70136 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  OpenStatus  Pred\n",
       "3       What is this PHP code in VB.net I am looking f...           0     0\n",
       "7       List of all .txt file I want to write a progra...           0     0\n",
       "8       I want to design an invitation card for my wed...           0     0\n",
       "9       VB Script To Delete Header and Footer plus App...           0     0\n",
       "11      Is It Possible to Create CSV File with Multipl...           0     1\n",
       "...                                                   ...         ...   ...\n",
       "140262  Programming a microprocessor? Im not sure if t...           0     0\n",
       "140263  Disable Duplicate Tab Option or disable the ta...           0     1\n",
       "140266  Force compile a .java file How would I get a ....           0     1\n",
       "140269  deleting image from image folder I am working ...           0     1\n",
       "140270  Need help making HTML's Hi to all the gurus ou...           0     0\n",
       "\n",
       "[70136 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e472109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(\"False Prediction of Close_Bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "976bb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df3[df3.Pred==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "601b2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(\"True Prediction of Close_Bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72166bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.OpenStatus.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b45505",
   "metadata": {},
   "source": [
    "# SBERT TITLE+BODYMARKDOWN (with 4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfbe0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Regression with BERT Accuracy: 0.6507574407414008\n",
      "\n",
      "Classification Report (BERT - Multiclass Logistic Regression):\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "not a real question       0.56      0.47      0.51      6196\n",
      "   not constructive       0.60      0.60      0.60      3110\n",
      "          off topic       0.58      0.43      0.49      3563\n",
      "               open       0.70      0.86      0.77     13938\n",
      "      too localized       0.44      0.03      0.06      1248\n",
      "\n",
      "           accuracy                           0.65     28055\n",
      "          macro avg       0.58      0.48      0.49     28055\n",
      "       weighted avg       0.63      0.65      0.63     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a pre-trained BERT model for sentence embeddings\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  \n",
    "\n",
    "# Convert OpenStatus to numerical labels for multiclass classification\n",
    "unique_labels = df[\"OpenStatus\"].unique()\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(label_to_index)\n",
    "\n",
    "# Generate BERT embeddings\n",
    "X_bert = np.array(bert_model.encode(df[\"text\"].tolist(), convert_to_numpy=True))\n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(X_bert, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Multiclass Logistic Regression\n",
    "logreg_bert = LogisticRegression(max_iter=1000, solver=\"lbfgs\", multi_class=\"multinomial\")  \n",
    "logreg_bert.fit(X_train_bert, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_bert = logreg_bert.predict(X_test_bert)\n",
    "\n",
    "# Convert numerical predictions back to labels\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "y_test_labels = [index_to_label[y] for y in y_test]\n",
    "y_pred_labels = [index_to_label[y] for y in y_pred_bert]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Multiclass Logistic Regression with BERT Accuracy:\", accuracy_score(y_test, y_pred_bert))\n",
    "print(\"\\nClassification Report (BERT - Multiclass Logistic Regression):\\n\", classification_report(y_test_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b42d2814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\False Prediction of Open.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0302c6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tokens</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['for', 'mongodb', 'is', 'it', 'better', 'to',...</td>\n",
       "      <td>1</td>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['too', 'many', 'lookup', 'tables', 'what', 'a...</td>\n",
       "      <td>1</td>\n",
       "      <td>Too many lookup tables  What are the adverse e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>['in', 'gef', 'bendpoints', 'how', 'can', 'i',...</td>\n",
       "      <td>1</td>\n",
       "      <td>In GEF bendpoints, how can i retrieve point fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>['how', 'can', 'a', 'windows', 'phone', '7', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>How can a Windows Phone 7 application register...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>['micro', 'cloud', 'foundry', 'sinatra', 'hell...</td>\n",
       "      <td>1</td>\n",
       "      <td>Micro Cloud Foundry Sinatra Hello world applic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17991</th>\n",
       "      <td>140250</td>\n",
       "      <td>['summing', 'integers', 'recursive', 'with', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>Summing integers recursive with Java. I have t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17992</th>\n",
       "      <td>140259</td>\n",
       "      <td>['javascript', 'can', 't', 'find', 'element', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Javascript can't find element by id?     &lt;html...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17993</th>\n",
       "      <td>140260</td>\n",
       "      <td>['how', 'to', 'create', 'internet', 'explorer'...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to create Internet Explorer sidebar extens...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17994</th>\n",
       "      <td>140264</td>\n",
       "      <td>['automated', 'typing', 'of', 'words', 'fed', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Automated typing of words fed through text/csv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>140265</td>\n",
       "      <td>['how', 'to', 'check', 'unicode', 'string', 't...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to check unicode string to be letters, spa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17996 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             tokens  \\\n",
       "0               0  ['for', 'mongodb', 'is', 'it', 'better', 'to',...   \n",
       "1               2  ['too', 'many', 'lookup', 'tables', 'what', 'a...   \n",
       "2              10  ['in', 'gef', 'bendpoints', 'how', 'can', 'i',...   \n",
       "3              20  ['how', 'can', 'a', 'windows', 'phone', '7', '...   \n",
       "4              25  ['micro', 'cloud', 'foundry', 'sinatra', 'hell...   \n",
       "...           ...                                                ...   \n",
       "17991      140250  ['summing', 'integers', 'recursive', 'with', '...   \n",
       "17992      140259  ['javascript', 'can', 't', 'find', 'element', ...   \n",
       "17993      140260  ['how', 'to', 'create', 'internet', 'explorer'...   \n",
       "17994      140264  ['automated', 'typing', 'of', 'words', 'fed', ...   \n",
       "17995      140265  ['how', 'to', 'check', 'unicode', 'string', 't...   \n",
       "\n",
       "       OpenStatus                                               text  Pred  \n",
       "0               1  For Mongodb is it better to reference an objec...     0  \n",
       "1               1  Too many lookup tables  What are the adverse e...     0  \n",
       "2               1  In GEF bendpoints, how can i retrieve point fr...     0  \n",
       "3               1  How can a Windows Phone 7 application register...     0  \n",
       "4               1  Micro Cloud Foundry Sinatra Hello world applic...     0  \n",
       "...           ...                                                ...   ...  \n",
       "17991           1  Summing integers recursive with Java. I have t...     0  \n",
       "17992           1  Javascript can't find element by id?     <html...     0  \n",
       "17993           1  How to create Internet Explorer sidebar extens...     0  \n",
       "17994           1  Automated typing of words fed through text/csv...     0  \n",
       "17995           1  How to check unicode string to be letters, spa...     0  \n",
       "\n",
       "[17996 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "265c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "avg=np.array([len(text) for text in df.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c3e7153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017469   0.00510068 0.00480064 ... 0.02977064 0.01163488 0.01220163]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Compute text lengths\n",
    "avg = np.array([len(text) for text in df.text]).reshape(-1, 1)  # Reshape for sklearn\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "avg_scaled = scaler.fit_transform(avg)\n",
    "\n",
    "print(avg_scaled.flatten())  # Values now between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65854859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021960390821613884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avg_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "844a7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\True Prediction of Open.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73e17e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tokens</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>text</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['how', 'to', 'insert', 'schemalocation', 'in'...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>['spring', 'data', 'mongodb', 'querying', 'mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>['stop', 'ajax', 'function', 'in', 'midway', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>stop ajax function in midway when other elemen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>['regex', 'to', 'detect', 'javascript', 'in', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Regex to detect Javascript In a string I am tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>['how', 'to', 'write', 'shellextension', 'cont...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to write shellextension contextmenuitem in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52135</th>\n",
       "      <td>140253</td>\n",
       "      <td>['hiding', 'inherited', 'members', 'in', 'c', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hiding inherited members in C# I'm looking for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52136</th>\n",
       "      <td>140254</td>\n",
       "      <td>['dropdown', 'dont', 'show', 'correct', 'paren...</td>\n",
       "      <td>1</td>\n",
       "      <td>dropdown dont show correct(parent div has over...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52137</th>\n",
       "      <td>140267</td>\n",
       "      <td>['is', 'it', 'possible', 'to', 'implement', 'b...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52138</th>\n",
       "      <td>140268</td>\n",
       "      <td>['ruby', 'on', 'rails', 'mysql', 'gem', 'does'...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52139</th>\n",
       "      <td>140271</td>\n",
       "      <td>['how', 'dangerous', 'is', 'it', 'to', 'output...</td>\n",
       "      <td>1</td>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52140 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             tokens  \\\n",
       "0               1  ['how', 'to', 'insert', 'schemalocation', 'in'...   \n",
       "1               4  ['spring', 'data', 'mongodb', 'querying', 'mul...   \n",
       "2               5  ['stop', 'ajax', 'function', 'in', 'midway', '...   \n",
       "3               6  ['regex', 'to', 'detect', 'javascript', 'in', ...   \n",
       "4              12  ['how', 'to', 'write', 'shellextension', 'cont...   \n",
       "...           ...                                                ...   \n",
       "52135      140253  ['hiding', 'inherited', 'members', 'in', 'c', ...   \n",
       "52136      140254  ['dropdown', 'dont', 'show', 'correct', 'paren...   \n",
       "52137      140267  ['is', 'it', 'possible', 'to', 'implement', 'b...   \n",
       "52138      140268  ['ruby', 'on', 'rails', 'mysql', 'gem', 'does'...   \n",
       "52139      140271  ['how', 'dangerous', 'is', 'it', 'to', 'output...   \n",
       "\n",
       "       OpenStatus                                               text  Pred  \n",
       "0               1  How to insert schemalocation in a xml document...     1  \n",
       "1               1  Spring-Data mongodb querying multiple classes ...     1  \n",
       "2               1  stop ajax function in midway when other elemen...     1  \n",
       "3               1  Regex to detect Javascript In a string I am tr...     1  \n",
       "4               1  How to write shellextension contextmenuitem in...     1  \n",
       "...           ...                                                ...   ...  \n",
       "52135           1  Hiding inherited members in C# I'm looking for...     1  \n",
       "52136           1  dropdown dont show correct(parent div has over...     1  \n",
       "52137           1  Is it possible to implement bitwise operators ...     1  \n",
       "52138           1  Ruby on Rails: MySql Gem does not work: uninit...     1  \n",
       "52139           1  How dangerous is it to output certain content ...     1  \n",
       "\n",
       "[52140 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6129845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "avg=np.array([len(text) for text in df1.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2474526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03181848 0.02095689 0.01762511 ... 0.1058506  0.02752049 0.02522156]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Compute text lengths\n",
    "avg = np.array([len(text) for text in df1.text]).reshape(-1, 1)  # Reshape for sklearn\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "avg_scaled = scaler.fit_transform(avg)\n",
    "\n",
    "print(avg_scaled.flatten())  # Values now between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db8ac97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03521380471238471"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avg_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf8a57a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31456990442320515"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for i in df.text:\n",
    "    if ('code' in i) | ('{' in i) :\n",
    "        c+=1\n",
    "c/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85b655d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49493670886075947"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for i in df1.text:\n",
    "    if ('code' in i) | ('{' in i) :\n",
    "        c+=1\n",
    "c/len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5141784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\sample_train_tokens_with_stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "860a9317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15652\\1536407353.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.OpenStatus[(df.OpenStatus=='too localized') | (df.OpenStatus=='not a real question') | (df.OpenStatus=='off topic') | (df.OpenStatus=='not constructive')]='closed'\n"
     ]
    }
   ],
   "source": [
    "df.OpenStatus[(df.OpenStatus=='too localized') | (df.OpenStatus=='not a real question') | (df.OpenStatus=='off topic') | (df.OpenStatus=='not constructive')]='closed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f43559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03cd9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"OpenStatus\"]=df[\"OpenStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a0fadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For Mongodb is it better to reference an objec...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to insert schemalocation in a xml document...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Too many lookup tables</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is this PHP code in VB.net</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>Is it possible to implement bitwise operators ...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>Ruby on Rails: MySql Gem does not work: uninit...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>deleting image from image folder</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>Need help making HTML's</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>How dangerous is it to output certain content ...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title OpenStatus\n",
       "0       For Mongodb is it better to reference an objec...       open\n",
       "1       How to insert schemalocation in a xml document...       open\n",
       "2                                 Too many lookup tables        open\n",
       "3                         What is this PHP code in VB.net     closed\n",
       "4       Spring-Data mongodb querying multiple classes ...       open\n",
       "...                                                   ...        ...\n",
       "140267  Is it possible to implement bitwise operators ...       open\n",
       "140268  Ruby on Rails: MySql Gem does not work: uninit...       open\n",
       "140269                   deleting image from image folder     closed\n",
       "140270                            Need help making HTML's     closed\n",
       "140271  How dangerous is it to output certain content ...       open\n",
       "\n",
       "[140272 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9575ec",
   "metadata": {},
   "source": [
    "# SBERT TITLE ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae168cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BERT Accuracy: 0.7134200677241134\n",
      "\n",
      "Classification Report (BERT - Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71     14117\n",
      "           1       0.70      0.73      0.72     13938\n",
      "\n",
      "    accuracy                           0.71     28055\n",
      "   macro avg       0.71      0.71      0.71     28055\n",
      "weighted avg       0.71      0.71      0.71     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a pre-trained BERT model for sentence embeddings\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient & good performance\n",
    "\n",
    "# Assume df1 contains our dataset with \"text\" (combined title + body) and \"OpenStatus\"\n",
    "df1[\"OpenStatus\"] = df1[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "\n",
    "# Generate embeddings\n",
    "X_bert = np.array(bert_model.encode(df1[\"Title\"].tolist(), convert_to_numpy=True))\n",
    "y = df1[\"OpenStatus\"].values\n",
    "\n",
    "# Split into train & test sets\n",
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(X_bert, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression on BERT embeddings\n",
    "logreg_bert = LogisticRegression(max_iter=1000)\n",
    "logreg_bert.fit(X_train_bert, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_bert = logreg_bert.predict(X_test_bert)\n",
    "\n",
    "print(\"Logistic Regression with BERT Accuracy:\", accuracy_score(y_test, y_pred_bert))\n",
    "print(\"\\nClassification Report (BERT - Logistic Regression):\\n\", classification_report(y_test, y_pred_bert))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39de8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\sample_train_tokens_with_stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9023e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15652\\1536407353.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.OpenStatus[(df.OpenStatus=='too localized') | (df.OpenStatus=='not a real question') | (df.OpenStatus=='off topic') | (df.OpenStatus=='not constructive')]='closed'\n"
     ]
    }
   ],
   "source": [
    "df.OpenStatus[(df.OpenStatus=='too localized') | (df.OpenStatus=='not a real question') | (df.OpenStatus=='off topic') | (df.OpenStatus=='not constructive')]='closed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09530fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df.BodyMarkdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b56a7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"OpenStatus\"]=df[\"OpenStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72fb13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BodyMarkdown</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am building a corpus of indexed sentences in...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i create a xml document with JAXP and search a...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the adverse effects of having too man...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am looking for the vb.net equivalent of this...</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With Spring-Data, you can use the @Document an...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140267</th>\n",
       "      <td>I am facing a rather peculiar problem. I am wo...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140268</th>\n",
       "      <td>I have the following installed:\\r\\nMac Os 10.7...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>I am working with an asp.net application.I wan...</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>Hi to all the gurus out there.\\r\\n\\r\\nAnybody ...</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140271</th>\n",
       "      <td>Following on from a question I asked about esc...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             BodyMarkdown OpenStatus\n",
       "0       I am building a corpus of indexed sentences in...       open\n",
       "1       i create a xml document with JAXP and search a...       open\n",
       "2       What are the adverse effects of having too man...       open\n",
       "3       I am looking for the vb.net equivalent of this...     closed\n",
       "4       With Spring-Data, you can use the @Document an...       open\n",
       "...                                                   ...        ...\n",
       "140267  I am facing a rather peculiar problem. I am wo...       open\n",
       "140268  I have the following installed:\\r\\nMac Os 10.7...       open\n",
       "140269  I am working with an asp.net application.I wan...     closed\n",
       "140270  Hi to all the gurus out there.\\r\\n\\r\\nAnybody ...     closed\n",
       "140271  Following on from a question I asked about esc...       open\n",
       "\n",
       "[140272 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04649095",
   "metadata": {},
   "source": [
    "# SBERT BODYMARKDOWN ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c47d205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with BERT Accuracy: 0.7493494920691499\n",
      "\n",
      "Classification Report (BERT - Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75     14117\n",
      "           1       0.74      0.76      0.75     13938\n",
      "\n",
      "    accuracy                           0.75     28055\n",
      "   macro avg       0.75      0.75      0.75     28055\n",
      "weighted avg       0.75      0.75      0.75     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a pre-trained BERT model for sentence embeddings\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient & good performance\n",
    "\n",
    "# Assume df1 contains our dataset with \"text\" (combined title + body) and \"OpenStatus\"\n",
    "df1[\"OpenStatus\"] = df1[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "\n",
    "# Generate embeddings\n",
    "X_bert = np.array(bert_model.encode(df1[\"BodyMarkdown\"].tolist(), convert_to_numpy=True))\n",
    "y = df1[\"OpenStatus\"].values\n",
    "\n",
    "# Split into train & test sets\n",
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(X_bert, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression on BERT embeddings\n",
    "logreg_bert = LogisticRegression(max_iter=1000)\n",
    "logreg_bert.fit(X_train_bert, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_bert = logreg_bert.predict(X_test_bert)\n",
    "\n",
    "print(\"Logistic Regression with BERT Accuracy:\", accuracy_score(y_test, y_pred_bert))\n",
    "print(\"\\nClassification Report (BERT - Logistic Regression):\\n\", classification_report(y_test, y_pred_bert))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711e1fb",
   "metadata": {},
   "source": [
    "# EXTRACT CODE SNIPPETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818ce7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\Labs\\NLP\\Project\\train-sample.csv\\train-sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f890eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code snippets extracted and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_code_snippets(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Extract properly formatted code blocks (triple backticks)\n",
    "    triple_backtick_pattern = re.findall(r'```(?:[a-zA-Z]+\\n)?(.*?)```', text, re.DOTALL)\n",
    "    \n",
    "    # Extract code from <code>...</code> tags\n",
    "    html_code_pattern = re.findall(r'<code>(.*?)</code>', text, re.DOTALL)\n",
    "    \n",
    "    # Extract indented code (at least 4 spaces at the start of the line)\n",
    "    indented_code_pattern = re.findall(r'(?m)(?:^|\\n)(    .+)', text)\n",
    "    \n",
    "    # Extract inline code (single backticks)\n",
    "    inline_code_pattern = re.findall(r'`(.*?)`', text)\n",
    "    \n",
    "    # Extract code-like patterns that use common programming keywords or symbols\n",
    "    code_like_pattern = re.findall(r'(?m)(?:^|\\n).*?[=;{}<>()[\\]]+.*', text)\n",
    "    \n",
    "    # Combine all extracted snippets\n",
    "    extracted_code = (\n",
    "        triple_backtick_pattern + html_code_pattern + indented_code_pattern + \n",
    "        inline_code_pattern + code_like_pattern\n",
    "    )\n",
    "    \n",
    "    # Join multiple snippets with a gap between them\n",
    "    return \"\\n\\n\".join(extracted_code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply function to extract code snippets\n",
    "df[\"CodeSnippets\"] = df[\"BodyMarkdown\"].apply(extract_code_snippets)\n",
    "\n",
    "# Save the modified dataset\n",
    "df.to_csv(\"train-sample_with_code.csv\", index=False)\n",
    "\n",
    "print(\"Code snippets extracted and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c53a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54db4903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostId                                      0\n",
       "PostCreationDate                            0\n",
       "OwnerUserId                                 0\n",
       "OwnerCreationDate                           0\n",
       "ReputationAtPostCreation                    0\n",
       "OwnerUndeletedAnswerCountAtPostTime         0\n",
       "Title                                       0\n",
       "BodyMarkdown                                0\n",
       "Tag1                                       10\n",
       "Tag2                                    27251\n",
       "Tag3                                    64358\n",
       "Tag4                                   100622\n",
       "Tag5                                   124558\n",
       "PostClosedDate                          70136\n",
       "OpenStatus                                  0\n",
       "CodeSnippets                            44278\n",
       "CodeLanguage                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63409339",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218d3f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Compute embeddings using GPU\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "df['Tags_embedding'] = df['Tags_combined'].apply(encode_text)\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8304283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"with_code_embeddings.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8c1372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7698\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77     14117\n",
      "           1       0.77      0.77      0.77     13938\n",
      "\n",
      "    accuracy                           0.77     28055\n",
      "   macro avg       0.77      0.77      0.77     28055\n",
      "weighted avg       0.77      0.77      0.77     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc18cfa",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITHOUT CODE) + TAGS + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1254a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"with_code_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e10fe98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "def remove_code_from_body(body, code):\n",
    "    body = str(body) if pd.notna(body) else \"\"  # Ensure body is a string\n",
    "    code = str(code) if pd.notna(code) else \"\"  # Ensure code is a string\n",
    "    return body.replace(code, \"\").strip() if code in body else body\n",
    "df['BodyMarkdown'] = df.apply(lambda row: remove_code_from_body(row['BodyMarkdown'], row['CodeSnippets']), axis=1)\n",
    "\n",
    "\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "df['Tags_embedding'] = df['Tags_combined'].apply(encode_text)\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a785016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7641\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76     14117\n",
      "           1       0.76      0.77      0.76     13938\n",
      "\n",
      "    accuracy                           0.76     28055\n",
      "   macro avg       0.76      0.76      0.76     28055\n",
      "weighted avg       0.76      0.76      0.76     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e5cba",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITHOUT CODE) + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6d9c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5508928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7593\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76     14117\n",
      "           1       0.76      0.76      0.76     13938\n",
      "\n",
      "    accuracy                           0.76     28055\n",
      "   macro avg       0.76      0.76      0.76     28055\n",
      "weighted avg       0.76      0.76      0.76     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "#df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd85fa",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ffc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7074ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "\n",
    "\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)  \n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ae53a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7645\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76     14117\n",
      "           1       0.76      0.77      0.76     13938\n",
      "\n",
      "    accuracy                           0.76     28055\n",
      "   macro avg       0.76      0.76      0.76     28055\n",
      "weighted avg       0.76      0.76      0.76     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d90b9",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fed3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f939b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7614\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76     14117\n",
      "           1       0.75      0.77      0.76     13938\n",
      "\n",
      "    accuracy                           0.76     28055\n",
      "   macro avg       0.76      0.76      0.76     28055\n",
      "weighted avg       0.76      0.76      0.76     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "#df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28162f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4078c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "started\n",
      "Title finished\n",
      "Bodymarkdown finished\n",
      "Codesnippets Finished\n",
      "tags finished\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Compute embeddings using GPU\n",
    "print(\"started\")\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "print(\"Bodymarkdown finished\")\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "print(\"Codesnippets Finished\")\n",
    "df['Tags_embedding'] = df['Tags_combined'].apply(encode_text)\n",
    "print(\"tags finished\")\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8d9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f14989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7258\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72     14117\n",
      "           1       0.71      0.75      0.73     13938\n",
      "\n",
      "    accuracy                           0.73     28055\n",
      "   macro avg       0.73      0.73      0.73     28055\n",
      "weighted avg       0.73      0.73      0.73     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de75a206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [19:25:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7555\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75     14117\n",
      "           1       0.75      0.76      0.76     13938\n",
      "\n",
      "    accuracy                           0.76     28055\n",
      "   macro avg       0.76      0.76      0.76     28055\n",
      "weighted avg       0.76      0.76      0.76     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d474c1e",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE} => (USING SVM LINEAR KERNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88942245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM model\n",
    "svm_clf = SVC(kernel='linear', C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da52e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa57dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c045ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7706\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77     14117\n",
      "           1       0.77      0.77      0.77     13938\n",
      "\n",
      "    accuracy                           0.77     28055\n",
      "   macro avg       0.77      0.77      0.77     28055\n",
      "weighted avg       0.77      0.77      0.77     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df870b23",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE} => (MUTLICLASS CLASSIFICATION) using different MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "585440d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79fb7fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6649\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "not a real question       0.57      0.51      0.54      6196\n",
      "   not constructive       0.60      0.59      0.60      3110\n",
      "          off topic       0.60      0.49      0.54      3563\n",
      "               open       0.72      0.85      0.78     13938\n",
      "      too localized       0.42      0.06      0.11      1248\n",
      "\n",
      "           accuracy                           0.66     28055\n",
      "          macro avg       0.58      0.50      0.51     28055\n",
      "       weighted avg       0.65      0.66      0.65     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_m[\"OpenStatus\"] = label_encoder.fit_transform(df_m[\"OpenStatus\"])  \n",
    "\n",
    "X = np.vstack(df_m['combined_embedding'].values)  \n",
    "y = df_m[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model for multi-class classification\n",
    "clf = LogisticRegression(max_iter=1000, multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6dc1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5837\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "not a real question       0.52      0.32      0.40      6196\n",
      "   not constructive       0.61      0.39      0.48      3110\n",
      "          off topic       0.64      0.10      0.17      3563\n",
      "               open       0.59      0.92      0.72     13938\n",
      "      too localized       0.00      0.00      0.00      1248\n",
      "\n",
      "           accuracy                           0.58     28055\n",
      "          macro avg       0.47      0.35      0.35     28055\n",
      "       weighted avg       0.56      0.58      0.52     28055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cd8fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bd36129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6670\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "not a real question       0.57      0.51      0.54      6196\n",
      "   not constructive       0.60      0.62      0.61      3110\n",
      "          off topic       0.62      0.49      0.55      3563\n",
      "               open       0.72      0.85      0.78     13938\n",
      "      too localized       0.00      0.00      0.00      1248\n",
      "\n",
      "           accuracy                           0.67     28055\n",
      "          macro avg       0.50      0.49      0.50     28055\n",
      "       weighted avg       0.63      0.67      0.64     28055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Convert OpenStatus to numerical labels for multi-class classification\n",
    "label_encoder = LabelEncoder()\n",
    "df_m[\"OpenStatus\"] = label_encoder.fit_transform(df_m[\"OpenStatus\"])  # Encode categories as 0,1,2,...\n",
    "\n",
    "X = np.vstack(df_m['combined_embedding'].values)  \n",
    "y = df_m[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM model for multi-class classification\n",
    "clf = SVC(kernel=\"linear\", decision_function_shape=\"ovr\")  # \"ovr\" = One-vs-Rest strategy\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVM Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3903e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485294e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29b714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaa0cb30",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE} => (MUTLICLASS CLASSIFICATION AND OUTPUT AS BINARY CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bc2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a5b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "cuda\n",
      "started\n",
      "Title finished\n",
      "Bodymarkdown finished\n",
      "Codesnippets Finished\n",
      "tags finished\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Compute embeddings using GPU\n",
    "print(\"started\")\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "print(\"Bodymarkdown finished\")\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "print(\"Codesnippets Finished\")\n",
    "df['Tags_embedding'] = df['Tags_combined'].apply(encode_text)\n",
    "print(\"tags finished\")\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f8ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1742ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Binary (Open vs. Rest) Accuracy: 0.7642\n",
      "Binary Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Not Open       0.82      0.68      0.74     14117\n",
      "        Open       0.72      0.85      0.78     13938\n",
      "\n",
      "    accuracy                           0.76     28055\n",
      "   macro avg       0.77      0.76      0.76     28055\n",
      "weighted avg       0.77      0.76      0.76     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Convert OpenStatus to numerical labels for multi-class classification\n",
    "label_encoder = LabelEncoder()\n",
    "df_m[\"OpenStatus\"] = label_encoder.fit_transform(df_m[\"OpenStatus\"])  # Encode categories as 0,1,2,...\n",
    "\n",
    "X = np.vstack(df_m['combined_embedding'].values)  \n",
    "y = df_m[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM model for multi-class classification\n",
    "clf = SVC(kernel=\"linear\", decision_function_shape=\"ovr\")  # \"ovr\" = One-vs-Rest strategy\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions for multi-class classification\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# ---- Convert to Binary Classification (Open vs. Rest) ----\n",
    "# Identify the label index for \"open\"\n",
    "open_class_index = np.where(label_encoder.classes_ == \"open\")[0][0]\n",
    "\n",
    "# Convert y_test and y_pred into binary classification\n",
    "y_test_binary = np.where(y_test == open_class_index, 1, 0)\n",
    "y_pred_binary = np.where(y_pred == open_class_index, 1, 0)\n",
    "\n",
    "# Evaluate binary classification\n",
    "accuracy_binary = accuracy_score(y_test_binary, y_pred_binary)\n",
    "print(f\"SVM Binary (Open vs. Rest) Accuracy: {accuracy_binary:.4f}\")\n",
    "print(\"Binary Classification Report:\\n\", classification_report(y_test_binary, y_pred_binary, target_names=[\"Not Open\", \"Open\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5a081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3933a5f9",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + {TAG1+....+TAG5}(Word2Vec) + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5c43ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa20437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "cuda\n",
      "Started computing SBERT embeddings...\n",
      "Title finished\n",
      "BodyMarkdown finished\n",
      "CodeSnippets finished\n",
      "Preparing Word2Vec model for tags...\n",
      "Word2Vec embeddings computed for tags!\n",
      "Feature engineering completed!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using SBERT\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():\n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "\n",
    "# ---- Compute SBERT Embeddings ----\n",
    "print(\"Started computing SBERT embeddings...\")\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "print(\"BodyMarkdown finished\")\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "print(\"CodeSnippets finished\")\n",
    "\n",
    "# ---- Prepare Word2Vec for Tags ----\n",
    "print(\"Preparing Word2Vec model for tags...\")\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "tags_list = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].values.tolist()\n",
    "tags_flattened = [tag for sublist in tags_list for tag in sublist if tag]\n",
    "\n",
    "# Train Word2Vec model on tags\n",
    "word2vec_model = Word2Vec(sentences=[tags_flattened], vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get Word2Vec embedding for a tag\n",
    "def get_tag_embedding(tag):\n",
    "    if tag in word2vec_model.wv:\n",
    "        return word2vec_model.wv[tag]\n",
    "    else:\n",
    "        return np.zeros(50)  # Zero vector if tag is missing in vocabulary\n",
    "\n",
    "# Compute Word2Vec embeddings for each Tag\n",
    "df['Tag1_embedding'] = df['Tag1'].apply(get_tag_embedding)\n",
    "df['Tag2_embedding'] = df['Tag2'].apply(get_tag_embedding)\n",
    "df['Tag3_embedding'] = df['Tag3'].apply(get_tag_embedding)\n",
    "df['Tag4_embedding'] = df['Tag4'].apply(get_tag_embedding)\n",
    "df['Tag5_embedding'] = df['Tag5'].apply(get_tag_embedding)\n",
    "\n",
    "print(\"Word2Vec embeddings computed for tags!\")\n",
    "\n",
    "# ---- Merge All Embeddings ----\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tag1_embedding'],\n",
    "        row['Tag2_embedding'],\n",
    "        row['Tag3_embedding'],\n",
    "        row['Tag4_embedding'],\n",
    "        row['Tag5_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d3732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77     14117\n",
      "           1       0.76      0.77      0.77     13938\n",
      "\n",
      "    accuracy                           0.77     28055\n",
      "   macro avg       0.77      0.77      0.77     28055\n",
      "weighted avg       0.77      0.77      0.77     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79508b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ad95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00d66b60",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + {TAG1+....+TAG5}(Word2Vec) with permutations(mean) + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56393f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f074c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "from itertools import permutations\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using SBERT\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():\n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy()\n",
    "    else:\n",
    "        return np.zeros(384)  # Return zero vector for empty values\n",
    "\n",
    "# ---- Compute SBERT Embeddings ----\n",
    "print(\"Started computing SBERT embeddings...\")\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "print(\"BodyMarkdown finished\")\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "print(\"CodeSnippets finished\")\n",
    "\n",
    "# ---- Prepare Word2Vec for Tags ----\n",
    "print(\"Preparing Word2Vec model for tags...\")\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "tags_list = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].values.tolist()\n",
    "tags_flattened = [tag for sublist in tags_list for tag in sublist if tag]\n",
    "\n",
    "# Train Word2Vec model on tags\n",
    "word2vec_model = Word2Vec(sentences=[tags_flattened], vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get Word2Vec embedding for a tag\n",
    "def get_tag_embedding(tag):\n",
    "    if tag and tag in word2vec_model.wv:\n",
    "        return word2vec_model.wv[tag]\n",
    "    else:\n",
    "        return np.zeros(50)  # Zero vector if tag is missing in vocabulary\n",
    "\n",
    "# ---- Compute Permutation-Based Tag Embeddings ----\n",
    "def get_permutation_embedding(tags):\n",
    "    valid_tags = [tag for tag in tags if tag]  # Remove empty tags\n",
    "    perm_embeddings = []\n",
    "    \n",
    "    if not valid_tags:\n",
    "        return np.zeros(50)  # Handle cases where all tags are empty\n",
    "\n",
    "    for perm in permutations(valid_tags):\n",
    "        perm_embedding = np.mean([get_tag_embedding(tag) for tag in perm], axis=0)  # Average embedding\n",
    "        perm_embeddings.append(perm_embedding)\n",
    "\n",
    "    return np.mean(perm_embeddings, axis=0) if perm_embeddings else np.zeros(50)  # Ensure valid output\n",
    "\n",
    "df['Tag_permutation_embedding'] = df.apply(lambda row: get_permutation_embedding([row['Tag1'], row['Tag2'], row['Tag3'], row['Tag4'], row['Tag5']]), axis=1)\n",
    "print(\"Permutation embeddings computed for tags!\")\n",
    "\n",
    "# ---- Ensure all embeddings have the same shape ----\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tag_permutation_embedding'].reshape(-1)  # Ensures it's a 1D array\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1207c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7662\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77     14117\n",
      "           1       0.76      0.77      0.77     13938\n",
      "\n",
      "    accuracy                           0.77     28055\n",
      "   macro avg       0.77      0.77      0.77     28055\n",
      "weighted avg       0.77      0.77      0.77     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572faf0",
   "metadata": {},
   "source": [
    "# SUMMARY GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c41ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f992c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  For Mongodb is it better to reference an objec...   \n",
      "1  How to insert schemalocation in a xml document...   \n",
      "2                            Too many lookup tables    \n",
      "3                    What is this PHP code in VB.net   \n",
      "4  Spring-Data mongodb querying multiple classes ...   \n",
      "\n",
      "                                             summary  \n",
      "0  For Mongodb is it better to reference an objec...  \n",
      "1  i create a xml document with JAXP and search a...  \n",
      "2  I have to incorportate too many Enumerations, ...  \n",
      "3  I am looking for the vb.net equivalent of this...  \n",
      "4  Spring-Data mongodb querying multiple classes ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1  \n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "\n",
    "df['combined_text'] = df['Title'].astype(str) + \". \" + df['BodyMarkdown'].astype(str)\n",
    "\n",
    "def summarize_text(text):\n",
    "    input_length = len(text.split()) \n",
    "    \n",
    "    if input_length < 20:\n",
    "        return text  \n",
    "\n",
    "    max_length = max(10, min(input_length // 2, input_length - 5)) \n",
    "    min_length = max(5, max_length // 2)  \n",
    "\n",
    "    try:\n",
    "        summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Apply summarization\n",
    "df['summary'] = df['combined_text'].apply(summarize_text)\n",
    "\n",
    "# Save summarized data to a new CSV file\n",
    "df.to_csv(\"preprocessed_with_summary.csv\", index=False)\n",
    "\n",
    "# Display a sample of the results\n",
    "print(df[['Title', 'summary']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506d985",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { SUMMARY + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dc9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"preprocessed_with_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ba8ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "cuda\n",
      "started\n",
      "Title finished\n",
      "Codesnippets Finished\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  \n",
    "\n",
    "# Compute embeddings using GPU\n",
    "print(\"started\")\n",
    "df['Summary_embedding'] = df['summary'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "print(\"Codesnippets Finished\")\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Summary_embedding'],\n",
    "        row['CodeSnippets_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ba5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6970\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.72     14117\n",
      "           1       0.73      0.63      0.67     13938\n",
      "\n",
      "    accuracy                           0.70     28055\n",
      "   macro avg       0.70      0.70      0.70     28055\n",
      "weighted avg       0.70      0.70      0.70     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b320b8",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { SUMMARY + TAGS + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7eb7311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tags finished\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  \n",
    "    \n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "df['Tags_embedding'] = df['Tags_combined'].apply(encode_text)\n",
    "print(\"tags finished\")\n",
    "\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Summary_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c42100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7158\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72     14117\n",
      "           1       0.72      0.70      0.71     13938\n",
      "\n",
      "    accuracy                           0.72     28055\n",
      "   macro avg       0.72      0.72      0.72     28055\n",
      "weighted avg       0.72      0.72      0.72     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e44a8",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { SUMMARY + TITLE + BODYMARKDOWN(WITH CODE) + CODE} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1fe6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "started\n",
      "Title finished\n",
      "Bodymarkdown finished\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  \n",
    "\n",
    "# Compute embeddings using GPU\n",
    "print(\"started\")\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "print(\"Bodymarkdown finished\")\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Summary_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "018b24cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7654\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77     14117\n",
      "           1       0.76      0.77      0.77     13938\n",
      "\n",
      "    accuracy                           0.77     28055\n",
      "   macro avg       0.77      0.77      0.77     28055\n",
      "weighted avg       0.77      0.77      0.77     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5707e1e",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE { SUMMARY + TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad39c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Summary_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52fb762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7689\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77     14117\n",
      "           1       0.76      0.78      0.77     13938\n",
      "\n",
      "    accuracy                           0.77     28055\n",
      "   macro avg       0.77      0.77      0.77     28055\n",
      "weighted avg       0.77      0.77      0.77     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99617bc1",
   "metadata": {},
   "source": [
    "# REMOVING TOO LOCALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c299c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2429860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.OpenStatus!='too localized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca65dbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "cuda\n",
      "started\n",
      "Title finished\n",
      "Bodymarkdown finished\n",
      "Codesnippets Finished\n",
      "tags finished\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Compute embeddings using GPU\n",
    "print(\"started\")\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "print(\"Bodymarkdown finished\")\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "print(\"Codesnippets Finished\")\n",
    "df['Tags_embedding'] = df['Tags_combined'].apply(encode_text)\n",
    "print(\"tags finished\")\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f943ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7889\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77     12640\n",
      "           1       0.79      0.81      0.80     14183\n",
      "\n",
      "    accuracy                           0.79     26823\n",
      "   macro avg       0.79      0.79      0.79     26823\n",
      "weighted avg       0.79      0.79      0.79     26823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.vstack(df['combined_embedding'].values)  \n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset into training & testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1184871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56722de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da71a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a6d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4124f47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "started\n",
      "Title finished\n",
      "Bodymarkdown finished\n",
      "Codesnippets Finished\n",
      "tags finished\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load SBERT model and move it to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to encode text using GPU\n",
    "def encode_text(text):\n",
    "    if isinstance(text, str) and text.strip():  \n",
    "        return sbert_model.encode(text, convert_to_tensor=True, device=device).cpu().numpy().tolist()\n",
    "    else:\n",
    "        return np.zeros(384).tolist()  # Return zero vector for empty values\n",
    "\n",
    "# Fill NaN values\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Compute embeddings using GPU\n",
    "print(\"started\")\n",
    "df['Title_embedding'] = df['Title'].apply(encode_text)\n",
    "print(\"Title finished\")\n",
    "df['BodyMarkdown_embedding'] = df['BodyMarkdown'].apply(encode_text)\n",
    "print(\"Bodymarkdown finished\")\n",
    "df['CodeSnippets_embedding'] = df['CodeSnippets'].apply(encode_text)\n",
    "print(\"Codesnippets Finished\")\n",
    "df['Tags_embedding'] = df['Tags_combined'].apply(encode_text)\n",
    "print(\"tags finished\")\n",
    "\n",
    "# Merge embeddings\n",
    "def merge_embeddings(row):\n",
    "    return np.concatenate([\n",
    "        row['Title_embedding'],\n",
    "        row['BodyMarkdown_embedding'],\n",
    "        row['CodeSnippets_embedding'],\n",
    "        row['Tags_embedding']\n",
    "    ])\n",
    "\n",
    "df['combined_embedding'] = df.apply(merge_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8286c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to NumPy array\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "X = np.stack(df['combined_embedding'].values)  # Shape: (num_samples, embedding_dim)\n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Classification labels\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9acc36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),  \n",
    "            nn.BatchNorm1d(512),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Reduce overfitting  \n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b546d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 128\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Reduce overfitting  \n",
    "\n",
    "            nn.Linear(hid, hid//2),\n",
    "            nn.BatchNorm1d(hid//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hid//2, hid//4),\n",
    "            nn.BatchNorm1d(hid//4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(hid//4, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2502c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 128\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)  # Reduce overfitting  \n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)\n",
    "\n",
    "        self.b3 = nn.Sequential(    \n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),)\n",
    "\n",
    "        self.final = nn.Linear(hid, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.b1(x)\n",
    "        x = x + self.b2(x)\n",
    "        x = x + self.b3(x)\n",
    "        \n",
    "        #densenet\n",
    "        #x1 = x + self.b2(x)\n",
    "        #x2 = x1 + self.b3(x1) + x\n",
    "        # return self.final(x2)\n",
    "        \n",
    "        return self.final(x)\n",
    "    \n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aab765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.5058\n",
      "Epoch [2/25], Loss: 0.4847\n",
      "Epoch [3/25], Loss: 0.4781\n",
      "Epoch [4/25], Loss: 0.4740\n",
      "Epoch [5/25], Loss: 0.4703\n",
      "Epoch [6/25], Loss: 0.4665\n",
      "Epoch [7/25], Loss: 0.4634\n",
      "Epoch [8/25], Loss: 0.4598\n",
      "Epoch [9/25], Loss: 0.4565\n",
      "Epoch [10/25], Loss: 0.4565\n",
      "Epoch [11/25], Loss: 0.4548\n",
      "Epoch [12/25], Loss: 0.4529\n",
      "Epoch [13/25], Loss: 0.4521\n",
      "Epoch [14/25], Loss: 0.4502\n",
      "Epoch [15/25], Loss: 0.4476\n",
      "Epoch [16/25], Loss: 0.4477\n",
      "Epoch [17/25], Loss: 0.4471\n",
      "Epoch [18/25], Loss: 0.4454\n",
      "Epoch [19/25], Loss: 0.4446\n",
      "Epoch [20/25], Loss: 0.4443\n",
      "Epoch [21/25], Loss: 0.4427\n",
      "Epoch [22/25], Loss: 0.4407\n",
      "Epoch [23/25], Loss: 0.4401\n",
      "Epoch [24/25], Loss: 0.4399\n",
      "Epoch [25/25], Loss: 0.4377\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e916d",
   "metadata": {},
   "source": [
    "# GENERAL NN WITH DROPOUT and HID=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9f32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.67%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342654fc",
   "metadata": {},
   "source": [
    "# GENERAL NN WITH DROPOUT and HID=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e68bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.4399\n",
      "Epoch [2/25], Loss: 0.4393\n",
      "Epoch [3/25], Loss: 0.4373\n",
      "Epoch [4/25], Loss: 0.4380\n",
      "Epoch [5/25], Loss: 0.4366\n",
      "Epoch [6/25], Loss: 0.4360\n",
      "Epoch [7/25], Loss: 0.4345\n",
      "Epoch [8/25], Loss: 0.4347\n",
      "Epoch [9/25], Loss: 0.4354\n",
      "Epoch [10/25], Loss: 0.4331\n",
      "Epoch [11/25], Loss: 0.4331\n",
      "Epoch [12/25], Loss: 0.4332\n",
      "Epoch [13/25], Loss: 0.4325\n",
      "Epoch [14/25], Loss: 0.4329\n",
      "Epoch [15/25], Loss: 0.4336\n",
      "Epoch [16/25], Loss: 0.4311\n",
      "Epoch [17/25], Loss: 0.4336\n",
      "Epoch [18/25], Loss: 0.4311\n",
      "Epoch [19/25], Loss: 0.4318\n",
      "Epoch [20/25], Loss: 0.4310\n",
      "Epoch [21/25], Loss: 0.4307\n",
      "Epoch [22/25], Loss: 0.4301\n",
      "Epoch [23/25], Loss: 0.4307\n",
      "Epoch [24/25], Loss: 0.4293\n",
      "Epoch [25/25], Loss: 0.4291\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccd226f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.16%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ff52e",
   "metadata": {},
   "source": [
    "# GENERAL NN WITH DROPOUT and HID=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9751bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 64\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Reduce overfitting  \n",
    "\n",
    "            nn.Linear(hid, hid//2),\n",
    "            nn.BatchNorm1d(hid//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hid//2, hid//4),\n",
    "            nn.BatchNorm1d(hid//4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(hid//4, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d5ffa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.5146\n",
      "Epoch [2/25], Loss: 0.4922\n",
      "Epoch [3/25], Loss: 0.4822\n",
      "Epoch [4/25], Loss: 0.4768\n",
      "Epoch [5/25], Loss: 0.4735\n",
      "Epoch [6/25], Loss: 0.4697\n",
      "Epoch [7/25], Loss: 0.4678\n",
      "Epoch [8/25], Loss: 0.4649\n",
      "Epoch [9/25], Loss: 0.4613\n",
      "Epoch [10/25], Loss: 0.4604\n",
      "Epoch [11/25], Loss: 0.4567\n",
      "Epoch [12/25], Loss: 0.4565\n",
      "Epoch [13/25], Loss: 0.4560\n",
      "Epoch [14/25], Loss: 0.4563\n",
      "Epoch [15/25], Loss: 0.4529\n",
      "Epoch [16/25], Loss: 0.4522\n",
      "Epoch [17/25], Loss: 0.4511\n",
      "Epoch [18/25], Loss: 0.4504\n",
      "Epoch [19/25], Loss: 0.4512\n",
      "Epoch [20/25], Loss: 0.4469\n",
      "Epoch [21/25], Loss: 0.4494\n",
      "Epoch [22/25], Loss: 0.4483\n",
      "Epoch [23/25], Loss: 0.4471\n",
      "Epoch [24/25], Loss: 0.4473\n",
      "Epoch [25/25], Loss: 0.4468\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8fa6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.34%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188f585",
   "metadata": {},
   "source": [
    "# Residual with hid=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ef8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 128\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)  # Reduce overfitting  \n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)\n",
    "\n",
    "        self.b3 = nn.Sequential(    \n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),)\n",
    "\n",
    "        self.final = nn.Linear(hid, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.b1(x)\n",
    "        x = x + self.b2(x)\n",
    "        x = x + self.b3(x)\n",
    "        \n",
    "        #densenet\n",
    "        #x1 = x + self.b2(x)\n",
    "        #x2 = x1 + self.b3(x1) + x\n",
    "        # return self.final(x2)\n",
    "        \n",
    "        return self.final(x)\n",
    "    \n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d29a0d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.5088\n",
      "Epoch [2/25], Loss: 0.4847\n",
      "Epoch [3/25], Loss: 0.4766\n",
      "Epoch [4/25], Loss: 0.4707\n",
      "Epoch [5/25], Loss: 0.4663\n",
      "Epoch [6/25], Loss: 0.4643\n",
      "Epoch [7/25], Loss: 0.4607\n",
      "Epoch [8/25], Loss: 0.4574\n",
      "Epoch [9/25], Loss: 0.4560\n",
      "Epoch [10/25], Loss: 0.4536\n",
      "Epoch [11/25], Loss: 0.4507\n",
      "Epoch [12/25], Loss: 0.4488\n",
      "Epoch [13/25], Loss: 0.4467\n",
      "Epoch [14/25], Loss: 0.4439\n",
      "Epoch [15/25], Loss: 0.4431\n",
      "Epoch [16/25], Loss: 0.4415\n",
      "Epoch [17/25], Loss: 0.4412\n",
      "Epoch [18/25], Loss: 0.4394\n",
      "Epoch [19/25], Loss: 0.4373\n",
      "Epoch [20/25], Loss: 0.4363\n",
      "Epoch [21/25], Loss: 0.4361\n",
      "Epoch [22/25], Loss: 0.4331\n",
      "Epoch [23/25], Loss: 0.4335\n",
      "Epoch [24/25], Loss: 0.4328\n",
      "Epoch [25/25], Loss: 0.4312\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85b96d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.55%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0911d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.55%\n",
      "Misclassified samples saved to 'misclassified_samples.csv'\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {status: idx for idx, status in enumerate(df[\"OpenStatus\"].unique())}\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(label_mapping)\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "misclassified = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Misclassified indices\n",
    "        mis_idx = (predicted != labels).nonzero(as_tuple=False).squeeze()\n",
    "        if mis_idx.dim() == 0:\n",
    "            mis_idx = mis_idx.unsqueeze(0)\n",
    "\n",
    "        for i in mis_idx:\n",
    "            global_test_index = idx * batch_size + i.item()\n",
    "            global_df_index = X_train.shape[0] + global_test_index\n",
    "\n",
    "            row = df.iloc[global_df_index]\n",
    "            misclassified.append({\n",
    "                \"Title\": row[\"Title\"],\n",
    "                \"BodyMarkdown\": row[\"BodyMarkdown\"],\n",
    "                \"CodeSnippets\": row[\"CodeSnippets\"],\n",
    "                \"Tags_combined\": row[\"Tags_combined\"],\n",
    "                \"TrueLabel\": reverse_label_mapping[row[\"OpenStatus\"]],\n",
    "                \"PredictedLabel\": reverse_label_mapping[predicted[i].item()]\n",
    "            })\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Step 10: Save Misclassified Examples\n",
    "misclassified_df = pd.DataFrame(misclassified)\n",
    "misclassified_df.to_csv(\"misclassified_samples_sbert_nn_binary.csv\", index=False)\n",
    "print(\"Misclassified samples saved to 'misclassified_samples.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2d412",
   "metadata": {},
   "source": [
    "# Residual with HID=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a92b6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 64\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)  # Reduce overfitting  \n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)\n",
    "\n",
    "        self.b3 = nn.Sequential(    \n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),)\n",
    "\n",
    "        self.final = nn.Linear(hid, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.b1(x)\n",
    "        x = x + self.b2(x)\n",
    "        x = x + self.b3(x)\n",
    "        \n",
    "        #densenet\n",
    "        #x1 = x + self.b2(x)\n",
    "        #x2 = x1 + self.b3(x1) + x\n",
    "        # return self.final(x2)\n",
    "        \n",
    "        return self.final(x)\n",
    "    \n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e499325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.5083\n",
      "Epoch [2/25], Loss: 0.4863\n",
      "Epoch [3/25], Loss: 0.4782\n",
      "Epoch [4/25], Loss: 0.4723\n",
      "Epoch [5/25], Loss: 0.4682\n",
      "Epoch [6/25], Loss: 0.4647\n",
      "Epoch [7/25], Loss: 0.4619\n",
      "Epoch [8/25], Loss: 0.4585\n",
      "Epoch [9/25], Loss: 0.4570\n",
      "Epoch [10/25], Loss: 0.4546\n",
      "Epoch [11/25], Loss: 0.4530\n",
      "Epoch [12/25], Loss: 0.4515\n",
      "Epoch [13/25], Loss: 0.4495\n",
      "Epoch [14/25], Loss: 0.4472\n",
      "Epoch [15/25], Loss: 0.4452\n",
      "Epoch [16/25], Loss: 0.4451\n",
      "Epoch [17/25], Loss: 0.4430\n",
      "Epoch [18/25], Loss: 0.4424\n",
      "Epoch [19/25], Loss: 0.4394\n",
      "Epoch [20/25], Loss: 0.4399\n",
      "Epoch [21/25], Loss: 0.4374\n",
      "Epoch [22/25], Loss: 0.4364\n",
      "Epoch [23/25], Loss: 0.4353\n",
      "Epoch [24/25], Loss: 0.4354\n",
      "Epoch [25/25], Loss: 0.4356\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f73b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.53%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f34d8e",
   "metadata": {},
   "source": [
    "# DenseNet with HID=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b90cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 128\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)  # Reduce overfitting  \n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)\n",
    "\n",
    "        self.b3 = nn.Sequential(    \n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),)\n",
    "\n",
    "        self.final = nn.Linear(hid, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "#         x = self.b1(x)\n",
    "#         x = x + self.b2(x)\n",
    "#         x = x + self.b3(x)\n",
    "        \n",
    "        #densenet\n",
    "        x = self.b1(x)\n",
    "        x1 = x + self.b2(x)\n",
    "        x2 = x1 + self.b3(x1) + x\n",
    "        return self.final(x2)\n",
    "    \n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2691680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.5114\n",
      "Epoch [2/25], Loss: 0.4867\n",
      "Epoch [3/25], Loss: 0.4783\n",
      "Epoch [4/25], Loss: 0.4713\n",
      "Epoch [5/25], Loss: 0.4683\n",
      "Epoch [6/25], Loss: 0.4640\n",
      "Epoch [7/25], Loss: 0.4593\n",
      "Epoch [8/25], Loss: 0.4582\n",
      "Epoch [9/25], Loss: 0.4559\n",
      "Epoch [10/25], Loss: 0.4527\n",
      "Epoch [11/25], Loss: 0.4496\n",
      "Epoch [12/25], Loss: 0.4464\n",
      "Epoch [13/25], Loss: 0.4462\n",
      "Epoch [14/25], Loss: 0.4427\n",
      "Epoch [15/25], Loss: 0.4420\n",
      "Epoch [16/25], Loss: 0.4416\n",
      "Epoch [17/25], Loss: 0.4395\n",
      "Epoch [18/25], Loss: 0.4369\n",
      "Epoch [19/25], Loss: 0.4348\n",
      "Epoch [20/25], Loss: 0.4345\n",
      "Epoch [21/25], Loss: 0.4337\n",
      "Epoch [22/25], Loss: 0.4324\n",
      "Epoch [23/25], Loss: 0.4322\n",
      "Epoch [24/25], Loss: 0.4318\n",
      "Epoch [25/25], Loss: 0.4293\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25124af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.51%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf631c",
   "metadata": {},
   "source": [
    "# DenseNet with HID=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4ef9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 64\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  # Normalize activations  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)  # Reduce overfitting  \n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),)\n",
    "\n",
    "        self.b3 = nn.Sequential(    \n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),)\n",
    "\n",
    "        self.final = nn.Linear(hid, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "#         x = self.b1(x)\n",
    "#         x = x + self.b2(x)\n",
    "#         x = x + self.b3(x)\n",
    "        \n",
    "        #densenet\n",
    "        x = self.b1(x)\n",
    "        x1 = x + self.b2(x)\n",
    "        x2 = x1 + self.b3(x1) + x\n",
    "        return self.final(x2)\n",
    "    \n",
    "input_dim=X.shape[1]\n",
    "num_classes = len(set(y))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05d8ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.5120\n",
      "Epoch [2/25], Loss: 0.4878\n",
      "Epoch [3/25], Loss: 0.4797\n",
      "Epoch [4/25], Loss: 0.4732\n",
      "Epoch [5/25], Loss: 0.4694\n",
      "Epoch [6/25], Loss: 0.4642\n",
      "Epoch [7/25], Loss: 0.4610\n",
      "Epoch [8/25], Loss: 0.4593\n",
      "Epoch [9/25], Loss: 0.4550\n",
      "Epoch [10/25], Loss: 0.4533\n",
      "Epoch [11/25], Loss: 0.4529\n",
      "Epoch [12/25], Loss: 0.4490\n",
      "Epoch [13/25], Loss: 0.4485\n",
      "Epoch [14/25], Loss: 0.4475\n",
      "Epoch [15/25], Loss: 0.4452\n",
      "Epoch [16/25], Loss: 0.4452\n",
      "Epoch [17/25], Loss: 0.4430\n",
      "Epoch [18/25], Loss: 0.4407\n",
      "Epoch [19/25], Loss: 0.4405\n",
      "Epoch [20/25], Loss: 0.4401\n",
      "Epoch [21/25], Loss: 0.4394\n",
      "Epoch [22/25], Loss: 0.4390\n",
      "Epoch [23/25], Loss: 0.4367\n",
      "Epoch [24/25], Loss: 0.4363\n",
      "Epoch [25/25], Loss: 0.4341\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea0f0984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.48%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b33aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4da1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682346c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c86d06d",
   "metadata": {},
   "source": [
    "# BERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1adc02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Keep relevant columns\n",
    "df = df[['Title', 'BodyMarkdown', 'CodeSnippets', 'Tags_combined', 'OpenStatus']].dropna()\n",
    "\n",
    "# Convert OpenStatus to binary labels\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "\n",
    "# Load Pretrained BERT Tokenizer and Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)  # Move model to GPU\n",
    "\n",
    "# Function to extract BERT embeddings for a given text\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    # Extract CLS token embedding (first token) and move it back to CPU for NumPy conversion\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "# Extract BERT embeddings for each text field and concatenate\n",
    "def get_combined_embedding(row):\n",
    "    title_emb = get_bert_embeddings(row['Title'])\n",
    "    body_emb = get_bert_embeddings(row['BodyMarkdown'])\n",
    "    code_emb = get_bert_embeddings(row['CodeSnippets'])\n",
    "    tags_emb = get_bert_embeddings(row['Tags_combined'])\n",
    "\n",
    "    # Concatenate all embeddings into one feature vector\n",
    "    return np.concatenate([title_emb, body_emb, code_emb, tags_emb])\n",
    "\n",
    "# Apply function to get embeddings\n",
    "df['bert_embeddings'] = df.apply(get_combined_embedding, axis=1)\n",
    "\n",
    "# Convert embeddings to NumPy array\n",
    "X = np.vstack(df['bert_embeddings'])  # (num_samples, embedding_size * 4)\n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Logistic Regression (BERT) Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify misclassified indices\n",
    "misclassified_indices = np.where(y_pred_lr != y_test)[0]\n",
    "\n",
    "# Convert test split to DataFrame\n",
    "# First, create a temporary test dataframe using the index from train_test_split\n",
    "X_test_indices = df.iloc[X_train.shape[0]:].index  # assumes order is preserved\n",
    "\n",
    "# Now collect misclassified rows using index from original df\n",
    "misclassified_rows = []\n",
    "\n",
    "for idx in misclassified_indices:\n",
    "    row_idx = X_test_indices[idx]\n",
    "    row = df.loc[row_idx]\n",
    "\n",
    "    misclassified_rows.append({\n",
    "        \"Title\": row[\"Title\"],\n",
    "        \"BodyMarkdown\": row[\"BodyMarkdown\"],\n",
    "        \"CodeSnippets\": row[\"CodeSnippets\"],\n",
    "        \"Tags_combined\": row[\"Tags_combined\"],\n",
    "        \"TrueLabel\": row[\"OpenStatus\"],\n",
    "        \"PredictedLabel\": int(y_pred_lr[idx])\n",
    "    })\n",
    "\n",
    "# Create DataFrame from misclassified rows\n",
    "misclassified_df = pd.DataFrame(misclassified_rows)\n",
    "\n",
    "# Save to CSV\n",
    "misclassified_df.to_csv(\"bert_lr_misclassified_binary.csv\", index=False)\n",
    "print(\"Misclassified samples saved to 'bert_lr_misclassified.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f2aac",
   "metadata": {},
   "source": [
    "# BERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE} Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f66541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b49354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ====== DATA PREPARATION ======\n",
    "\n",
    "# Fill missing tags\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Keep relevant columns\n",
    "df = df[['Title', 'BodyMarkdown', 'CodeSnippets', 'Tags_combined', 'OpenStatus']].dropna()\n",
    "\n",
    "# Create label mappings for multiclass\n",
    "unique_labels = df[\"OpenStatus\"].unique()\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Map labels to numeric form\n",
    "df[\"OpenStatusLabel\"] = df[\"OpenStatus\"].map(label_mapping)\n",
    "\n",
    "# ====== LOAD BERT ======\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# ====== EMBEDDING FUNCTION ======\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "def get_combined_embedding(row):\n",
    "    title_emb = get_bert_embeddings(row['Title'])\n",
    "    body_emb = get_bert_embeddings(row['BodyMarkdown'])\n",
    "    code_emb = get_bert_embeddings(row['CodeSnippets'])\n",
    "    tags_emb = get_bert_embeddings(row['Tags_combined'])\n",
    "    return np.concatenate([title_emb, body_emb, code_emb, tags_emb])\n",
    "\n",
    "# ====== EXTRACT EMBEDDINGS ======\n",
    "\n",
    "print(\"Extracting embeddings...\")\n",
    "df['bert_embeddings'] = df.apply(get_combined_embedding, axis=1)\n",
    "\n",
    "X = np.vstack(df['bert_embeddings'])  # Shape: (num_samples, embedding_size * 4)\n",
    "y = df[\"OpenStatusLabel\"].values\n",
    "\n",
    "# ====== TRAIN-TEST SPLIT ======\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ====== MODEL TRAINING ======\n",
    "print(\"Training Logistic Regression for multi-class...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# ====== EVALUATION ======\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression (Multiclass BERT) Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=[reverse_label_mapping[i] for i in sorted(reverse_label_mapping)]))\n",
    "\n",
    "# ====== MISCLASSIFIED SAMPLES ======\n",
    "\n",
    "misclassified_indices = np.where(y_pred_lr != y_test)[0]\n",
    "print(f\"Total misclassified samples: {len(misclassified_indices)}\")\n",
    "\n",
    "# Find indices of X_test in original df (preserving row alignment)\n",
    "X_test_indices = df.iloc[X_train.shape[0]:].index\n",
    "\n",
    "misclassified_rows = []\n",
    "for idx in misclassified_indices:\n",
    "    row_idx = X_test_indices[idx]\n",
    "    row = df.loc[row_idx]\n",
    "    misclassified_rows.append({\n",
    "        \"Title\": row[\"Title\"],\n",
    "        \"BodyMarkdown\": row[\"BodyMarkdown\"],\n",
    "        \"CodeSnippets\": row[\"CodeSnippets\"],\n",
    "        \"Tags_combined\": row[\"Tags_combined\"],\n",
    "        \"TrueLabel\": reverse_label_mapping[row[\"OpenStatusLabel\"]],\n",
    "        \"PredictedLabel\": reverse_label_mapping[y_pred_lr[idx]]\n",
    "    })\n",
    "\n",
    "misclassified_df = pd.DataFrame(misclassified_rows)\n",
    "misclassified_df.to_csv(\"bertpretained_multiclass_misclassified.csv\", index=False)\n",
    "print(\"Saved misclassified samples to 'bert_multiclass_misclassified.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d88ee",
   "metadata": {},
   "source": [
    "# BERT CONCATINATE { TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE} CLASIFIER AS NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dfae23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"train-sample_with_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d180f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/25], Loss: 0.5250\n",
      "Epoch [2/25], Loss: 0.4997\n",
      "Epoch [3/25], Loss: 0.4883\n",
      "Epoch [4/25], Loss: 0.4759\n",
      "Epoch [5/25], Loss: 0.4627\n",
      "Epoch [6/25], Loss: 0.4527\n",
      "Epoch [7/25], Loss: 0.4396\n",
      "Epoch [8/25], Loss: 0.4261\n",
      "Epoch [9/25], Loss: 0.4090\n",
      "Epoch [10/25], Loss: 0.3960\n",
      "Epoch [11/25], Loss: 0.3788\n",
      "Epoch [12/25], Loss: 0.3620\n",
      "Epoch [13/25], Loss: 0.3469\n",
      "Epoch [14/25], Loss: 0.3307\n",
      "Epoch [15/25], Loss: 0.3146\n",
      "Epoch [16/25], Loss: 0.3008\n",
      "Epoch [17/25], Loss: 0.2861\n",
      "Epoch [18/25], Loss: 0.2749\n",
      "Epoch [19/25], Loss: 0.2609\n",
      "Epoch [20/25], Loss: 0.2512\n",
      "Epoch [21/25], Loss: 0.2388\n",
      "Epoch [22/25], Loss: 0.2308\n",
      "Epoch [23/25], Loss: 0.2216\n",
      "Epoch [24/25], Loss: 0.2113\n",
      "Epoch [25/25], Loss: 0.2041\n",
      "Test Accuracy: 0.7470\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      7998\n",
      "           1       0.79      0.78      0.78     11201\n",
      "\n",
      "    accuracy                           0.75     19199\n",
      "   macro avg       0.74      0.74      0.74     19199\n",
      "weighted avg       0.75      0.75      0.75     19199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].fillna('')\n",
    "df['Tags_combined'] = df[['Tag1', 'Tag2', 'Tag3', 'Tag4', 'Tag5']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "df = df[['Title', 'BodyMarkdown', 'CodeSnippets', 'Tags_combined', 'OpenStatus']].dropna()\n",
    "\n",
    "# Convert OpenStatus to binary labels\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(lambda x: 1 if x == \"open\" else 0)\n",
    "\n",
    "# Load Pretrained BERT Tokenizer and Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)  # Move model to GPU\n",
    "\n",
    "# Function to extract BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    # Extract CLS token embedding (first token)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "def get_combined_embedding(row):\n",
    "    title_emb = get_bert_embeddings(row['Title'])\n",
    "    body_emb = get_bert_embeddings(row['BodyMarkdown'])\n",
    "    code_emb = get_bert_embeddings(row['CodeSnippets'])\n",
    "    tags_emb = get_bert_embeddings(row['Tags_combined'])\n",
    "\n",
    "    return np.concatenate([title_emb, body_emb, code_emb, tags_emb])\n",
    "\n",
    "# Apply function to get embeddings\n",
    "df['bert_embeddings'] = df.apply(get_combined_embedding, axis=1)\n",
    "\n",
    "# Convert embeddings to NumPy array\n",
    "X = np.vstack(df['bert_embeddings'])  # Shape: (num_samples, embedding_size * 4)\n",
    "y = df[\"OpenStatus\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create PyTorch dataset\n",
    "class StackOverflowDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 32\n",
    "train_dataset = StackOverflowDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = StackOverflowDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the Neural Network Model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128, num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "model = NeuralNetwork(input_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # No sigmoid, using logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        y_pred_labels.extend(preds)\n",
    "\n",
    "# Compute accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bee4f5",
   "metadata": {},
   "source": [
    "# SBERT CONCATINATE {TITLE + BODYMARKDOWN(WITH CODE) + TAGS + CODE} with MULTICLASS CLASSIFIER AS NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a9d1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36c1352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.9369\n",
      "Epoch [2/25], Loss: 0.8810\n",
      "Epoch [3/25], Loss: 0.8602\n",
      "Epoch [4/25], Loss: 0.8473\n",
      "Epoch [5/25], Loss: 0.8380\n",
      "Epoch [6/25], Loss: 0.8263\n",
      "Epoch [7/25], Loss: 0.8216\n",
      "Epoch [8/25], Loss: 0.8154\n",
      "Epoch [9/25], Loss: 0.8083\n",
      "Epoch [10/25], Loss: 0.8059\n",
      "Epoch [11/25], Loss: 0.7991\n",
      "Epoch [12/25], Loss: 0.7929\n",
      "Epoch [13/25], Loss: 0.7921\n",
      "Epoch [14/25], Loss: 0.7861\n",
      "Epoch [15/25], Loss: 0.7811\n",
      "Epoch [16/25], Loss: 0.7801\n",
      "Epoch [17/25], Loss: 0.7760\n",
      "Epoch [18/25], Loss: 0.7739\n",
      "Epoch [19/25], Loss: 0.7680\n",
      "Epoch [20/25], Loss: 0.7684\n",
      "Epoch [21/25], Loss: 0.7657\n",
      "Epoch [22/25], Loss: 0.7643\n",
      "Epoch [23/25], Loss: 0.7618\n",
      "Epoch [24/25], Loss: 0.7604\n",
      "Epoch [25/25], Loss: 0.7574\n",
      "Test Accuracy: 67.23%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Ensure OpenStatus is mapped to multiple classes\n",
    "label_mapping = {status: idx for idx, status in enumerate(df[\"OpenStatus\"].unique())}\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(label_mapping)\n",
    "\n",
    "# Convert embeddings to NumPy array\n",
    "X = np.stack(df['combined_embedding'].values)  # Shape: (num_samples, embedding_dim)\n",
    "y = df[\"OpenStatus\"].values  # Multiclass labels\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Multiclass labels\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 128\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        self.b3 = nn.Sequential(    \n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.final = nn.Linear(hid, num_classes)  # Multiclass output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = x + self.b2(x)  # Residual connection\n",
    "        x = x + self.b3(x)  # Residual connection\n",
    "        return self.final(x)  # No activation here (CrossEntropyLoss handles softmax)\n",
    "\n",
    "# Model setup\n",
    "input_dim = X.shape[1]\n",
    "num_classes = len(set(y))  # Ensure this is >2 for multiclass\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d644503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reverse mapping for labels if needed later\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Store misclassified samples\n",
    "misclassified = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Flattened index to map back to df (based on test split)\n",
    "    for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Get indices of misclassified samples in this batch\n",
    "        mis_idx = (predicted != labels).nonzero(as_tuple=False).squeeze()\n",
    "\n",
    "        # Convert from batch indices to global test set indices\n",
    "        start = batch_idx * batch_size\n",
    "        for i in mis_idx:\n",
    "            i = i.item() if isinstance(i, torch.Tensor) else i\n",
    "            global_test_index = start + i\n",
    "            global_df_index = X_train.shape[0] + global_test_index  # offset from train split\n",
    "\n",
    "            row = df.iloc[global_df_index]\n",
    "            misclassified.append({\n",
    "                \"Title\": row[\"Title\"],\n",
    "                \"BodyMarkdown\": row[\"BodyMarkdown\"],\n",
    "                \"CodeSnippets\": row[\"CodeSnippets\"],\n",
    "                \"Tags_combined\": row[\"Tags_combined\"],\n",
    "                \"TrueLabel\": reverse_label_mapping[row[\"OpenStatus\"]],\n",
    "                \"PredictedLabel\": reverse_label_mapping[predicted[i].item()]\n",
    "            })\n",
    "\n",
    "# Save to CSV\n",
    "misclassified_df = pd.DataFrame(misclassified)\n",
    "misclassified_df.to_csv(\"misclassified_multiclass.csv\", index=False)\n",
    "print(\"Misclassified multi-class samples saved to 'misclassified_multiclass.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963c970",
   "metadata": {},
   "source": [
    "# CLASSIFIER AS NN WITH DATASET OF ONLY 4 CLASSES OF CLOSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2086ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[df1.OpenStatus!='open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d8d1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>PostCreationDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>OwnerCreationDate</th>\n",
       "      <th>ReputationAtPostCreation</th>\n",
       "      <th>OwnerUndeletedAnswerCountAtPostTime</th>\n",
       "      <th>Title</th>\n",
       "      <th>BodyMarkdown</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>...</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>PostClosedDate</th>\n",
       "      <th>OpenStatus</th>\n",
       "      <th>CodeSnippets</th>\n",
       "      <th>Tags_combined</th>\n",
       "      <th>Title_embedding</th>\n",
       "      <th>BodyMarkdown_embedding</th>\n",
       "      <th>CodeSnippets_embedding</th>\n",
       "      <th>Tags_embedding</th>\n",
       "      <th>combined_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9990413</td>\n",
       "      <td>04/03/2012 09:18:39</td>\n",
       "      <td>851755</td>\n",
       "      <td>07/19/2011 10:22:40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>What is this PHP code in VB.net</td>\n",
       "      <td>I am looking for the vb.net equivalent of this...</td>\n",
       "      <td>php</td>\n",
       "      <td>vb.net</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>04/15/2012 21:12:48</td>\n",
       "      <td>too localized</td>\n",
       "      <td>function GetRandomImageURL($topic='', ...</td>\n",
       "      <td>php vb.net</td>\n",
       "      <td>[-0.03341841325163841, 0.07775048911571503, -0...</td>\n",
       "      <td>[-0.0372251495718956, 0.016819197684526443, -0...</td>\n",
       "      <td>[0.038327597081661224, 0.0040036882273852825, ...</td>\n",
       "      <td>[0.027393272146582603, 0.011022448539733887, -...</td>\n",
       "      <td>[-0.03341841325163841, 0.07775048911571503, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5528942</td>\n",
       "      <td>04/03/2011 10:12:59</td>\n",
       "      <td>667355</td>\n",
       "      <td>03/19/2011 14:04:57</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>List of all .txt file</td>\n",
       "      <td>I want to write a program that give a path in ...</td>\n",
       "      <td>c++</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>04/07/2011 05:46:46</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c++ c qt qt4</td>\n",
       "      <td>[0.02608320862054825, 0.038119155913591385, -0...</td>\n",
       "      <td>[0.009011914022266865, 0.03867581486701965, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.037348829209804535, 0.11380478739738464, 0...</td>\n",
       "      <td>[0.02608320862054825, 0.038119155913591385, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4344698</td>\n",
       "      <td>12/03/2010 10:37:44</td>\n",
       "      <td>447244</td>\n",
       "      <td>09/01/2010 09:10:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I want to design an invitation card for my wed...</td>\n",
       "      <td>I want to make an Application in Silverlight f...</td>\n",
       "      <td>silverlight-4.0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>01/08/2012 21:15:49</td>\n",
       "      <td>too localized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silverlight-4.0</td>\n",
       "      <td>[-0.04340985044836998, 0.0606970451772213, 0.0...</td>\n",
       "      <td>[-0.09764896333217621, -0.02625514380633831, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.0334366112947464, -0.0438530258834362, 0.0...</td>\n",
       "      <td>[-0.04340985044836998, 0.0606970451772213, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7910832</td>\n",
       "      <td>10/27/2011 01:37:33</td>\n",
       "      <td>1015681</td>\n",
       "      <td>10/27/2011 01:28:41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VB Script To Delete Header and Footer plus App...</td>\n",
       "      <td>Hi All VB Script Gurus,\\r\\n\\r\\nI am new to VB ...</td>\n",
       "      <td>vb</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>10/27/2011 03:24:58</td>\n",
       "      <td>too localized</td>\n",
       "      <td>\\nI am receiving below sample text file data a...</td>\n",
       "      <td>vb</td>\n",
       "      <td>[-0.0377446785569191, 0.10141204297542572, -0....</td>\n",
       "      <td>[0.00048224395141005516, 0.09679697453975677, ...</td>\n",
       "      <td>[-0.01979973167181015, 0.08987566828727722, -0...</td>\n",
       "      <td>[-0.0012642811052501202, 0.022728707641363144,...</td>\n",
       "      <td>[-0.0377446785569191, 0.10141204297542572, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9131744</td>\n",
       "      <td>02/03/2012 16:12:22</td>\n",
       "      <td>1146408</td>\n",
       "      <td>01/12/2012 20:44:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Is It Possible to Create CSV File with Multipl...</td>\n",
       "      <td>I'm looking to create a .csv file that can be ...</td>\n",
       "      <td>shell</td>\n",
       "      <td>command-line</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>02/06/2012 18:30:34</td>\n",
       "      <td>off topic</td>\n",
       "      <td>I'm looking to create a .csv file that can be ...</td>\n",
       "      <td>shell command-line csv batch</td>\n",
       "      <td>[0.0358935110270977, -0.029179489240050316, -0...</td>\n",
       "      <td>[0.03681127354502678, 0.028263196349143982, -0...</td>\n",
       "      <td>[0.040548935532569885, 0.03179900720715523, -0...</td>\n",
       "      <td>[0.02483845129609108, 0.03598981723189354, -0....</td>\n",
       "      <td>[0.0358935110270977, -0.029179489240050316, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140262</th>\n",
       "      <td>11006475</td>\n",
       "      <td>06/12/2012 23:54:48</td>\n",
       "      <td>1291510</td>\n",
       "      <td>03/25/2012 16:31:50</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Programming a microprocessor?</td>\n",
       "      <td>Im not sure if this would even be the right pl...</td>\n",
       "      <td>assembly</td>\n",
       "      <td>arduino</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>06/13/2012 13:34:13</td>\n",
       "      <td>not constructive</td>\n",
       "      <td>\\nI have little background with Java and ardui...</td>\n",
       "      <td>assembly arduino</td>\n",
       "      <td>[-0.0236246045678854, 0.053209275007247925, -0...</td>\n",
       "      <td>[-0.035059746354818344, -0.028959056362509727,...</td>\n",
       "      <td>[-0.11153912544250488, 0.010645456612110138, -...</td>\n",
       "      <td>[-0.016658557578921318, -0.030236613005399704,...</td>\n",
       "      <td>[-0.0236246045678854, 0.053209275007247925, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140263</th>\n",
       "      <td>7437964</td>\n",
       "      <td>09/15/2011 22:06:00</td>\n",
       "      <td>622096</td>\n",
       "      <td>02/17/2011 20:40:01</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "      <td>Disable Duplicate Tab Option or disable the ta...</td>\n",
       "      <td>I would like to know if there is a way to Disa...</td>\n",
       "      <td>c#</td>\n",
       "      <td>asp.net</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>09/16/2011 10:25:04</td>\n",
       "      <td>off topic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c# asp.net internet-explorer sharepoint</td>\n",
       "      <td>[-0.0051639629527926445, -0.0464232861995697, ...</td>\n",
       "      <td>[0.0061971512623131275, -0.08823780715465546, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.015424485318362713, -0.024611176922917366, ...</td>\n",
       "      <td>[-0.0051639629527926445, -0.0464232861995697, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140266</th>\n",
       "      <td>11487517</td>\n",
       "      <td>07/14/2012 21:32:15</td>\n",
       "      <td>1526149</td>\n",
       "      <td>07/14/2012 21:27:29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Force compile a .java file</td>\n",
       "      <td>How would I get a .java file to compile even w...</td>\n",
       "      <td>java</td>\n",
       "      <td>file</td>\n",
       "      <td>...</td>\n",
       "      <td>errors</td>\n",
       "      <td>07/14/2012 21:51:13</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>java file compilation force errors</td>\n",
       "      <td>[-0.04150749370455742, 0.09111425280570984, -0...</td>\n",
       "      <td>[-0.07320421934127808, 0.06306997686624527, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.023722603917121887, 0.052357129752635956, ...</td>\n",
       "      <td>[-0.04150749370455742, 0.09111425280570984, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140269</th>\n",
       "      <td>10674791</td>\n",
       "      <td>05/20/2012 15:36:31</td>\n",
       "      <td>1388595</td>\n",
       "      <td>05/11/2012 04:43:47</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>deleting image from image folder</td>\n",
       "      <td>I am working with an asp.net application.I wan...</td>\n",
       "      <td>asp.net</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>05/21/2012 21:21:27</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>I am working with an asp.net application.I wan...</td>\n",
       "      <td>asp.net</td>\n",
       "      <td>[0.019524477422237396, 0.03446486219763756, -0...</td>\n",
       "      <td>[0.027463916689157486, 0.01182473637163639, -0...</td>\n",
       "      <td>[0.027463916689157486, 0.01182473637163639, -0...</td>\n",
       "      <td>[-0.05470646917819977, -0.06998041272163391, -...</td>\n",
       "      <td>[0.019524477422237396, 0.03446486219763756, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140270</th>\n",
       "      <td>3997045</td>\n",
       "      <td>10/22/2010 13:04:30</td>\n",
       "      <td>484232</td>\n",
       "      <td>10/22/2010 13:04:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Need help making HTML's</td>\n",
       "      <td>Hi to all the gurus out there.\\r\\n\\r\\nAnybody ...</td>\n",
       "      <td>html</td>\n",
       "      <td>copy</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>10/22/2010 13:10:28</td>\n",
       "      <td>not a real question</td>\n",
       "      <td>\\nnevermind as complex as it sounds it works e...</td>\n",
       "      <td>html copy remove move</td>\n",
       "      <td>[-0.00916069932281971, 0.02880004048347473, -0...</td>\n",
       "      <td>[-0.04521068185567856, -0.026103327050805092, ...</td>\n",
       "      <td>[-0.059632912278175354, -0.06358436495065689, ...</td>\n",
       "      <td>[-0.039570603519678116, 0.012084572575986385, ...</td>\n",
       "      <td>[-0.00916069932281971, 0.02880004048347473, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70136 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PostId     PostCreationDate  OwnerUserId    OwnerCreationDate  \\\n",
       "3        9990413  04/03/2012 09:18:39       851755  07/19/2011 10:22:40   \n",
       "7        5528942  04/03/2011 10:12:59       667355  03/19/2011 14:04:57   \n",
       "8        4344698  12/03/2010 10:37:44       447244  09/01/2010 09:10:05   \n",
       "9        7910832  10/27/2011 01:37:33      1015681  10/27/2011 01:28:41   \n",
       "11       9131744  02/03/2012 16:12:22      1146408  01/12/2012 20:44:19   \n",
       "...          ...                  ...          ...                  ...   \n",
       "140262  11006475  06/12/2012 23:54:48      1291510  03/25/2012 16:31:50   \n",
       "140263   7437964  09/15/2011 22:06:00       622096  02/17/2011 20:40:01   \n",
       "140266  11487517  07/14/2012 21:32:15      1526149  07/14/2012 21:27:29   \n",
       "140269  10674791  05/20/2012 15:36:31      1388595  05/11/2012 04:43:47   \n",
       "140270   3997045  10/22/2010 13:04:30       484232  10/22/2010 13:04:30   \n",
       "\n",
       "        ReputationAtPostCreation  OwnerUndeletedAnswerCountAtPostTime  \\\n",
       "3                              4                                    1   \n",
       "7                             32                                    0   \n",
       "8                              1                                    0   \n",
       "9                              1                                    0   \n",
       "11                             1                                    0   \n",
       "...                          ...                                  ...   \n",
       "140262                        11                                    1   \n",
       "140263                       155                                    3   \n",
       "140266                         1                                    0   \n",
       "140269                         4                                    0   \n",
       "140270                         1                                    0   \n",
       "\n",
       "                                                    Title  \\\n",
       "3                         What is this PHP code in VB.net   \n",
       "7                                   List of all .txt file   \n",
       "8       I want to design an invitation card for my wed...   \n",
       "9       VB Script To Delete Header and Footer plus App...   \n",
       "11      Is It Possible to Create CSV File with Multipl...   \n",
       "...                                                   ...   \n",
       "140262                      Programming a microprocessor?   \n",
       "140263  Disable Duplicate Tab Option or disable the ta...   \n",
       "140266                         Force compile a .java file   \n",
       "140269                   deleting image from image folder   \n",
       "140270                            Need help making HTML's   \n",
       "\n",
       "                                             BodyMarkdown             Tag1  \\\n",
       "3       I am looking for the vb.net equivalent of this...              php   \n",
       "7       I want to write a program that give a path in ...              c++   \n",
       "8       I want to make an Application in Silverlight f...  silverlight-4.0   \n",
       "9       Hi All VB Script Gurus,\\r\\n\\r\\nI am new to VB ...               vb   \n",
       "11      I'm looking to create a .csv file that can be ...            shell   \n",
       "...                                                   ...              ...   \n",
       "140262  Im not sure if this would even be the right pl...         assembly   \n",
       "140263  I would like to know if there is a way to Disa...               c#   \n",
       "140266  How would I get a .java file to compile even w...             java   \n",
       "140269  I am working with an asp.net application.I wan...          asp.net   \n",
       "140270  Hi to all the gurus out there.\\r\\n\\r\\nAnybody ...             html   \n",
       "\n",
       "                Tag2  ...    Tag5       PostClosedDate           OpenStatus  \\\n",
       "3             vb.net  ...          04/15/2012 21:12:48        too localized   \n",
       "7                  c  ...          04/07/2011 05:46:46  not a real question   \n",
       "8                     ...          01/08/2012 21:15:49        too localized   \n",
       "9                     ...          10/27/2011 03:24:58        too localized   \n",
       "11      command-line  ...          02/06/2012 18:30:34            off topic   \n",
       "...              ...  ...     ...                  ...                  ...   \n",
       "140262       arduino  ...          06/13/2012 13:34:13     not constructive   \n",
       "140263       asp.net  ...          09/16/2011 10:25:04            off topic   \n",
       "140266          file  ...  errors  07/14/2012 21:51:13  not a real question   \n",
       "140269                ...          05/21/2012 21:21:27  not a real question   \n",
       "140270          copy  ...          10/22/2010 13:10:28  not a real question   \n",
       "\n",
       "                                             CodeSnippets  \\\n",
       "3               function GetRandomImageURL($topic='', ...   \n",
       "7                                                     NaN   \n",
       "8                                                     NaN   \n",
       "9       \\nI am receiving below sample text file data a...   \n",
       "11      I'm looking to create a .csv file that can be ...   \n",
       "...                                                   ...   \n",
       "140262  \\nI have little background with Java and ardui...   \n",
       "140263                                                NaN   \n",
       "140266                                                NaN   \n",
       "140269  I am working with an asp.net application.I wan...   \n",
       "140270  \\nnevermind as complex as it sounds it works e...   \n",
       "\n",
       "                                   Tags_combined  \\\n",
       "3                                  php vb.net      \n",
       "7                                  c++ c qt qt4    \n",
       "8                            silverlight-4.0       \n",
       "9                                         vb       \n",
       "11                 shell command-line csv batch    \n",
       "...                                          ...   \n",
       "140262                       assembly arduino      \n",
       "140263  c# asp.net internet-explorer sharepoint    \n",
       "140266        java file compilation force errors   \n",
       "140269                               asp.net       \n",
       "140270                    html copy remove move    \n",
       "\n",
       "                                          Title_embedding  \\\n",
       "3       [-0.03341841325163841, 0.07775048911571503, -0...   \n",
       "7       [0.02608320862054825, 0.038119155913591385, -0...   \n",
       "8       [-0.04340985044836998, 0.0606970451772213, 0.0...   \n",
       "9       [-0.0377446785569191, 0.10141204297542572, -0....   \n",
       "11      [0.0358935110270977, -0.029179489240050316, -0...   \n",
       "...                                                   ...   \n",
       "140262  [-0.0236246045678854, 0.053209275007247925, -0...   \n",
       "140263  [-0.0051639629527926445, -0.0464232861995697, ...   \n",
       "140266  [-0.04150749370455742, 0.09111425280570984, -0...   \n",
       "140269  [0.019524477422237396, 0.03446486219763756, -0...   \n",
       "140270  [-0.00916069932281971, 0.02880004048347473, -0...   \n",
       "\n",
       "                                   BodyMarkdown_embedding  \\\n",
       "3       [-0.0372251495718956, 0.016819197684526443, -0...   \n",
       "7       [0.009011914022266865, 0.03867581486701965, -0...   \n",
       "8       [-0.09764896333217621, -0.02625514380633831, -...   \n",
       "9       [0.00048224395141005516, 0.09679697453975677, ...   \n",
       "11      [0.03681127354502678, 0.028263196349143982, -0...   \n",
       "...                                                   ...   \n",
       "140262  [-0.035059746354818344, -0.028959056362509727,...   \n",
       "140263  [0.0061971512623131275, -0.08823780715465546, ...   \n",
       "140266  [-0.07320421934127808, 0.06306997686624527, 0....   \n",
       "140269  [0.027463916689157486, 0.01182473637163639, -0...   \n",
       "140270  [-0.04521068185567856, -0.026103327050805092, ...   \n",
       "\n",
       "                                   CodeSnippets_embedding  \\\n",
       "3       [0.038327597081661224, 0.0040036882273852825, ...   \n",
       "7       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9       [-0.01979973167181015, 0.08987566828727722, -0...   \n",
       "11      [0.040548935532569885, 0.03179900720715523, -0...   \n",
       "...                                                   ...   \n",
       "140262  [-0.11153912544250488, 0.010645456612110138, -...   \n",
       "140263  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "140266  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "140269  [0.027463916689157486, 0.01182473637163639, -0...   \n",
       "140270  [-0.059632912278175354, -0.06358436495065689, ...   \n",
       "\n",
       "                                           Tags_embedding  \\\n",
       "3       [0.027393272146582603, 0.011022448539733887, -...   \n",
       "7       [-0.037348829209804535, 0.11380478739738464, 0...   \n",
       "8       [-0.0334366112947464, -0.0438530258834362, 0.0...   \n",
       "9       [-0.0012642811052501202, 0.022728707641363144,...   \n",
       "11      [0.02483845129609108, 0.03598981723189354, -0....   \n",
       "...                                                   ...   \n",
       "140262  [-0.016658557578921318, -0.030236613005399704,...   \n",
       "140263  [0.015424485318362713, -0.024611176922917366, ...   \n",
       "140266  [-0.023722603917121887, 0.052357129752635956, ...   \n",
       "140269  [-0.05470646917819977, -0.06998041272163391, -...   \n",
       "140270  [-0.039570603519678116, 0.012084572575986385, ...   \n",
       "\n",
       "                                       combined_embedding  \n",
       "3       [-0.03341841325163841, 0.07775048911571503, -0...  \n",
       "7       [0.02608320862054825, 0.038119155913591385, -0...  \n",
       "8       [-0.04340985044836998, 0.0606970451772213, 0.0...  \n",
       "9       [-0.0377446785569191, 0.10141204297542572, -0....  \n",
       "11      [0.0358935110270977, -0.029179489240050316, -0...  \n",
       "...                                                   ...  \n",
       "140262  [-0.0236246045678854, 0.053209275007247925, -0...  \n",
       "140263  [-0.0051639629527926445, -0.0464232861995697, ...  \n",
       "140266  [-0.04150749370455742, 0.09111425280570984, -0...  \n",
       "140269  [0.019524477422237396, 0.03446486219763756, -0...  \n",
       "140270  [-0.00916069932281971, 0.02880004048347473, -0...  \n",
       "\n",
       "[70136 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dfa1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ad2a8de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.8618\n",
      "Epoch [2/25], Loss: 0.7945\n",
      "Epoch [3/25], Loss: 0.7675\n",
      "Epoch [4/25], Loss: 0.7486\n",
      "Epoch [5/25], Loss: 0.7306\n",
      "Epoch [6/25], Loss: 0.7099\n",
      "Epoch [7/25], Loss: 0.6937\n",
      "Epoch [8/25], Loss: 0.6793\n",
      "Epoch [9/25], Loss: 0.6658\n",
      "Epoch [10/25], Loss: 0.6552\n",
      "Epoch [11/25], Loss: 0.6366\n",
      "Epoch [12/25], Loss: 0.6276\n",
      "Epoch [13/25], Loss: 0.6156\n",
      "Epoch [14/25], Loss: 0.6006\n",
      "Epoch [15/25], Loss: 0.5905\n",
      "Epoch [16/25], Loss: 0.5863\n",
      "Epoch [17/25], Loss: 0.5719\n",
      "Epoch [18/25], Loss: 0.5664\n",
      "Epoch [19/25], Loss: 0.5558\n",
      "Epoch [20/25], Loss: 0.5512\n",
      "Epoch [21/25], Loss: 0.5417\n",
      "Epoch [22/25], Loss: 0.5373\n",
      "Epoch [23/25], Loss: 0.5302\n",
      "Epoch [24/25], Loss: 0.5246\n",
      "Epoch [25/25], Loss: 0.5222\n",
      "Test Accuracy: 67.65%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Ensure OpenStatus is mapped to multiple classes\n",
    "label_mapping = {status: idx for idx, status in enumerate(df[\"OpenStatus\"].unique())}\n",
    "df[\"OpenStatus\"] = df[\"OpenStatus\"].map(label_mapping)\n",
    "\n",
    "# Convert embeddings to NumPy array\n",
    "X = np.stack(df['combined_embedding'].values)  # Shape: (num_samples, embedding_dim)\n",
    "y = df[\"OpenStatus\"].values  # Multiclass labels\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Multiclass labels\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        hid = 128\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid),  \n",
    "            nn.BatchNorm1d(hid),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        self.b3 = nn.Sequential(    \n",
    "            nn.Linear(hid, hid),\n",
    "            nn.BatchNorm1d(hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.final = nn.Linear(hid, num_classes)  # Multiclass output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = x + self.b2(x)  # Residual connection\n",
    "        x = x + self.b3(x)  # Residual connection\n",
    "        return self.final(x)  # No activation here (CrossEntropyLoss handles softmax)\n",
    "\n",
    "# Model setup\n",
    "input_dim = X.shape[1]\n",
    "num_classes = len(set(y))  # Ensure this is >2 for multiclass\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(input_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f476153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a01cb4a",
   "metadata": {},
   "source": [
    "# CASCADING PREDICTIONS USING TWO LOGIESTIC REGRESSION MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4773b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59357e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 66.60%\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "not a real question       0.54      0.59      0.56      6158\n",
      "   not constructive       0.62      0.64      0.63      3132\n",
      "          off topic       0.56      0.54      0.55      3506\n",
      "               open       0.77      0.79      0.78     14027\n",
      "      too localized       0.37      0.09      0.15      1232\n",
      "\n",
      "           accuracy                           0.67     28055\n",
      "          macro avg       0.57      0.53      0.53     28055\n",
      "       weighted avg       0.66      0.67      0.66     28055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "df['binary_label'] = df['OpenStatus'].apply(lambda x: 1 if x == 'open' else 0)\n",
    "\n",
    "closed_categories = [\"not a real question\", \"off topic\", \"too localized\", \"not constructive\"]\n",
    "df['multi_label'] = df['OpenStatus'].apply(lambda x: closed_categories.index(x) if x in closed_categories else np.nan)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['OpenStatus'])\n",
    "\n",
    "X_train_bi = np.vstack(train_df['combined_embedding'])\n",
    "y_train_bi = train_df['binary_label']\n",
    "\n",
    "X_test_bi = np.vstack(test_df['combined_embedding'])\n",
    "y_test_bi = test_df['binary_label']\n",
    "\n",
    "log_reg_bi = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_bi.fit(X_train_bi, y_train_bi)\n",
    "\n",
    "df_multi_train = df[df['OpenStatus'] != 'open']\n",
    "\n",
    "X_train_multi = np.vstack(df_multi_train['combined_embedding'])\n",
    "y_train_multi = df_multi_train['multi_label'].astype(int)\n",
    "\n",
    "log_reg_multi = LogisticRegression(max_iter=1000, random_state=42, multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "log_reg_multi.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "correct = 0\n",
    "total = len(test_df)\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    embedding = row['combined_embedding'].reshape(1, -1)\n",
    "    actual_label = row['OpenStatus']\n",
    "\n",
    "    # Step 1: Binary classification (open/closed)\n",
    "    binary_pred = log_reg_bi.predict(embedding)[0]\n",
    "\n",
    "    if binary_pred == 1:  # If predicted Open\n",
    "        final_pred = \"open\"\n",
    "    else:  # If predicted Closed, pass to multiclass model\n",
    "        multi_pred_idx = log_reg_multi.predict(embedding)[0]\n",
    "        final_pred = closed_categories[multi_pred_idx]\n",
    "\n",
    "    predictions.append(final_pred)\n",
    "    actuals.append(actual_label)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "print(f\"Final Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d09135e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 9370 misclassified cases to 'misclassified_cases_cascading_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Collect misclassifications\n",
    "misclassified_rows = []\n",
    "\n",
    "for idx, (pred, actual) in enumerate(zip(predictions, actuals)):\n",
    "    if pred != actual:\n",
    "        row = test_df.iloc[idx]\n",
    "        misclassified_rows.append({\n",
    "            \"Index\": row.name,\n",
    "            \"True_Label\": actual,\n",
    "            \"Predicted_Label\": pred,\n",
    "            \"Title\": row[\"Title\"],\n",
    "            \"BodyMarkdown\": row[\"BodyMarkdown\"],\n",
    "            \"Tags_combined\": row[\"Tags_combined\"],\n",
    "            \"CodeSnippets\": row[\"CodeSnippets\"],\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "misclassified_df = pd.DataFrame(misclassified_rows)\n",
    "\n",
    "# Save to CSV\n",
    "misclassified_df.to_csv(\"misclassified_cases_cascading_predictions.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSaved {len(misclassified_df)} misclassified cases to 'misclassified_cases_cascading_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b0c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7bc872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
